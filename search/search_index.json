{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CRC User Documentation The HPC team within The University of Notre Dame's Center for Research Computing provides computing resources with the associated support for faculty members, researchers, and campus users. Within these pages the supporting documentation and resources for utilizing the CRC's infrastructure can be found. For any questions or assistance please contact us: crcsupport@nd.edu Recent announcements: Note For more information on the January 2025 Biannual System Maintenance, please see here: 2025-january-maintenance . What does the CRC do? The CRC provides faculty sponsored research access to HPC and HTC resources for members of the Notre Dame community. The Center can also facilitate access to large Nationally sponsored resources and other resources through xsede . If you are a new user, be sure to check the links under \"New User Info\" on the left toolbar starting with the quick-start-guide . How can I get help? The CRC User Support Team is happy to help facilitate the use of the CRC infrastructure with day to day operations, general or specific questions, issues, and training for proper and efficient use of the cluster. To schedule an appointment or ask a question, send an email to CRCSupport@nd.edu . Be sure to first view the help page to see what all you need to gather before contacting CRCSupport. The CRC User Support offices are located on the 8th floor of Flanner Hall to the right after leaving the elevators. For specific documentation you can search in the toolbar to the upper left, common and important sections can be found within the toolbar to the left. Internships Interested in a possible internship? Further information can be found on the interns page. new_user/obtain_account new_user/quick_start new_user/connecting_to_crc new_user/linux_guide popular_modules/modules new_user/introductory_videos new_user/training faq/faq help/help infrastructure/resources infrastructure/software infrastructure/available_hardware infrastructure/storage infrastructure/crc_uge_env infrastructure/faculty_infrastructure maintenance/landing resources/gpu resources/condor resources/globus resources/NDCMS/ndcms resources/singularity resources/caml popular_modules/matlab popular_modules/python popular_modules/r popular_modules/tensorflow popular_modules/conda","title":"HOME"},{"location":"#crc-user-documentation","text":"The HPC team within The University of Notre Dame's Center for Research Computing provides computing resources with the associated support for faculty members, researchers, and campus users. Within these pages the supporting documentation and resources for utilizing the CRC's infrastructure can be found. For any questions or assistance please contact us: crcsupport@nd.edu","title":"CRC User Documentation"},{"location":"#recent-announcements","text":"Note For more information on the January 2025 Biannual System Maintenance, please see here: 2025-january-maintenance .","title":"Recent announcements:"},{"location":"#what-does-the-crc-do","text":"The CRC provides faculty sponsored research access to HPC and HTC resources for members of the Notre Dame community. The Center can also facilitate access to large Nationally sponsored resources and other resources through xsede . If you are a new user, be sure to check the links under \"New User Info\" on the left toolbar starting with the quick-start-guide .","title":"What does the CRC do?"},{"location":"#how-can-i-get-help","text":"The CRC User Support Team is happy to help facilitate the use of the CRC infrastructure with day to day operations, general or specific questions, issues, and training for proper and efficient use of the cluster. To schedule an appointment or ask a question, send an email to CRCSupport@nd.edu . Be sure to first view the help page to see what all you need to gather before contacting CRCSupport. The CRC User Support offices are located on the 8th floor of Flanner Hall to the right after leaving the elevators. For specific documentation you can search in the toolbar to the upper left, common and important sections can be found within the toolbar to the left.","title":"How can I get help?"},{"location":"#internships","text":"Interested in a possible internship? Further information can be found on the interns page. new_user/obtain_account new_user/quick_start new_user/connecting_to_crc new_user/linux_guide popular_modules/modules new_user/introductory_videos new_user/training faq/faq help/help infrastructure/resources infrastructure/software infrastructure/available_hardware infrastructure/storage infrastructure/crc_uge_env infrastructure/faculty_infrastructure maintenance/landing resources/gpu resources/condor resources/globus resources/NDCMS/ndcms resources/singularity resources/caml popular_modules/matlab popular_modules/python popular_modules/r popular_modules/tensorflow popular_modules/conda","title":"Internships"},{"location":"crc_infra/available_hardware/","text":"Available Hardware The CRC maintains a mix of compute, interactive, and storage machines. Below is a short descriptive list of the CRC owned machines available. Interactive Front End(s) crcfe01.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD crcfe02.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD daccssfe.crc.nd.edu Dell PowerEdge R930 Server (64 total cores) Quad Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz (64 total cores) 3 TB RAM 6 TB drive - Using Dell H730P hardware RAID controller - RAID 10 using 11 x 1 TB SAS drives CRC Owned Compute Clusters d32cepyc182-d32cepyc247.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #$ -q long or #$ -q *@@general_access d24cepyc067-d24cepyc133.crc.nd.edu HPE ProLiant DL385 Gen10 Servers Dual 24 core AMD EPYC 7451 CPU @ 2.30GHz 128 GB RAM - 2 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q hpc d24cepyc134-d24cepyc137.crc.nd.edu HPE ProLiant DL385 Gen10 Servers Dual 24 core AMD EPYC 7451 CPU @ 2.30GHz 128 GB RAM - 2 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q hpc-debug Large Memory Systems d32cepyc254-d32cepyc257.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 2 TB RAM - 1 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q largemem GPU Systems qa-a10-023-qa-a10-034.crc.nd.edu 12 Dell PowerEdge R750xa Server Dual 16 core 2.9GHz Intel(R) Xeon(R) Gold 6326 processors - 32 total cores 256 GB RAM 4 NVIDIA A10 GPU accelerators **Usage:** Command for interactive access requesting 1 GPU: qrsh -q gpu -l gpu_card=1 Queue syntax for job submission script requesting 1 GPU: #!/bin/csh #$ -q gpu #$ -l gpu_card=1","title":"Available Hardware"},{"location":"crc_infra/available_hardware/#available-hardware","text":"The CRC maintains a mix of compute, interactive, and storage machines. Below is a short descriptive list of the CRC owned machines available.","title":"Available Hardware"},{"location":"crc_infra/available_hardware/#interactive-front-ends","text":"crcfe01.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD crcfe02.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD daccssfe.crc.nd.edu Dell PowerEdge R930 Server (64 total cores) Quad Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz (64 total cores) 3 TB RAM 6 TB drive - Using Dell H730P hardware RAID controller - RAID 10 using 11 x 1 TB SAS drives","title":"Interactive Front End(s)"},{"location":"crc_infra/available_hardware/#crc-owned-compute-clusters","text":"d32cepyc182-d32cepyc247.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 256 GB RAM - 1 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #$ -q long or #$ -q *@@general_access d24cepyc067-d24cepyc133.crc.nd.edu HPE ProLiant DL385 Gen10 Servers Dual 24 core AMD EPYC 7451 CPU @ 2.30GHz 128 GB RAM - 2 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q hpc d24cepyc134-d24cepyc137.crc.nd.edu HPE ProLiant DL385 Gen10 Servers Dual 24 core AMD EPYC 7451 CPU @ 2.30GHz 128 GB RAM - 2 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q hpc-debug","title":"CRC Owned Compute Clusters"},{"location":"crc_infra/available_hardware/#large-memory-systems","text":"d32cepyc254-d32cepyc257.crc.nd.edu Dell PowerEdge R6525 Server (64 total cores) Dual 32 core AMD EPYC 7543 CPU @ 2.80GHz 2 TB RAM - 1 TB Solid State Disk - SSD **Usage:** Queue syntax for job submission script: #!/bin/bash #$ -q largemem","title":"Large Memory Systems"},{"location":"crc_infra/available_hardware/#gpu-systems","text":"qa-a10-023-qa-a10-034.crc.nd.edu 12 Dell PowerEdge R750xa Server Dual 16 core 2.9GHz Intel(R) Xeon(R) Gold 6326 processors - 32 total cores 256 GB RAM 4 NVIDIA A10 GPU accelerators **Usage:** Command for interactive access requesting 1 GPU: qrsh -q gpu -l gpu_card=1 Queue syntax for job submission script requesting 1 GPU: #!/bin/csh #$ -q gpu #$ -l gpu_card=1","title":"GPU Systems"},{"location":"crc_infra/crc_uge_env/","text":"UGE Environment General access to the CRC computational resources is managed with the Grid Engine software tool set. Users should be aware of 4 key framework concepts/components in order to achieve the most effective access to CRC compute nodes. The 4 components covered here are queues, parallel environments, host groups, and user groups. In this document the terms core, slot, and process can be considered suitably equivalent. Note this documentation only covers the CRC general resource pool. There are additional unique instances for particular research group requirements. Using the information found within this page, you are able to submit jobs to the CRC's batch system. For more information on the submission process, see submitting_batch_jobs . Queues CRC queues are configured for differing user run time requirements: long (15 days, no limit on # of cores, normal priority) a maximum limit of 50 running jobs combined between all queues a maximum limit of 2,000 tasks within an array job NOTE: The long queue contains many machines with various hardware architectures. The debug queue consists of only Intel based servers each with a total of 24 cores with 64GB of RAM* Queues are specified in your submit script with the syntax #$ -q long Parallel Environments Parallel Environments (PE) allow the user to specify the mechanisms by which the target code runs in parallel. If a PE is not specified the job will be treated as a serial job and be allocated 1 core. Note that all CRC machines are configured for ONE thread per core. Use the MPI PEs (mpi-24, mpi-48, etc...) when you need more cores than available on 1 machine Use the SMP PE when you need less than or equal to the number of cores on one machine Common Parallel Environments include: * smp (shared memory processing on a single machine up to 64 cores) * MPI is the PE for MPI applications at the CRC (which have been compiled against OpenMPI, MPICH2, and MVAPICH MPI libraries)* * mpi-24 (multi [24 core per] machine processing in 24 core increments) * mpi-32 (multi [32 core per] machine processing in 32 core increments) * mpi-64 (multi [64 core per] machine processing in 64 core increments) [!NOTE] Increments (24,48,64) are mapped to total cores per server. A server with 24 cores will not accept mpi-32 requests. PEs are specified in your submit script with the syntax: #$ -pe mpi-64 128 #$ -pe smp 8 Host Groups Hosts groups allow for the specification of hosts/servers with differing architectures. For example a user can specify a host group of Intel versus AMD based servers. Host groups are specified with the syntax, using the general access host group as an example:: #$ -q *@@crc_d32cepyc To see all available host groups, you can use the -shgrpl flag with qconf as seen below. Note that you will not be able to run jobs on all host groups, only on those which are a part of your research group / groups you have been granted access to. qconf -shgrpl User Groups User groups allow for the designation resource access to specific individuals. This is most often utilized for faculty or group owned resources accessible through the Grid Engine like host groups as explained above. Users do not need to specify their user group as this is automatically determined by user ID. Users must however make sure via their faculty adviser that their ID is in the user group. If it is not, have your PI / faculy advisor send an email to CRCSupport@nd.edu . To view all user lists, pass the -sul flag to qconf. qconf -sul","title":"UGE Environment"},{"location":"crc_infra/crc_uge_env/#uge-environment","text":"General access to the CRC computational resources is managed with the Grid Engine software tool set. Users should be aware of 4 key framework concepts/components in order to achieve the most effective access to CRC compute nodes. The 4 components covered here are queues, parallel environments, host groups, and user groups. In this document the terms core, slot, and process can be considered suitably equivalent. Note this documentation only covers the CRC general resource pool. There are additional unique instances for particular research group requirements. Using the information found within this page, you are able to submit jobs to the CRC's batch system. For more information on the submission process, see submitting_batch_jobs .","title":"UGE Environment"},{"location":"crc_infra/crc_uge_env/#queues","text":"CRC queues are configured for differing user run time requirements: long (15 days, no limit on # of cores, normal priority) a maximum limit of 50 running jobs combined between all queues a maximum limit of 2,000 tasks within an array job NOTE: The long queue contains many machines with various hardware architectures. The debug queue consists of only Intel based servers each with a total of 24 cores with 64GB of RAM* Queues are specified in your submit script with the syntax #$ -q long","title":"Queues"},{"location":"crc_infra/crc_uge_env/#parallel-environments","text":"Parallel Environments (PE) allow the user to specify the mechanisms by which the target code runs in parallel. If a PE is not specified the job will be treated as a serial job and be allocated 1 core. Note that all CRC machines are configured for ONE thread per core. Use the MPI PEs (mpi-24, mpi-48, etc...) when you need more cores than available on 1 machine Use the SMP PE when you need less than or equal to the number of cores on one machine Common Parallel Environments include: * smp (shared memory processing on a single machine up to 64 cores) * MPI is the PE for MPI applications at the CRC (which have been compiled against OpenMPI, MPICH2, and MVAPICH MPI libraries)* * mpi-24 (multi [24 core per] machine processing in 24 core increments) * mpi-32 (multi [32 core per] machine processing in 32 core increments) * mpi-64 (multi [64 core per] machine processing in 64 core increments) [!NOTE] Increments (24,48,64) are mapped to total cores per server. A server with 24 cores will not accept mpi-32 requests. PEs are specified in your submit script with the syntax: #$ -pe mpi-64 128 #$ -pe smp 8","title":"Parallel Environments"},{"location":"crc_infra/crc_uge_env/#host-groups","text":"Hosts groups allow for the specification of hosts/servers with differing architectures. For example a user can specify a host group of Intel versus AMD based servers. Host groups are specified with the syntax, using the general access host group as an example:: #$ -q *@@crc_d32cepyc To see all available host groups, you can use the -shgrpl flag with qconf as seen below. Note that you will not be able to run jobs on all host groups, only on those which are a part of your research group / groups you have been granted access to. qconf -shgrpl","title":"Host Groups"},{"location":"crc_infra/crc_uge_env/#user-groups","text":"User groups allow for the designation resource access to specific individuals. This is most often utilized for faculty or group owned resources accessible through the Grid Engine like host groups as explained above. Users do not need to specify their user group as this is automatically determined by user ID. Users must however make sure via their faculty adviser that their ID is in the user group. If it is not, have your PI / faculy advisor send an email to CRCSupport@nd.edu . To view all user lists, pass the -sul flag to qconf. qconf -sul","title":"User Groups"},{"location":"crc_infra/faculty_infrastructure/","text":"Faculty Cluster Partnership Program This general guidance is subject to frequent revision as the role of research computing at the University of Notre Dame evolves. The needs of the faculty, departments, and colleges along with the strategic goals of the university administration will continue to shape and redefine these guidelines. Further, factors external to this university such as directives from national funding agencies (DOE, NSF, DOD, NIH, etc..) will directly impact these guidelines. Purchasing Dedicated Servers If the general workflow of utilizing the CRC's general access resources works for your research group and there is a need for more computing resources (additional machines) or a desire to decrease queued job wait times, the Cluster Partnership Program may be the next step. With regards to the HPC equipment, the CRC provides engineering support and services in the form maintenance and system administration. For those wishing to purchase servers through the CRC, total department/college/university operating costs are reduced through centralized maintenance of these clusters when compared to in-house management or cloud infrastructure. Further, research groups optimize their investment by reducing spin-up time learning how to use the resources. More detailed information can be found within the CPP form under \"Policies\" on the CRC website . Bulk Purchasing When the CRC performs large purchases of equipment after retiring aging equipment, there may be opportunites to join the purchase at bulk prices. The CRC will always announce these opportunites through email to the CRC-Users email list. For any questions contact the CRC via email at CRCSupport@nd.edu . Grant Proposals Purchasing dedicated resources through grants is a common procedure to aquire CRC managed HPC resources. The full detailed explaination of the resource allocation policy, including a narrative for inserting into grants, can be found on the the CRC website within the Resource Allocation Policy document .","title":"Faculty Cluster Partnership Program"},{"location":"crc_infra/faculty_infrastructure/#faculty-cluster-partnership-program","text":"This general guidance is subject to frequent revision as the role of research computing at the University of Notre Dame evolves. The needs of the faculty, departments, and colleges along with the strategic goals of the university administration will continue to shape and redefine these guidelines. Further, factors external to this university such as directives from national funding agencies (DOE, NSF, DOD, NIH, etc..) will directly impact these guidelines.","title":"Faculty Cluster Partnership Program"},{"location":"crc_infra/faculty_infrastructure/#purchasing-dedicated-servers","text":"If the general workflow of utilizing the CRC's general access resources works for your research group and there is a need for more computing resources (additional machines) or a desire to decrease queued job wait times, the Cluster Partnership Program may be the next step. With regards to the HPC equipment, the CRC provides engineering support and services in the form maintenance and system administration. For those wishing to purchase servers through the CRC, total department/college/university operating costs are reduced through centralized maintenance of these clusters when compared to in-house management or cloud infrastructure. Further, research groups optimize their investment by reducing spin-up time learning how to use the resources. More detailed information can be found within the CPP form under \"Policies\" on the CRC website .","title":"Purchasing Dedicated Servers"},{"location":"crc_infra/faculty_infrastructure/#bulk-purchasing","text":"When the CRC performs large purchases of equipment after retiring aging equipment, there may be opportunites to join the purchase at bulk prices. The CRC will always announce these opportunites through email to the CRC-Users email list. For any questions contact the CRC via email at CRCSupport@nd.edu .","title":"Bulk Purchasing"},{"location":"crc_infra/faculty_infrastructure/#grant-proposals","text":"Purchasing dedicated resources through grants is a common procedure to aquire CRC managed HPC resources. The full detailed explaination of the resource allocation policy, including a narrative for inserting into grants, can be found on the the CRC website within the Resource Allocation Policy document .","title":"Grant Proposals"},{"location":"crc_infra/landing/","text":"Maintenance The CRC performs major renovations of physical infrastructure and software / module changes during two scheduled outages within each calendar year. These outages always occur first in January during the break between Fall and Spring semesters, and during the weekend of undergraduate graduation. All systems are unavailable during these maintenance periods including compute hosts. All UGE / HTCondor jobs are removed from queues and any jobs still running once a biannual maintenance period begins are removed. Typical Changes RHEL OS updates system GCC compiler updates system Python updates Server firmware / bios patches Core software updates / patches including: module command UGE HTCondor Module Changes Within each biannual maintenance, the collection of software modules follows a planned upgrade model. New modules may be added, modules added to the deprecated list in a previous maintenance period will be removed, and older modules will be added to the deprecated list to be removed during the next maintenance. The lifetime of a specific module depends on several factors such as the development cycle of the software, the security risk of the software, usage of the module, and other factors. The typical life of module XYZ is below: Created April 2019 --> Deprecated during January 2021 Maintenance --> Removed during May 2021 Maintenance More information on the module system can be found on the modules page. Reoccuring Maintenance The CRC reserves the right to perform maintenance and security patching on machines each Sunday morning from 2:00 am - 10:00 am EST. During this time front end machines may be unavailable. Past Maintenance Periods See the past maintenances <past-maintenances>","title":"Maintenance"},{"location":"crc_infra/landing/#maintenance","text":"The CRC performs major renovations of physical infrastructure and software / module changes during two scheduled outages within each calendar year. These outages always occur first in January during the break between Fall and Spring semesters, and during the weekend of undergraduate graduation. All systems are unavailable during these maintenance periods including compute hosts. All UGE / HTCondor jobs are removed from queues and any jobs still running once a biannual maintenance period begins are removed.","title":"Maintenance"},{"location":"crc_infra/landing/#typical-changes","text":"RHEL OS updates system GCC compiler updates system Python updates Server firmware / bios patches Core software updates / patches including: module command UGE HTCondor","title":"Typical Changes"},{"location":"crc_infra/landing/#module-changes","text":"Within each biannual maintenance, the collection of software modules follows a planned upgrade model. New modules may be added, modules added to the deprecated list in a previous maintenance period will be removed, and older modules will be added to the deprecated list to be removed during the next maintenance. The lifetime of a specific module depends on several factors such as the development cycle of the software, the security risk of the software, usage of the module, and other factors. The typical life of module XYZ is below: Created April 2019 --> Deprecated during January 2021 Maintenance --> Removed during May 2021 Maintenance More information on the module system can be found on the modules page.","title":"Module Changes"},{"location":"crc_infra/landing/#reoccuring-maintenance","text":"The CRC reserves the right to perform maintenance and security patching on machines each Sunday morning from 2:00 am - 10:00 am EST. During this time front end machines may be unavailable.","title":"Reoccuring Maintenance"},{"location":"crc_infra/landing/#past-maintenance-periods","text":"See the past maintenances <past-maintenances>","title":"Past Maintenance Periods"},{"location":"crc_infra/resources/","text":"CRC Resources The CRC provides access to both internal and external resources while housing and maintains its own HPC equipment with regular cycles of decommissioning older equipment and purchasing new equipment. Below you'll find information pertaining to both internal and external resources. Current Equipment available_hardware virtual_machines Network The CRC cooperates with and utilizes Internet2 testing_network_bandwidth ibm_q Systems Dashboard The following links will aid in monitoring the status and check information on various systems: Any non-green (alarm state) CRC machines https://mon.crc.nd.edu/xymon/nongreen.html Condor status http://condor.cse.nd.edu/condor_matrix.cgi Storage and server lookup Lookup individual storage and group storage usage by netID http://www.crc.nd.edu/info/storage.html Lookup specs on an individual server / host http://www.crc.nd.edu/info/srvspec.html","title":"CRC Resources"},{"location":"crc_infra/resources/#crc-resources","text":"The CRC provides access to both internal and external resources while housing and maintains its own HPC equipment with regular cycles of decommissioning older equipment and purchasing new equipment. Below you'll find information pertaining to both internal and external resources.","title":"CRC Resources"},{"location":"crc_infra/resources/#current-equipment","text":"available_hardware virtual_machines Network The CRC cooperates with and utilizes Internet2 testing_network_bandwidth ibm_q","title":"Current Equipment"},{"location":"crc_infra/resources/#systems-dashboard","text":"The following links will aid in monitoring the status and check information on various systems: Any non-green (alarm state) CRC machines https://mon.crc.nd.edu/xymon/nongreen.html Condor status http://condor.cse.nd.edu/condor_matrix.cgi","title":"Systems Dashboard"},{"location":"crc_infra/resources/#storage-and-server-lookup","text":"Lookup individual storage and group storage usage by netID http://www.crc.nd.edu/info/storage.html Lookup specs on an individual server / host http://www.crc.nd.edu/info/srvspec.html","title":"Storage and server lookup"},{"location":"crc_infra/software/","text":"CRC Software The CRC provides many precompiled and optimized pieces of software for general use by all users and hosts the license servers for many applications. For details on which pieces of software are available for use on CRC infrastructure, run module avail . More detail can be found on the modules page. Popular / highly utilized modules can be found on the toolbar to the left. If you have a specific piece of software in mind, try searching for it in the top left of the toolbar. Note that most software provided as a module by the CRC will have a limited lifetime. The typical lifetime for a module is typically segmented by maintenance periods (see maintenance-landing for more details). For example: A new Python module is created and released during January 2020 maintenance. During May 2020 maintenance this Python module is made the default. During May 2021 maintenance this Python module is moved to deprecated. A newer Python module takes its place as Default. January 2022 mainteance the example Python module is removed from service. User Requested Software Unfortunately we do not have the human resources at CRC to install individual user requested software applications that are not standard in the RHEL software stack or already part of the core CRC application stack. We would recommend that you try to install the software within your own local AFS space using the installation notes provided by the developers. If you run into serious issues during the installation which cannot be resolved through the documentation, user forums and direct contact with the developers, then please let us know and we will try to provide assistance based on our experience with building packages on our systems. Please see the CRC Software Policy document for further details.","title":"CRC Software"},{"location":"crc_infra/software/#crc-software","text":"The CRC provides many precompiled and optimized pieces of software for general use by all users and hosts the license servers for many applications. For details on which pieces of software are available for use on CRC infrastructure, run module avail . More detail can be found on the modules page. Popular / highly utilized modules can be found on the toolbar to the left. If you have a specific piece of software in mind, try searching for it in the top left of the toolbar. Note that most software provided as a module by the CRC will have a limited lifetime. The typical lifetime for a module is typically segmented by maintenance periods (see maintenance-landing for more details). For example: A new Python module is created and released during January 2020 maintenance. During May 2020 maintenance this Python module is made the default. During May 2021 maintenance this Python module is moved to deprecated. A newer Python module takes its place as Default. January 2022 mainteance the example Python module is removed from service.","title":"CRC Software"},{"location":"crc_infra/software/#user-requested-software","text":"Unfortunately we do not have the human resources at CRC to install individual user requested software applications that are not standard in the RHEL software stack or already part of the core CRC application stack. We would recommend that you try to install the software within your own local AFS space using the installation notes provided by the developers. If you run into serious issues during the installation which cannot be resolved through the documentation, user forums and direct contact with the developers, then please let us know and we will try to provide assistance based on our experience with building packages on our systems. Please see the CRC Software Policy document for further details.","title":"User Requested Software"},{"location":"crc_infra/storage/","text":"Storage All storage is allocated to users and attributed to their account sponsor (faculty advisor). To see the storage used by a particular faculty advisor simply type their ND ID into the storage reporting tool . AFS Storage The CRC's AFS cell consists of several different AFS servers. Both user home storage and research group storage space resides within the CRC AFS cell. Some note: All storage allocation is tracked per faculty sponsor. Default of 100 GB user space per account. This can be increased through request. Any amount higher than 500GB must be confirmed by the faculty sponsor of the account. AFS Limitations and Notes There are a few limitations to be aware of within AFS. A single directory can only contain a certain number of files. This number depends on the length of the filenames of each file within said directory. For example, ~32,000 is generally an average number of files which can be within a single directory. If filenames are long, this max number will be smaller. If you hit the maximum number of files within a single directory, you'll see an error such as: touch: cannot touch 'path/to/dir/file_name.txt': File too large A single volume within AFS can be at a maximum of 2 TB. Should you need more than 2 TB, multiple volumes will have to be created and any data will need to be split between multiple volumes. If you have a running job, you will not see the results of creation / deletion etc of files from your job until it completes. If you would like to see file updates in real time, see the synchronizing_files_afs page. AFS Group Storage Often research teams require a shared access storage space. The two primary considerations in this regard are understanding the file structure respective of quotas and the access list. We can mount volumes anywhere in the directory tree thus quotas only map to the volume mount point. In this example any file or subdirectory you place in directory researchgroupname will be part of the associated 2TB quota EXCEPT the dataset01 sub-directory which has a separate 2TB quota because it is the mount point of a new volume. Thus 10TB could be allocated as: /afs/crc.nd.edu/group/researchgroupname/dataset01 /afs/crc.nd.edu/group/researchgroupname/dataset02 /afs/crc.nd.edu/group/researchgroupname/dataset03 /afs/crc.nd.edu/group/researchgroupname/dataset04 with each dataset0X directory having 2TB of quota and the parent directory having capacity for 2TB of files in addition to the 4 dataset0X directories. AFS Website If you would like to obtain a CRC AFS website (e.g. crc.nd.edu/~NETID), please send a request for one to CRCSupport@nd.edu from your netID email address. You will also need to make sure that there is a folder with the name www within your CRC Home directory. [!WARNING] All websites within the CRC AFS webspace should be considered to be INSECURE and are world-readable. You should not place any sensitive or confidential material in your webspace. Anything placed in your webspace can be viewed by anyone in the world. AFS Permissions / ACLs AFS does not use normal POSIX file permissions. To manage access to your files / directories, you must apply ACLs (Access Control Lists). For details on single user ACLs and the creation of ACL groups (better for labs etc), see the user_acls . Panasas (scratch) Storage For high performance scratch space, the CRC utilizes Panasas ActiveStor. To obtain scratch space, please send a request to CRCSupport@nd.edu . Some important notes about scratch365: Your scratch directory is located at /scratch365/$USER . scratch365 is designed to be TEMPORARY storage space and it is very important that you understand this space is NOT BACKED UP . A failure in the scratch filesystem could result in permanent data loss. scratch365 is subject to a 365 day PURGE POLICY . Data older than 365 days will automatically BE DELETED from the filesystem. Important data and results that you wish to keep should be moved to AFS and/or downloaded to a local computer as soon possible. We recommend doing this at least once a week for files that are frequently updated. Panasas Best Practices The Panasas resource is shared among several hundred users. In order to minimize the impact of your simulations on others please try to follow these guidelines. We encourage you to reach out to us if you have any questions or concerns. Delete temporary or intermediate files that are not needed for future analysis. This also applies to data that can easily be regenerated. Avoid using --color options to ls and other similar programs when working in scratch. While color output can be very helpful, programs like ls that offer this option put extra load on the filesystem as each file in the directory must have its contents examined in order to determine the file type and other attributes. Many people set up aliases for ls and other commands to automatically include color options. When in doubt, use the full path like so: /bin/ls -l /scratch365/$USER Use the tar command to store large amounts of data as a single file. Panasas and other high performance file systems excel at storing large files, particularly in lieu of thousands (or millions) of small files. The tar command allows you to efficiently replace many files and directories with a single, combined file. # Create a tar file named mydata.tar and remove existing files after adding them to the .tar: tar --remove-files --verbose --create -f mydata.tar ./directory-with-lots-of-files other-file different-file # See the contents of an existing tar file: tar --list -f mydata.tar # To unpack a tar file named mydata.tar and then remove the existing tar file: tar --verbose --extract -f mydata.tar; rm -i mydata.tar Minimize the number of files in a single directory, preferably with no more than 5,000 files per directory. Many commands that work on files must parse the entire contents of a directory before the command is able to complete. This is usually a linear process, so the more files there are in a directory the longer and more resources the action will take. It is much more efficient to have 100 directories that contain 1,000 files each rather than a single directory with 100,000 files. If you must have thousands of files per directory, consider using the command tar to encapsulate them into a single file when they are not actively being used. When you are writing your own applications that include file I/O: Only open() and close() files a single time inside of your application and never inside of loops. Try to avoid using file I/O operations inside of operational for() or while() loops. If this is necessary, program your application to read and write your data in large chunks . Use local variables to store many values. It is much more efficient to read or write 10 operations of 2 megabytes each than 1,000 operations of 20 kilobytes each. Potentially make use of the local hard drive. Every compute node has a local hard drive in it with a writable folder located in /tmp. You may find that copying files to a unique directory in /tmp and running your program from there will improve performance of your job and/or reduce load on the Panasas. # Create a temporary directory on /tmp, do some work, copy the data out of /tmp, then remove the directory. MY_TEMP=$(mktemp -d) cp /scratch365/$USER/collection_of_small_files.tar \"$MY_TEMP\" # do work here cp /$MY_TEMP/results /scratch365/$USER /bin/rm -r $MY_TEMP Danger Note that the local hard drive, /tmp, typically only has a couple 100 GBs of available storage. Filling up the local hard drive will cause the server to crash, so it is important to use the space sparingly and remove any files that you create there. Local /tmp Space Every compute host has a local disk which contains the OS and a small amount of space available to users. This local disk will normally be faster for higher I/O bound jobs, in addition to relieving network congestion to the other networked file systems available. The amount of storage available on the local disk varies by which machine the job is running on. Some note: Local disk is mounted on /tmp . Anyone can use this area. File and directory access is controlled by normal Unix permissions. If you plan on using this space be sure to clean up after yourself. Be mindful of the amount of space used on /tmp , if it runs out the machine will crash. Storage Backups Backup in this context refers to an independent copy of user files regularly changing in either a distributed filesystem (AFS) or local filesystem on a dedicated research machine. This is an automated cyclic process where changing data is incrementally backed up (daily, weekly, monthly). Backups are only maintained for 3 months (not persistent). For backups, the CRC utilizes a SpectraLogic T950 system . Storage Comparison Below is a scrollable comparison between the different storage options within the CRC. [TABLE]","title":"Storage"},{"location":"crc_infra/storage/#storage","text":"All storage is allocated to users and attributed to their account sponsor (faculty advisor). To see the storage used by a particular faculty advisor simply type their ND ID into the storage reporting tool .","title":"Storage"},{"location":"crc_infra/storage/#afs-storage","text":"The CRC's AFS cell consists of several different AFS servers. Both user home storage and research group storage space resides within the CRC AFS cell. Some note: All storage allocation is tracked per faculty sponsor. Default of 100 GB user space per account. This can be increased through request. Any amount higher than 500GB must be confirmed by the faculty sponsor of the account.","title":"AFS Storage"},{"location":"crc_infra/storage/#afs-limitations-and-notes","text":"There are a few limitations to be aware of within AFS. A single directory can only contain a certain number of files. This number depends on the length of the filenames of each file within said directory. For example, ~32,000 is generally an average number of files which can be within a single directory. If filenames are long, this max number will be smaller. If you hit the maximum number of files within a single directory, you'll see an error such as: touch: cannot touch 'path/to/dir/file_name.txt': File too large A single volume within AFS can be at a maximum of 2 TB. Should you need more than 2 TB, multiple volumes will have to be created and any data will need to be split between multiple volumes. If you have a running job, you will not see the results of creation / deletion etc of files from your job until it completes. If you would like to see file updates in real time, see the synchronizing_files_afs page.","title":"AFS Limitations and Notes"},{"location":"crc_infra/storage/#afs-group-storage","text":"Often research teams require a shared access storage space. The two primary considerations in this regard are understanding the file structure respective of quotas and the access list. We can mount volumes anywhere in the directory tree thus quotas only map to the volume mount point. In this example any file or subdirectory you place in directory researchgroupname will be part of the associated 2TB quota EXCEPT the dataset01 sub-directory which has a separate 2TB quota because it is the mount point of a new volume. Thus 10TB could be allocated as: /afs/crc.nd.edu/group/researchgroupname/dataset01 /afs/crc.nd.edu/group/researchgroupname/dataset02 /afs/crc.nd.edu/group/researchgroupname/dataset03 /afs/crc.nd.edu/group/researchgroupname/dataset04 with each dataset0X directory having 2TB of quota and the parent directory having capacity for 2TB of files in addition to the 4 dataset0X directories.","title":"AFS Group Storage"},{"location":"crc_infra/storage/#afs-website","text":"If you would like to obtain a CRC AFS website (e.g. crc.nd.edu/~NETID), please send a request for one to CRCSupport@nd.edu from your netID email address. You will also need to make sure that there is a folder with the name www within your CRC Home directory. [!WARNING] All websites within the CRC AFS webspace should be considered to be INSECURE and are world-readable. You should not place any sensitive or confidential material in your webspace. Anything placed in your webspace can be viewed by anyone in the world.","title":"AFS Website"},{"location":"crc_infra/storage/#afs-permissions-acls","text":"AFS does not use normal POSIX file permissions. To manage access to your files / directories, you must apply ACLs (Access Control Lists). For details on single user ACLs and the creation of ACL groups (better for labs etc), see the user_acls .","title":"AFS Permissions / ACLs"},{"location":"crc_infra/storage/#panasas-scratch-storage","text":"For high performance scratch space, the CRC utilizes Panasas ActiveStor. To obtain scratch space, please send a request to CRCSupport@nd.edu . Some important notes about scratch365: Your scratch directory is located at /scratch365/$USER . scratch365 is designed to be TEMPORARY storage space and it is very important that you understand this space is NOT BACKED UP . A failure in the scratch filesystem could result in permanent data loss. scratch365 is subject to a 365 day PURGE POLICY . Data older than 365 days will automatically BE DELETED from the filesystem. Important data and results that you wish to keep should be moved to AFS and/or downloaded to a local computer as soon possible. We recommend doing this at least once a week for files that are frequently updated.","title":"Panasas (scratch) Storage"},{"location":"crc_infra/storage/#panasas-best-practices","text":"The Panasas resource is shared among several hundred users. In order to minimize the impact of your simulations on others please try to follow these guidelines. We encourage you to reach out to us if you have any questions or concerns. Delete temporary or intermediate files that are not needed for future analysis. This also applies to data that can easily be regenerated. Avoid using --color options to ls and other similar programs when working in scratch. While color output can be very helpful, programs like ls that offer this option put extra load on the filesystem as each file in the directory must have its contents examined in order to determine the file type and other attributes. Many people set up aliases for ls and other commands to automatically include color options. When in doubt, use the full path like so: /bin/ls -l /scratch365/$USER Use the tar command to store large amounts of data as a single file. Panasas and other high performance file systems excel at storing large files, particularly in lieu of thousands (or millions) of small files. The tar command allows you to efficiently replace many files and directories with a single, combined file. # Create a tar file named mydata.tar and remove existing files after adding them to the .tar: tar --remove-files --verbose --create -f mydata.tar ./directory-with-lots-of-files other-file different-file # See the contents of an existing tar file: tar --list -f mydata.tar # To unpack a tar file named mydata.tar and then remove the existing tar file: tar --verbose --extract -f mydata.tar; rm -i mydata.tar Minimize the number of files in a single directory, preferably with no more than 5,000 files per directory. Many commands that work on files must parse the entire contents of a directory before the command is able to complete. This is usually a linear process, so the more files there are in a directory the longer and more resources the action will take. It is much more efficient to have 100 directories that contain 1,000 files each rather than a single directory with 100,000 files. If you must have thousands of files per directory, consider using the command tar to encapsulate them into a single file when they are not actively being used. When you are writing your own applications that include file I/O: Only open() and close() files a single time inside of your application and never inside of loops. Try to avoid using file I/O operations inside of operational for() or while() loops. If this is necessary, program your application to read and write your data in large chunks . Use local variables to store many values. It is much more efficient to read or write 10 operations of 2 megabytes each than 1,000 operations of 20 kilobytes each. Potentially make use of the local hard drive. Every compute node has a local hard drive in it with a writable folder located in /tmp. You may find that copying files to a unique directory in /tmp and running your program from there will improve performance of your job and/or reduce load on the Panasas. # Create a temporary directory on /tmp, do some work, copy the data out of /tmp, then remove the directory. MY_TEMP=$(mktemp -d) cp /scratch365/$USER/collection_of_small_files.tar \"$MY_TEMP\" # do work here cp /$MY_TEMP/results /scratch365/$USER /bin/rm -r $MY_TEMP Danger Note that the local hard drive, /tmp, typically only has a couple 100 GBs of available storage. Filling up the local hard drive will cause the server to crash, so it is important to use the space sparingly and remove any files that you create there.","title":"Panasas Best Practices"},{"location":"crc_infra/storage/#local-tmp-space","text":"Every compute host has a local disk which contains the OS and a small amount of space available to users. This local disk will normally be faster for higher I/O bound jobs, in addition to relieving network congestion to the other networked file systems available. The amount of storage available on the local disk varies by which machine the job is running on. Some note: Local disk is mounted on /tmp . Anyone can use this area. File and directory access is controlled by normal Unix permissions. If you plan on using this space be sure to clean up after yourself. Be mindful of the amount of space used on /tmp , if it runs out the machine will crash.","title":"Local /tmp Space"},{"location":"crc_infra/storage/#storage-backups","text":"Backup in this context refers to an independent copy of user files regularly changing in either a distributed filesystem (AFS) or local filesystem on a dedicated research machine. This is an automated cyclic process where changing data is incrementally backed up (daily, weekly, monthly). Backups are only maintained for 3 months (not persistent). For backups, the CRC utilizes a SpectraLogic T950 system .","title":"Storage Backups"},{"location":"crc_infra/storage/#storage-comparison","text":"Below is a scrollable comparison between the different storage options within the CRC. [TABLE]","title":"Storage Comparison"},{"location":"help/faq/","text":"FAQ Below is a collection of frequently asked questions. CRC Accounts How Do I Request a CRC Account? The easiest way to request a new account is to fill out the CRC Account Request Form . After we create your account, you will receive an email with further instructions and additional information on synchronizing your password with the rest of campus. Please be sure to read and follow the instructions carefully. Also note that a 1 hour introductory course is a co-requisite. How Do I Find Some Quick Start Information? Consult the quick-start-guide for advice on getting started with CRC resources quickly. I Can't Login (New User / First Time Login) Your password for logging into CRC resources is your standard ND account password. HOWEVER, when you first obtain an account you need to login to okta.nd.edu (as instructed by the CRC Welcome email). If needed, you can reset your password here . I've Forgotten My Password Your CRC password is your standard Notre Dame account password. If your account has just been created, you will need to wait 1 hour before logging into Okta: Okta Login This will synchronize your Notre Dame and CRC accounts. If you are still having difficulties, please email crcsupport@nd.edu . How Do I Request an Account for an External Collaborator? A faculty member may request an affiliate account for an external collaborator via this form: Requesting NetID Access for Affiliates You may need to login to see the form. All questions regarding the Affiliate are for your collaborator's information. You may ignore or select No on questions regarding Departmental Access. If the form is not visible, it can be searched for in the search bar. This will bring you to the form where you may enter in the information. Note that you will need the individual's date of birth and their NDID#. The latter may be obtained by calling Human Resources. If the applicant has never had a Notre Dame account, you may place zeros in the form. How Can I Maintain My CRC Account After Graduating/Leaving Notre Dame? [!NOTE] The university disables staff accounts on the final day of employment, while graduating student accounts are disabled at the conclusion of the current semester. If you have research related to work here at Notre Dame and are able to justify continued access, you may request a faculty member sponsor your account as an external affiliate. These accounts are valid for up to one year, but may be renewed annualy. This process can be initiated by having your sponsor complete an external account request <Request External Account> . To avoid losing your CRC account and all associated data, please complete this process prior to your account being disabled. I am Getting A \"Module: Command Not Found\" Message When I Log In To My CRC Account This message generally indicates that you have deleted/corrupted your shell configuration scripts which prevent the Module environment from initializing correctly. To repair your scripts please see the login_scripts page for instructions. Remote Access Why Is My Remote Connection So Slow? Slow remote GUI response time is actually quite difficult to troubleshoot. First because slow in this regard does not have a fully tangible metric In this case slow means it is impractical for you to work with Secondly because it varies on numerous conditions: OS and Graphics card/drivers on your system Remote visualization client (remote GUI) Network reliability (on campus wired is usually pretty good) Load (CPU, RAM, Network, Disk I/O) on the machine you are trying to access For the first two you need laptop/desktop support which is provided by your department/college IT support folks. For the third you can verify if you are getting at least 100Mbps consistently: ndt speedtest For the fourth you can monitor the load on CRC machines here: https://mon.crc.nd.edu/xymon When I try to login I see the error: \"Algorithm Negotiation Failed\", what does this mean? The CRC systems only accept connections from an updated form of encryption, therefore if you are using an older ssh client you may see this error. To solve this issue, first try updating your OS or current ssh client. If you are connecting from Windows, we recommend mobaxterm . If you are connecting from an older Mac Os system which cannot be updated, you can still connect to CRC systems by first connecting to jumpbox.nd.edu . If you continue to have login issues, contact CRC Support. When I try to connect CRC through VSCode, why does Remote SSH keep asking for password again and again? This happens because, after your first ssh (through the plugin within VSCode) it creates a lock file inside the folder ~/.vscode-server/ within your CRC account and that prevents your subsequent ssh. To resolve this, in your ssh extension settings, you would need to check the option for \"Lockfiles In Tmp\". You can find this option in the menu-bar following: Code -> Preferences -> Extensions -> Extension settings - located inside the circular-shaped 'code engine' -> Turn-on the box for \"Lockfiles In Tmp\" Training How Do I Receive Training? CRC User Support conducts introductory training for new users all year round. Periodically throughout the year, CRC organizes scheduled training classes (typically at the beginning of Fall and Spring semesters). These classes are announced on the new-user-training page. Outside of the scheduled training classes, training is provided on-demand by CRC User Support staff. Please send an email to crcsupport@nd.edu to arrange a training session. CRC Software What Software Is Available At The CRC? The CRC organizes installed software as modules . More information can be found on the modules page. How Do I Request Help Installing Software? Many software packages can be installed in your local home directory and we're happy to assist with this process. Please email crcsupport@nd.edu with your request and include any information you have about obtaining the installation package for the software you are interested in. How Do I Request A Software Module To Be Installed/Updated? Software that is installed globally through our modules tool must undergo license review by the Notre Dame legal department. For this reason, all requests to add a new module must come from Notre Dame faculty. Please submit a Software Request Form and review the attached CRC Software Policy. The software policy also contains information on licensing and cost sharing with CRC. [!NOTE] This process can take up to 7 business days from receipt of the software request. If you require an expedited service, please make that apparent on your request form. Notes on sudo/root access Many websites will give instructions for installing software that uses a command called sudo . This command gives the user full adminstrator privileges and along with it the ability to make system wide changes, including altering other user's files. On a personal computer this is rarely a problem, but our systems are shared among more than 2000 students and staff. Attempting to run the sudo command will result in a message be sent to CRC staff so that we might help you find an alternate solution. AFS Storage How Do I Check My Available AFS Storage? You can check your AFS disk usage with the ''quota'' command e.g. quota How Do I Request More AFS Storage Space? Please consult the CRC Storage policy for rules and limitations for user/group storage quotas. When requesting a storage increase please email crcsupport@nd.edu with the following information: Name Name of PI Brief Justification for Increase How Do I Give A Particular User/Group Access To A Directory In My Personal AFS Space? For instructions, see user_acls . I Am Receiving A \"Locking Authority File\" Error If you receive the following error: > /usr/bin/xauth: error in locking authority file /afs/crc.nd.edu/user... you have most likely exhausted your AFS storage quota. Please delete unwanted files and/or request more storage space. How Do I Add and Remove Users From The Shared Group Space I Administer? To add a user use the following AFS command: pts adduser netid group To remove a user use the following AFS command: pts removeuser netid group I'm Not Seeing My Output When Running From AFS! AFS improves I/O performance by caching program output on the local host. The output data is only written to the file server when the program is complete. To overcome this issue, you should add the ''fsync'' command to your submission script. Please see the following wiki page for more details: synchronizing_files_afs I Am Getting The Following Message Using Find > find ./ -type d -print find: WARNING: Hard link count is wrong for .: this may be a bug in your file system driver. Use the -noleaf option when using the find command: -noleaf Do not optimize by assuming that directories contain 2 fewer subdirectories than their hard link count. This option is needed when searching file systems that do not follow the Unix directory-link convention, such as CD-ROM or MS-DOS file systems or AFS volume mount points. So use the following command instead: find ./ -noleaf -type d -print PANASAS Storage (/scratch365) How Do I Check My Available (/scratch365) Storage? You can check your /scratch365 disk usage with the ''pan_df'' command e.g. pan_df -H /scratch365/netid/ How Do I Request More (/scratch365) Storage Space? Please consult the CRC Storage policy for rules and limitations for user/group storage quotas. When requesting a storage increase please email crcsupport@nd.edu with the following information: ''Name'' ''Name of PI'' ''Brief Justification for Increase'' Jobs My Job Is Aborted At Runtime Due To Excessive Disk-Swapping If your job is aborted at runtime due to disk-swapping, this typically indicates that your simulation is starved of RAM at runtime. A general rule of thumb is to ensure that you \\<font color=red>request 1 core for every 2 GB of RAM\\</font> your simulation requires e.g. if your simulation requires 16GB of RAM in total, then you need to request 8 cores in your UGE submission script (either -pe smp 16 or -pe mpi-16 16), irrespective of whether your simulation actually uses 8 cores. This ensures that 8 cores (and potentially 16GB RAM) are assigned to your job and not accessible by other users. If unsure how much RAM your job will require, you can use the Xymon Memory Monitoring tool to see how much RAM your job is using. The Xymon Memory Monitoring tool contains two graphs. The graphs corresponds to the '''Physical/Real''' memory and the '''Actual''' memory. In memory management, no actual memory is being set aside whenever a process requests memory, but the memory management unit knows the process is planning on using the memory it requested. This will allow the memory management unit to use the unused memory for other purposes such as caching other data. The '''Physical/Real''' memory represents the amount of RAM the process requested. After the process begins writing to RAM, the memory management unit will begins giving '''actual''' memory to the process so it can write. If the RAM is being occupied by other data, that data is flushed so it can be used by the process. The RAM that the process is actually using represents the '''Actual''' memory graph. So in summary, there should not be a problem if your job's '''Actual''' graph never reaches the '''Physical/Real''' graph. If it does, that means the machine has run out of RAM for your job and that will cause the system to use the '''Hard Disk''' to read/write data. This can cause your job to take longer than expected as well as potentially crash the system your job is running on if it is excessively reading/writing to disk. Do Different Operating System Versions Affect Performance? Each machine uses a version of Red Hat Enterprise Linux, which has various versions available. These different Red Hat builds can have a slight impact on performance. According to multiple HPL trials run on machine dqcneh014 using a constant N, it appears that RHEL version 7.1 has the slowest performance, while RHEL version 7.2 has a slightly faster performance than the other versions. Other Red Hat versions tested include 6.4, 6.6, and 6.7. The complete data for this test, and for the test in 7.2, can be found in the following Google Doc: https://docs.google.com/spreadsheets/d/19c2if441JywnQy4N8-NhMAwDFkmCwzY275hc7vYg9g4/edit?usp=sharing Unable to run job: error: no suitable queues' Message When Submitting Job Script By default, UGE applies strict validation of resource requests within your submission script including checks for legal queue names and core counts that match valid parallel environments (pe). These checks are very useful in preventing erroneous jobs entering the batch system and immediately falling into (Eqw) error states. If an invalid resource request is identified by this validation procedure, your submission script will be rejected immediately with the \"Unable to run job:\" error message. For example the mpi-8 machines (machines with 8 cores) are either faculty owned (restricted) or on a restricted access list for codes which require an Infiniband interconnect. Standard user scripts will fail when specifying mpi-8. In the case the user should use mpi-12 as the majority of systems available for general access are 12 core machines. [!NOTE] Scripts that contain the '''mem_free=''' resource request i.e. #\\$ -l mem_free=X will unfortunately always fail the validation test (due to lack of memory information at the time the validation is undertaken). To overcome this situation, please disable the validation process in your submission script by adding the following line: #\\$ -w n How Can I Monitor The Behavior Of My Running Jobs? The behavior of running jobs can monitored using the \\<font color=red>Xymon\\</font> online tool. After using qstat to identify the server(s) on which your jobs are running, use the Xymon link below to locate the specific server name. Associated with each server is a series of sub-links that you can use to monitor CPU status, memory usage, communication statistics etc. CRC Xymon My Job Has Created Zombies...What Does That Mean? Zombie Processes are processes that still remain running even though your job has terminated within the Grid Engine batch system. There are various reasons why this happens including ungraceful termination of MPI due to either software or hardware issues. The CRC runs a script that runs periodically to remove these zombie processes from our systems. If zombie processes are detected during the running of this script, due to one of your jobs, you will be notified via email. If you continue to receive zombie notifications regularly please contact CRC Support for assistance in detecting the cause. Applications Xquartz gives me a failed request error: X Error of failed request: BadValue (integer parameter out of range for operation) Major opcode of failed request: 149 (GLX) Minor opcode of failed request: 24 (X_GLXCreateNewContext) Value in failed request: 0x0 Serial number of failed request: 20 Current serial number in output stream: 21 Open a terminal and enter the following command: defaults write org.macosforge.xquartz.X11 enable_iglx -bool true You will need to restart your Mac. I Need To Install ArcGIS On My System All GIS software installation and GIS desktop support for the Colleges of Science and Engineering will be handled by Engineering and Science Computing support. You can get the desktop support team contact info for the Colleges of Science and Engineering from the ESC website or send email at help@esc.nd.edu . I am trying to compile my code with mvapich2 but cannot find -lpsm_infinipath Please compile your code on crcfeib01.crc.nd.edu . I See Incomplete Images In COMSOL v4+ The OpenGL graphics libraries on our machines are not compatible with the latest versions of Comsol v4+. This results in distortion or incompleteness of rendered images. To overcome this issue please set your COMSOL graphics configuration to use ''software rendering'' via the following menu option: Option -> Preferences > Graphics > Rendering >Software My Gaussian Jobs Are Being Aborted Due To /tmp Over-usage By default GAUSSIAN jobs write temporary working data to the /tmp directory of the compute node. For large GAUSSIAN jobs this /tmp space can fill very quickly causing the machine to slowdown/crash ( note: machine supervisors may pre-empt machine crashes by killing your jobs). To avoid this situation please direct GAUSSIAN to write temporary working files to your own storage allocation (either AFS or /scratch365). Details on how to set this up in your GAUSSIAN scripts can be found here <gaussian_scratch_space> . Request of ArcGIS Installation and Support All GIS software installation and GIS desktop support for the Colleges of Science and Engineering will be handled by Engineering and Science Computing support. You can get the desktop support team contact info for the Colleges of Science and Engineering from the ESC website or send email at help@esc.nd.edu . Grants/Proposals How Do I Acknowledge the CRC In My Proposals? To acknowledge collaboration with the CRC, please add the following citation to your proposals: \"This research was supported in part by the Notre Dame Center for Research Computing through [CRC resources].\" \"[We specifically acknowledge the assistance of]\" Does The CRC Provide An Example Of A Data Management Plan? Please email crcsupport@nd.edu for more information including sample plans.","title":"FAQ"},{"location":"help/faq/#faq","text":"Below is a collection of frequently asked questions.","title":"FAQ"},{"location":"help/faq/#crc-accounts","text":"","title":"CRC Accounts"},{"location":"help/faq/#how-do-i-request-a-crc-account","text":"The easiest way to request a new account is to fill out the CRC Account Request Form . After we create your account, you will receive an email with further instructions and additional information on synchronizing your password with the rest of campus. Please be sure to read and follow the instructions carefully. Also note that a 1 hour introductory course is a co-requisite.","title":"How Do I Request a CRC Account?"},{"location":"help/faq/#how-do-i-find-some-quick-start-information","text":"Consult the quick-start-guide for advice on getting started with CRC resources quickly.","title":"How Do I Find Some Quick Start Information?"},{"location":"help/faq/#i-cant-login-new-user-first-time-login","text":"Your password for logging into CRC resources is your standard ND account password. HOWEVER, when you first obtain an account you need to login to okta.nd.edu (as instructed by the CRC Welcome email). If needed, you can reset your password here .","title":"I Can't Login (New User / First Time Login)"},{"location":"help/faq/#ive-forgotten-my-password","text":"Your CRC password is your standard Notre Dame account password. If your account has just been created, you will need to wait 1 hour before logging into Okta: Okta Login This will synchronize your Notre Dame and CRC accounts. If you are still having difficulties, please email crcsupport@nd.edu .","title":"I've Forgotten My Password"},{"location":"help/faq/#how-do-i-request-an-account-for-an-external-collaborator","text":"A faculty member may request an affiliate account for an external collaborator via this form: Requesting NetID Access for Affiliates You may need to login to see the form. All questions regarding the Affiliate are for your collaborator's information. You may ignore or select No on questions regarding Departmental Access. If the form is not visible, it can be searched for in the search bar. This will bring you to the form where you may enter in the information. Note that you will need the individual's date of birth and their NDID#. The latter may be obtained by calling Human Resources. If the applicant has never had a Notre Dame account, you may place zeros in the form.","title":"How Do I Request an Account for an External Collaborator?"},{"location":"help/faq/#how-can-i-maintain-my-crc-account-after-graduatingleaving-notre-dame","text":"[!NOTE] The university disables staff accounts on the final day of employment, while graduating student accounts are disabled at the conclusion of the current semester. If you have research related to work here at Notre Dame and are able to justify continued access, you may request a faculty member sponsor your account as an external affiliate. These accounts are valid for up to one year, but may be renewed annualy. This process can be initiated by having your sponsor complete an external account request <Request External Account> . To avoid losing your CRC account and all associated data, please complete this process prior to your account being disabled.","title":"How Can I Maintain My CRC Account After Graduating/Leaving Notre Dame?"},{"location":"help/faq/#i-am-getting-a-module-command-not-found-message-when-i-log-in-to-my-crc-account","text":"This message generally indicates that you have deleted/corrupted your shell configuration scripts which prevent the Module environment from initializing correctly. To repair your scripts please see the login_scripts page for instructions.","title":"I am Getting A \"Module: Command Not Found\" Message When I Log In To My CRC Account"},{"location":"help/faq/#remote-access","text":"","title":"Remote Access"},{"location":"help/faq/#why-is-my-remote-connection-so-slow","text":"Slow remote GUI response time is actually quite difficult to troubleshoot. First because slow in this regard does not have a fully tangible metric In this case slow means it is impractical for you to work with Secondly because it varies on numerous conditions: OS and Graphics card/drivers on your system Remote visualization client (remote GUI) Network reliability (on campus wired is usually pretty good) Load (CPU, RAM, Network, Disk I/O) on the machine you are trying to access For the first two you need laptop/desktop support which is provided by your department/college IT support folks. For the third you can verify if you are getting at least 100Mbps consistently: ndt speedtest For the fourth you can monitor the load on CRC machines here: https://mon.crc.nd.edu/xymon","title":"Why Is My Remote Connection So Slow?"},{"location":"help/faq/#when-i-try-to-login-i-see-the-error-algorithm-negotiation-failed-what-does-this-mean","text":"The CRC systems only accept connections from an updated form of encryption, therefore if you are using an older ssh client you may see this error. To solve this issue, first try updating your OS or current ssh client. If you are connecting from Windows, we recommend mobaxterm . If you are connecting from an older Mac Os system which cannot be updated, you can still connect to CRC systems by first connecting to jumpbox.nd.edu . If you continue to have login issues, contact CRC Support.","title":"When I try to login I see the error: \"Algorithm Negotiation Failed\", what does this mean?"},{"location":"help/faq/#when-i-try-to-connect-crc-through-vscode-why-does-remote-ssh-keep-asking-for-password-again-and-again","text":"This happens because, after your first ssh (through the plugin within VSCode) it creates a lock file inside the folder ~/.vscode-server/ within your CRC account and that prevents your subsequent ssh. To resolve this, in your ssh extension settings, you would need to check the option for \"Lockfiles In Tmp\". You can find this option in the menu-bar following: Code -> Preferences -> Extensions -> Extension settings - located inside the circular-shaped 'code engine' -> Turn-on the box for \"Lockfiles In Tmp\"","title":"When I try to connect CRC through VSCode, why does Remote SSH keep asking for password again and again?"},{"location":"help/faq/#training","text":"","title":"Training"},{"location":"help/faq/#how-do-i-receive-training","text":"CRC User Support conducts introductory training for new users all year round. Periodically throughout the year, CRC organizes scheduled training classes (typically at the beginning of Fall and Spring semesters). These classes are announced on the new-user-training page. Outside of the scheduled training classes, training is provided on-demand by CRC User Support staff. Please send an email to crcsupport@nd.edu to arrange a training session.","title":"How Do I Receive Training?"},{"location":"help/faq/#crc-software","text":"","title":"CRC Software"},{"location":"help/faq/#what-software-is-available-at-the-crc","text":"The CRC organizes installed software as modules . More information can be found on the modules page.","title":"What Software Is Available At The CRC?"},{"location":"help/faq/#how-do-i-request-help-installing-software","text":"Many software packages can be installed in your local home directory and we're happy to assist with this process. Please email crcsupport@nd.edu with your request and include any information you have about obtaining the installation package for the software you are interested in.","title":"How Do I Request Help Installing Software?"},{"location":"help/faq/#how-do-i-request-a-software-module-to-be-installedupdated","text":"Software that is installed globally through our modules tool must undergo license review by the Notre Dame legal department. For this reason, all requests to add a new module must come from Notre Dame faculty. Please submit a Software Request Form and review the attached CRC Software Policy. The software policy also contains information on licensing and cost sharing with CRC. [!NOTE] This process can take up to 7 business days from receipt of the software request. If you require an expedited service, please make that apparent on your request form.","title":"How Do I Request A Software Module To Be Installed/Updated?"},{"location":"help/faq/#notes-on-sudoroot-access","text":"Many websites will give instructions for installing software that uses a command called sudo . This command gives the user full adminstrator privileges and along with it the ability to make system wide changes, including altering other user's files. On a personal computer this is rarely a problem, but our systems are shared among more than 2000 students and staff. Attempting to run the sudo command will result in a message be sent to CRC staff so that we might help you find an alternate solution.","title":"Notes on sudo/root access"},{"location":"help/faq/#afs-storage","text":"","title":"AFS Storage"},{"location":"help/faq/#how-do-i-check-my-available-afs-storage","text":"You can check your AFS disk usage with the ''quota'' command e.g. quota","title":"How Do I Check My Available AFS Storage?"},{"location":"help/faq/#how-do-i-request-more-afs-storage-space","text":"Please consult the CRC Storage policy for rules and limitations for user/group storage quotas. When requesting a storage increase please email crcsupport@nd.edu with the following information: Name Name of PI Brief Justification for Increase","title":"How Do I Request More AFS Storage Space?"},{"location":"help/faq/#how-do-i-give-a-particular-usergroup-access-to-a-directory-in-my-personal-afs-space","text":"For instructions, see user_acls .","title":"How Do I Give A Particular User/Group Access To A Directory In My Personal AFS Space?"},{"location":"help/faq/#i-am-receiving-a-locking-authority-file-error","text":"If you receive the following error: > /usr/bin/xauth: error in locking authority file /afs/crc.nd.edu/user... you have most likely exhausted your AFS storage quota. Please delete unwanted files and/or request more storage space.","title":"I Am Receiving A \"Locking Authority File\" Error"},{"location":"help/faq/#how-do-i-add-and-remove-users-from-the-shared-group-space-i-administer","text":"To add a user use the following AFS command: pts adduser netid group To remove a user use the following AFS command: pts removeuser netid group","title":"How Do I Add and Remove Users From The Shared Group Space I Administer?"},{"location":"help/faq/#im-not-seeing-my-output-when-running-from-afs","text":"AFS improves I/O performance by caching program output on the local host. The output data is only written to the file server when the program is complete. To overcome this issue, you should add the ''fsync'' command to your submission script. Please see the following wiki page for more details: synchronizing_files_afs","title":"I'm Not Seeing My Output When Running From AFS!"},{"location":"help/faq/#i-am-getting-the-following-message-using-find","text":"> find ./ -type d -print find: WARNING: Hard link count is wrong for .: this may be a bug in your file system driver. Use the -noleaf option when using the find command: -noleaf Do not optimize by assuming that directories contain 2 fewer subdirectories than their hard link count. This option is needed when searching file systems that do not follow the Unix directory-link convention, such as CD-ROM or MS-DOS file systems or AFS volume mount points. So use the following command instead: find ./ -noleaf -type d -print","title":"I Am Getting The Following Message Using Find"},{"location":"help/faq/#panasas-storage-scratch365","text":"","title":"PANASAS Storage (/scratch365)"},{"location":"help/faq/#how-do-i-check-my-available-scratch365-storage","text":"You can check your /scratch365 disk usage with the ''pan_df'' command e.g. pan_df -H /scratch365/netid/","title":"How Do I Check My Available (/scratch365) Storage?"},{"location":"help/faq/#how-do-i-request-more-scratch365-storage-space","text":"Please consult the CRC Storage policy for rules and limitations for user/group storage quotas. When requesting a storage increase please email crcsupport@nd.edu with the following information: ''Name'' ''Name of PI'' ''Brief Justification for Increase''","title":"How Do I Request More (/scratch365) Storage Space?"},{"location":"help/faq/#jobs","text":"","title":"Jobs"},{"location":"help/faq/#my-job-is-aborted-at-runtime-due-to-excessive-disk-swapping","text":"If your job is aborted at runtime due to disk-swapping, this typically indicates that your simulation is starved of RAM at runtime. A general rule of thumb is to ensure that you \\<font color=red>request 1 core for every 2 GB of RAM\\</font> your simulation requires e.g. if your simulation requires 16GB of RAM in total, then you need to request 8 cores in your UGE submission script (either -pe smp 16 or -pe mpi-16 16), irrespective of whether your simulation actually uses 8 cores. This ensures that 8 cores (and potentially 16GB RAM) are assigned to your job and not accessible by other users. If unsure how much RAM your job will require, you can use the Xymon Memory Monitoring tool to see how much RAM your job is using. The Xymon Memory Monitoring tool contains two graphs. The graphs corresponds to the '''Physical/Real''' memory and the '''Actual''' memory. In memory management, no actual memory is being set aside whenever a process requests memory, but the memory management unit knows the process is planning on using the memory it requested. This will allow the memory management unit to use the unused memory for other purposes such as caching other data. The '''Physical/Real''' memory represents the amount of RAM the process requested. After the process begins writing to RAM, the memory management unit will begins giving '''actual''' memory to the process so it can write. If the RAM is being occupied by other data, that data is flushed so it can be used by the process. The RAM that the process is actually using represents the '''Actual''' memory graph. So in summary, there should not be a problem if your job's '''Actual''' graph never reaches the '''Physical/Real''' graph. If it does, that means the machine has run out of RAM for your job and that will cause the system to use the '''Hard Disk''' to read/write data. This can cause your job to take longer than expected as well as potentially crash the system your job is running on if it is excessively reading/writing to disk.","title":"My Job Is Aborted At Runtime Due To Excessive Disk-Swapping"},{"location":"help/faq/#do-different-operating-system-versions-affect-performance","text":"Each machine uses a version of Red Hat Enterprise Linux, which has various versions available. These different Red Hat builds can have a slight impact on performance. According to multiple HPL trials run on machine dqcneh014 using a constant N, it appears that RHEL version 7.1 has the slowest performance, while RHEL version 7.2 has a slightly faster performance than the other versions. Other Red Hat versions tested include 6.4, 6.6, and 6.7. The complete data for this test, and for the test in 7.2, can be found in the following Google Doc: https://docs.google.com/spreadsheets/d/19c2if441JywnQy4N8-NhMAwDFkmCwzY275hc7vYg9g4/edit?usp=sharing","title":"Do Different Operating System Versions Affect Performance?"},{"location":"help/faq/#unable-to-run-job-error-no-suitable-queues-message-when-submitting-job-script","text":"By default, UGE applies strict validation of resource requests within your submission script including checks for legal queue names and core counts that match valid parallel environments (pe). These checks are very useful in preventing erroneous jobs entering the batch system and immediately falling into (Eqw) error states. If an invalid resource request is identified by this validation procedure, your submission script will be rejected immediately with the \"Unable to run job:\" error message. For example the mpi-8 machines (machines with 8 cores) are either faculty owned (restricted) or on a restricted access list for codes which require an Infiniband interconnect. Standard user scripts will fail when specifying mpi-8. In the case the user should use mpi-12 as the majority of systems available for general access are 12 core machines. [!NOTE] Scripts that contain the '''mem_free=''' resource request i.e. #\\$ -l mem_free=X will unfortunately always fail the validation test (due to lack of memory information at the time the validation is undertaken). To overcome this situation, please disable the validation process in your submission script by adding the following line: #\\$ -w n","title":"Unable to run job: error: no suitable queues' Message When Submitting Job Script"},{"location":"help/faq/#how-can-i-monitor-the-behavior-of-my-running-jobs","text":"The behavior of running jobs can monitored using the \\<font color=red>Xymon\\</font> online tool. After using qstat to identify the server(s) on which your jobs are running, use the Xymon link below to locate the specific server name. Associated with each server is a series of sub-links that you can use to monitor CPU status, memory usage, communication statistics etc. CRC Xymon","title":"How Can I Monitor The Behavior Of My Running Jobs?"},{"location":"help/faq/#my-job-has-created-zombieswhat-does-that-mean","text":"Zombie Processes are processes that still remain running even though your job has terminated within the Grid Engine batch system. There are various reasons why this happens including ungraceful termination of MPI due to either software or hardware issues. The CRC runs a script that runs periodically to remove these zombie processes from our systems. If zombie processes are detected during the running of this script, due to one of your jobs, you will be notified via email. If you continue to receive zombie notifications regularly please contact CRC Support for assistance in detecting the cause.","title":"My Job Has Created Zombies...What Does That Mean?"},{"location":"help/faq/#applications","text":"","title":"Applications"},{"location":"help/faq/#xquartz-gives-me-a-failed-request-error","text":"X Error of failed request: BadValue (integer parameter out of range for operation) Major opcode of failed request: 149 (GLX) Minor opcode of failed request: 24 (X_GLXCreateNewContext) Value in failed request: 0x0 Serial number of failed request: 20 Current serial number in output stream: 21 Open a terminal and enter the following command: defaults write org.macosforge.xquartz.X11 enable_iglx -bool true You will need to restart your Mac.","title":"Xquartz gives me a failed request error:"},{"location":"help/faq/#i-need-to-install-arcgis-on-my-system","text":"All GIS software installation and GIS desktop support for the Colleges of Science and Engineering will be handled by Engineering and Science Computing support. You can get the desktop support team contact info for the Colleges of Science and Engineering from the ESC website or send email at help@esc.nd.edu .","title":"I Need To Install ArcGIS On My System"},{"location":"help/faq/#i-am-trying-to-compile-my-code-with-mvapich2-but-cannot-find-lpsm_infinipath","text":"Please compile your code on crcfeib01.crc.nd.edu .","title":"I am trying to compile my code with mvapich2 but cannot find -lpsm_infinipath"},{"location":"help/faq/#i-see-incomplete-images-in-comsol-v4","text":"The OpenGL graphics libraries on our machines are not compatible with the latest versions of Comsol v4+. This results in distortion or incompleteness of rendered images. To overcome this issue please set your COMSOL graphics configuration to use ''software rendering'' via the following menu option: Option -> Preferences > Graphics > Rendering >Software","title":"I See Incomplete Images In COMSOL v4+"},{"location":"help/faq/#my-gaussian-jobs-are-being-aborted-due-to-tmp-over-usage","text":"By default GAUSSIAN jobs write temporary working data to the /tmp directory of the compute node. For large GAUSSIAN jobs this /tmp space can fill very quickly causing the machine to slowdown/crash ( note: machine supervisors may pre-empt machine crashes by killing your jobs). To avoid this situation please direct GAUSSIAN to write temporary working files to your own storage allocation (either AFS or /scratch365). Details on how to set this up in your GAUSSIAN scripts can be found here <gaussian_scratch_space> .","title":"My Gaussian Jobs Are Being Aborted Due To /tmp Over-usage"},{"location":"help/faq/#request-of-arcgis-installation-and-support","text":"All GIS software installation and GIS desktop support for the Colleges of Science and Engineering will be handled by Engineering and Science Computing support. You can get the desktop support team contact info for the Colleges of Science and Engineering from the ESC website or send email at help@esc.nd.edu .","title":"Request of ArcGIS Installation and Support"},{"location":"help/faq/#grantsproposals","text":"","title":"Grants/Proposals"},{"location":"help/faq/#how-do-i-acknowledge-the-crc-in-my-proposals","text":"To acknowledge collaboration with the CRC, please add the following citation to your proposals: \"This research was supported in part by the Notre Dame Center for Research Computing through [CRC resources].\" \"[We specifically acknowledge the assistance of]\"","title":"How Do I Acknowledge the CRC In My Proposals?"},{"location":"help/faq/#does-the-crc-provide-an-example-of-a-data-management-plan","text":"Please email crcsupport@nd.edu for more information including sample plans.","title":"Does The CRC Provide An Example Of A Data Management Plan?"},{"location":"help/help/","text":"Getting Help Run into an issue or have a question related to the CRC's services / infrastructure? We're here to help! Having desktop, laptop, or workstation problems? Contact your department's IT staff member or ESC help@esc.nd.edu . Steps to Getting Help When you first come across an issue: Check the documentation on this site (if possible) regarding the piece of software you're using or the action you're trying to perform. You can search using the box in the upper left. Check the faq located on the left toolbar. Ensure all syntax within your job script and source code, CRC Staff cannot debug your source code for you. For python , try installing and using the pudb debugger. For C, C++, Python, Fortran, load the arm module and use ddt . Setting up an Appointment After exhausting the steps above, it's time to setup an appointment. The CRC User support staff offer walk in support and phone support, however it is best to schedule an appointment via email. This will ensure an engineer will be available to help you and have a chance to look over your issues beforehand. Send an email to crcsupport@nd.edu describing your issue. Include the path to any files you're using within AFS, including: Job script, any driver scripts, source code files, etc. For example: ~/research/program/stuff/ Include any error codes or messages you've seen. Include your availability for a meeting (preferred days/times). A User Support Engineer will respond and confirm an appointment time and location. User Support Location The User Support offices are located on the 8th floor of Flanner Hall. Proceed through two sets of doors to the right after leaving the elevators. There should be signs pointing you to User Support. Common meeting places are: 812 -- User Training room The central table within User Support office The cubicle of a User Support Engineer Training Opportunities The New User Training sessions will cover the basic topics of utilizing the CRC Resources. If you have not completed this course, please do so. You do not have to be a new user to register for the free training, if you'd like to refresh your memory on proper usage of the cluster you're more than welcome to register. Other training events which could prevent future issues can be found on the new-user-training page.","title":"Getting Help"},{"location":"help/help/#getting-help","text":"Run into an issue or have a question related to the CRC's services / infrastructure? We're here to help! Having desktop, laptop, or workstation problems? Contact your department's IT staff member or ESC help@esc.nd.edu .","title":"Getting Help"},{"location":"help/help/#steps-to-getting-help","text":"When you first come across an issue: Check the documentation on this site (if possible) regarding the piece of software you're using or the action you're trying to perform. You can search using the box in the upper left. Check the faq located on the left toolbar. Ensure all syntax within your job script and source code, CRC Staff cannot debug your source code for you. For python , try installing and using the pudb debugger. For C, C++, Python, Fortran, load the arm module and use ddt .","title":"Steps to Getting Help"},{"location":"help/help/#setting-up-an-appointment","text":"After exhausting the steps above, it's time to setup an appointment. The CRC User support staff offer walk in support and phone support, however it is best to schedule an appointment via email. This will ensure an engineer will be available to help you and have a chance to look over your issues beforehand. Send an email to crcsupport@nd.edu describing your issue. Include the path to any files you're using within AFS, including: Job script, any driver scripts, source code files, etc. For example: ~/research/program/stuff/ Include any error codes or messages you've seen. Include your availability for a meeting (preferred days/times). A User Support Engineer will respond and confirm an appointment time and location.","title":"Setting up an Appointment"},{"location":"help/help/#user-support-location","text":"The User Support offices are located on the 8th floor of Flanner Hall. Proceed through two sets of doors to the right after leaving the elevators. There should be signs pointing you to User Support. Common meeting places are: 812 -- User Training room The central table within User Support office The cubicle of a User Support Engineer","title":"User Support Location"},{"location":"help/help/#training-opportunities","text":"The New User Training sessions will cover the basic topics of utilizing the CRC Resources. If you have not completed this course, please do so. You do not have to be a new user to register for the free training, if you'd like to refresh your memory on proper usage of the cluster you're more than welcome to register. Other training events which could prevent future issues can be found on the new-user-training page.","title":"Training Opportunities"},{"location":"modules/conda/","text":"Conda General Description Conda is a popular package management system used in machine learning and artificial intelligence research. It is built as a part of Anaconda distribution and provides a useful alternative for the pip package manager. Conda allows users to create many different environments containing different packages without there being any overlap or crossover that may occur when using pip. Each environment may be customized to a specific program\u2019s needs and therefore allows for easy package management and access. Warning In order to use conda , you must be using bash as your shell. If you have an account created after May of 2018, your default shell is bash. To check your shell, type: echo $0 . If your shell is tcsh and you'd like it to be bash, email us at CRCSupport@nd.edu . Initial setup If you have never used Conda on the CRC before or want to start from scratch after removing any existing Conda files, you will likely need to first load the Conda module. After the initial configuration is setup, you will no longer need this step. module load conda conda init source ~/.bashrc module unload conda To verify that conda was successfully installed and to check the version of conda installed you may run the following. conda info Environment Management In Conda you are able to create multiple, unique environments. Each environment will be able to be filled with packages specifically suited for various different problems. To view what environments are already created you may run the following code. ''Note that there will already be a base environment installed.'' conda info --envs To add to this list of environments you may create a new environment by using the following conda create -n ENVNAME Keep in mind that environments will be installed by default into the envs directory in your conda directory. You can specify a different path if you would like with the --prefix= option. conda create --prefix=~/env_name After an environment is created it is essentially dormant until activated. When you activate you are jumping into that environment and therefore will then have access to all the packages associated with that environment. You may activate any of your environments using the following conda activate ENVNAME If this throws an error, try directly sourcing the activate script within the environments directory. source ~/env_name/bin/activate If you would like to jump out of your currently loaded environment you may use the following command to bring you back to the base environment. conda deactivate If you would like to create an exact copy of an environment you may use the following conda create -n nameofnewenvironment --clone nameoforiginalenvironment If you would like to delete an environment you may use the following. conda remove -n ENVNAME --all Package Management In each environment within conda you may load different packages into the environment. Each package is a different piece of software that you may find to be useful in solving whatever problem you may have. To view what packages may be available use the following command conda list If you are looking for a specific package simply use the following search command conda search PKGNAME The above search only searches among the default channel. However, if you would like to search across all channels then use the following anaconda search PKGNAME For more specific information about all of the package versions use the following conda search PKGNAME--info Once you have found the name of the package you want to install you may install use the following code to install it into an environment. conda install -n ENVNAME PKGNAME [!NOTE] If you omit the \u201c-n ENVNAME\u201d portion of code the package will be installed in your current environment. All installs must be executed in a specific conda environment, not the base environment. This means that (ENVNAME) must appear to the left of your [username]. This ensures that no base packages are uninstalled, for example pip or python.'' When you need to update one of your packages you may use the following update command. conda update PKGNAME If you need to update all of your packages in your currently loaded environment simply use the following conda --update-all If you would like to delete a package from your environment you may do so with the following uninstall command conda uninstall PKGNAME Python Management Many times when using conda for machine learning applications we will be using python. To look for the specific versions of python available for install use the following conda search -f python Once you have found the specific version of python you want to install you may use the following install command to specify which python you need. conda install -n ENVNAME python=3.4 To verify which version of python your current environment is using, use the following python --version Channel Management There are several main channels available for use in Anaconda. These include, anaconda, conda-forge, r, and bioconda. Each channel contains different packages that may be installed into your environment. None of these channels are more important than another, but instead are there for organization of packages. By default, all users are on the default channel. If there is a specific package that you are looking to install that is not available on this default channel, then you can search for that package on another channel. For example, the bioconda channel is a Conda channel that provides bioinformatic packages. If we wanted to switch to the bioconda channel and install a bioconda specific package we would do so using the following conda config --add channels bioconda conda config --set channel_priority strict When adding this channel using the \u201cadd\u201d command we are telling Conda to add the channel at the top, or highest priority of the channels accessible to our manager. The order of channels in your Conda matters due to the potential of channel collisions. To circumvent this issue and ensure that we do not encounter any channel collisions from duplicate packages we use the second line of code above. This ensures that all of the dependencies come from the bioconda channel as opposed to the default channel. If we wanted to set the priority back to our default channel we would have to edit the ~/.condarc file so that defaults is the first channel shown. The ~/.condarc file is only created upon creation of a new channel. channels: defaults bioconda Then we must run these lines of code in the command-line conda config --set channel_priority true conda update --all This will allow us to make changes to our default channel, without interfering with the previously made changes in the bioconda channel. We would recommend only using the default channel unless absolutely necessary, in order to ensure no channel collisions. If you only need one or two packages from another channel that may not exist in the default channel then you should use the following conda config --append channels bioconda This will push the bioconda channel to the bottom of the priority list, ensuring that there are no conflicts in dependencies with the default channel. Once the desired channel is installed we must use the following to install a package from that specific package conda install bioconda::PKGNAME Job Submission Using Conda Environments Since your environments are saved in a unique file path on your node all of the packages will already be installed in the referenced environment, allowing you to customize your environment before submitting your job. Once the job is submitted it will be referencing the packages in your environment, meaning that you don\u2019t need to redo any of your previous installations. To load your environment use the following code, keeping in mind that the first three lines are example job submission code. Everything after those initial three lines will be as if you are running the same code in your node. [!NOTE] Unlike many software packages at the CRC, you generally should never load the conda module in your job scripts or configuration files after the initial configuration is complete. #!/bin/bash #$ -q long #$ -pe smp 1 #$ -N jobname conda activate ENVNAME python3 example.py This will run your python code in the environment that you specify, allowing you access to whatever packages you have previously loaded. If you would like to run multiple jobs at once then you should refer to the submitting_batch_jobs page.","title":"Conda"},{"location":"modules/conda/#conda","text":"","title":"Conda"},{"location":"modules/conda/#general-description","text":"Conda is a popular package management system used in machine learning and artificial intelligence research. It is built as a part of Anaconda distribution and provides a useful alternative for the pip package manager. Conda allows users to create many different environments containing different packages without there being any overlap or crossover that may occur when using pip. Each environment may be customized to a specific program\u2019s needs and therefore allows for easy package management and access. Warning In order to use conda , you must be using bash as your shell. If you have an account created after May of 2018, your default shell is bash. To check your shell, type: echo $0 . If your shell is tcsh and you'd like it to be bash, email us at CRCSupport@nd.edu .","title":"General Description"},{"location":"modules/conda/#initial-setup","text":"If you have never used Conda on the CRC before or want to start from scratch after removing any existing Conda files, you will likely need to first load the Conda module. After the initial configuration is setup, you will no longer need this step. module load conda conda init source ~/.bashrc module unload conda To verify that conda was successfully installed and to check the version of conda installed you may run the following. conda info","title":"Initial setup"},{"location":"modules/conda/#environment-management","text":"In Conda you are able to create multiple, unique environments. Each environment will be able to be filled with packages specifically suited for various different problems. To view what environments are already created you may run the following code. ''Note that there will already be a base environment installed.'' conda info --envs To add to this list of environments you may create a new environment by using the following conda create -n ENVNAME Keep in mind that environments will be installed by default into the envs directory in your conda directory. You can specify a different path if you would like with the --prefix= option. conda create --prefix=~/env_name After an environment is created it is essentially dormant until activated. When you activate you are jumping into that environment and therefore will then have access to all the packages associated with that environment. You may activate any of your environments using the following conda activate ENVNAME If this throws an error, try directly sourcing the activate script within the environments directory. source ~/env_name/bin/activate If you would like to jump out of your currently loaded environment you may use the following command to bring you back to the base environment. conda deactivate If you would like to create an exact copy of an environment you may use the following conda create -n nameofnewenvironment --clone nameoforiginalenvironment If you would like to delete an environment you may use the following. conda remove -n ENVNAME --all","title":"Environment Management"},{"location":"modules/conda/#package-management","text":"In each environment within conda you may load different packages into the environment. Each package is a different piece of software that you may find to be useful in solving whatever problem you may have. To view what packages may be available use the following command conda list If you are looking for a specific package simply use the following search command conda search PKGNAME The above search only searches among the default channel. However, if you would like to search across all channels then use the following anaconda search PKGNAME For more specific information about all of the package versions use the following conda search PKGNAME--info Once you have found the name of the package you want to install you may install use the following code to install it into an environment. conda install -n ENVNAME PKGNAME [!NOTE] If you omit the \u201c-n ENVNAME\u201d portion of code the package will be installed in your current environment. All installs must be executed in a specific conda environment, not the base environment. This means that (ENVNAME) must appear to the left of your [username]. This ensures that no base packages are uninstalled, for example pip or python.'' When you need to update one of your packages you may use the following update command. conda update PKGNAME If you need to update all of your packages in your currently loaded environment simply use the following conda --update-all If you would like to delete a package from your environment you may do so with the following uninstall command conda uninstall PKGNAME","title":"Package Management"},{"location":"modules/conda/#python-management","text":"Many times when using conda for machine learning applications we will be using python. To look for the specific versions of python available for install use the following conda search -f python Once you have found the specific version of python you want to install you may use the following install command to specify which python you need. conda install -n ENVNAME python=3.4 To verify which version of python your current environment is using, use the following python --version","title":"Python Management"},{"location":"modules/conda/#channel-management","text":"There are several main channels available for use in Anaconda. These include, anaconda, conda-forge, r, and bioconda. Each channel contains different packages that may be installed into your environment. None of these channels are more important than another, but instead are there for organization of packages. By default, all users are on the default channel. If there is a specific package that you are looking to install that is not available on this default channel, then you can search for that package on another channel. For example, the bioconda channel is a Conda channel that provides bioinformatic packages. If we wanted to switch to the bioconda channel and install a bioconda specific package we would do so using the following conda config --add channels bioconda conda config --set channel_priority strict When adding this channel using the \u201cadd\u201d command we are telling Conda to add the channel at the top, or highest priority of the channels accessible to our manager. The order of channels in your Conda matters due to the potential of channel collisions. To circumvent this issue and ensure that we do not encounter any channel collisions from duplicate packages we use the second line of code above. This ensures that all of the dependencies come from the bioconda channel as opposed to the default channel. If we wanted to set the priority back to our default channel we would have to edit the ~/.condarc file so that defaults is the first channel shown. The ~/.condarc file is only created upon creation of a new channel. channels: defaults bioconda Then we must run these lines of code in the command-line conda config --set channel_priority true conda update --all This will allow us to make changes to our default channel, without interfering with the previously made changes in the bioconda channel. We would recommend only using the default channel unless absolutely necessary, in order to ensure no channel collisions. If you only need one or two packages from another channel that may not exist in the default channel then you should use the following conda config --append channels bioconda This will push the bioconda channel to the bottom of the priority list, ensuring that there are no conflicts in dependencies with the default channel. Once the desired channel is installed we must use the following to install a package from that specific package conda install bioconda::PKGNAME","title":"Channel Management"},{"location":"modules/conda/#job-submission-using-conda-environments","text":"Since your environments are saved in a unique file path on your node all of the packages will already be installed in the referenced environment, allowing you to customize your environment before submitting your job. Once the job is submitted it will be referencing the packages in your environment, meaning that you don\u2019t need to redo any of your previous installations. To load your environment use the following code, keeping in mind that the first three lines are example job submission code. Everything after those initial three lines will be as if you are running the same code in your node. [!NOTE] Unlike many software packages at the CRC, you generally should never load the conda module in your job scripts or configuration files after the initial configuration is complete. #!/bin/bash #$ -q long #$ -pe smp 1 #$ -N jobname conda activate ENVNAME python3 example.py This will run your python code in the environment that you specify, allowing you access to whatever packages you have previously loaded. If you would like to run multiple jobs at once then you should refer to the submitting_batch_jobs page.","title":"Job Submission Using Conda Environments"},{"location":"modules/matlab/","text":"Matlab MATLAB is a high-performance language for technical computing. It integrates computation, visualization, and programming in an easy-to-use interactive environment where problems and solutions are expressed in familiar mathematical notation. This high-level language and interactive environment enables you to perform computationally intensive tasks faster than with traditional programming languages such as C, C++, and Fortran. Toolboxes The Matlab Toolboxes licensed by ND changes each year based on user demand (measured by an annual survey). Faculty may also purchase toolbox licenses which were not centrally funded based on broad user demand. To see what toolboxes are currently available simply type ver in the Matlab Command Window. Submitting Single Core Jobs To submit a single core MATLAB job to CRC systems use the following template: #!/bin/bash #$ -q long #$ -pe smp 1 module load matlab matlab -singleCompThread -nodisplay -nosplash < your_file.m By default, recent versions of MATLAB will try to automatically multithread processing on all the cores available on a machine. If you are only requesting one core in your submission script, you need to invoke MATLAB with the -singleCompThread option (to avoid interfering with other user's running jobs): matlab -singleCompThread ... [!WARNING] If you request more than 1 core, maxNumCompThreads function should be used to control the maximum number of computational threads. For example, adding the following line in your Matlab code will limit the number of threads to the same number as that you entered for the -pe smp flag in your job script: maxNumCompThreads(str2num(getenv(\"NSLOTS\"))); Submitting Multicore Jobs To submit multicore MATLAB jobs (up to 24 cores with current CRC systems) using the PCT (Parallel Computing Toolbox), use the following template. Note that there are normally multiple versions of Matlab available, see the modules page for more information on how software is organized within the CRC. #!/bin/bash #$ -q long #$ -pe smp 12 export MATLABPATH=~/path/to/matlab_file cd ~/path/to/matlab_file module load matlab matlab -nodisplay -nosplash < matlab_file The matlab file above includes the command parpool('local',12) , allowing Matlab to use the 12 cores on the machine. Parallelization can also be accomplished using a parfor within your matlab file: parpool('local', 12); parfor i=1:N end % In Matlab 8.5 need to use \"delete(gcp('nocreate'))\" MATLAB and Array Jobs An example for combining MATLAB and job arrays is as follows: #!/bin/csh #$ -N testarray #$ -t 1-4:1 #$ -M afs_id@nd.edu #$ -m ae setenv MATLABPATH directory_path_to_your_files.m:other_user_contrib_directory_path matlab -nodisplay -nosplash -nojvm -r \"myFunction(${SGE_TASK_ID});exit\" The myfunction.m will receive respectively for each task 1,2,3 and 4 as an input parameter. Memory Profiling User can use the builtin MATLAB profiler to understand memory usage in your scripts. To enable memory profiling add the following line to your scripts: profile -memory on; License Information Matlab Parallel Computing Toolbox can be currently configured up to 64 cores (SMP) per simulation. We currently do not support a license for MATLAB Distributed Computing Tutorials and Training For more information, please visit the official Matlab training page for a wealth of video tutorials and training content. Known issue with parpool and matlabpool There is a known issue when submitting multiple jobs that use either of the Matlab pool commands. Basically, if more than one task is started close to another task, they may both try and write to the same temporary file and cause problems. One solution involves changing the name of the default file Matlab writes pool information to as described in this link: Matlab Pool Solution . Dynare Support Looking to use Matlab with dynare ? Simply load the dynare module, this will automatically bring in all dependencies. You can check which versions of dynare are available with: module avail dynare Further Information See the official site: MATLAB Default help files for version \"X.Y\" (replace X and Y with desired version) may be found at: /afs/crc.nd.edu/x86_64_linux/m/matlab/X.Y/help","title":"Matlab"},{"location":"modules/matlab/#matlab","text":"MATLAB is a high-performance language for technical computing. It integrates computation, visualization, and programming in an easy-to-use interactive environment where problems and solutions are expressed in familiar mathematical notation. This high-level language and interactive environment enables you to perform computationally intensive tasks faster than with traditional programming languages such as C, C++, and Fortran.","title":"Matlab"},{"location":"modules/matlab/#toolboxes","text":"The Matlab Toolboxes licensed by ND changes each year based on user demand (measured by an annual survey). Faculty may also purchase toolbox licenses which were not centrally funded based on broad user demand. To see what toolboxes are currently available simply type ver in the Matlab Command Window.","title":"Toolboxes"},{"location":"modules/matlab/#submitting-single-core-jobs","text":"To submit a single core MATLAB job to CRC systems use the following template: #!/bin/bash #$ -q long #$ -pe smp 1 module load matlab matlab -singleCompThread -nodisplay -nosplash < your_file.m By default, recent versions of MATLAB will try to automatically multithread processing on all the cores available on a machine. If you are only requesting one core in your submission script, you need to invoke MATLAB with the -singleCompThread option (to avoid interfering with other user's running jobs): matlab -singleCompThread ... [!WARNING] If you request more than 1 core, maxNumCompThreads function should be used to control the maximum number of computational threads. For example, adding the following line in your Matlab code will limit the number of threads to the same number as that you entered for the -pe smp flag in your job script: maxNumCompThreads(str2num(getenv(\"NSLOTS\")));","title":"Submitting Single Core Jobs"},{"location":"modules/matlab/#submitting-multicore-jobs","text":"To submit multicore MATLAB jobs (up to 24 cores with current CRC systems) using the PCT (Parallel Computing Toolbox), use the following template. Note that there are normally multiple versions of Matlab available, see the modules page for more information on how software is organized within the CRC. #!/bin/bash #$ -q long #$ -pe smp 12 export MATLABPATH=~/path/to/matlab_file cd ~/path/to/matlab_file module load matlab matlab -nodisplay -nosplash < matlab_file The matlab file above includes the command parpool('local',12) , allowing Matlab to use the 12 cores on the machine. Parallelization can also be accomplished using a parfor within your matlab file: parpool('local', 12); parfor i=1:N end % In Matlab 8.5 need to use \"delete(gcp('nocreate'))\"","title":"Submitting Multicore Jobs"},{"location":"modules/matlab/#matlab-and-array-jobs","text":"An example for combining MATLAB and job arrays is as follows: #!/bin/csh #$ -N testarray #$ -t 1-4:1 #$ -M afs_id@nd.edu #$ -m ae setenv MATLABPATH directory_path_to_your_files.m:other_user_contrib_directory_path matlab -nodisplay -nosplash -nojvm -r \"myFunction(${SGE_TASK_ID});exit\" The myfunction.m will receive respectively for each task 1,2,3 and 4 as an input parameter.","title":"MATLAB and Array Jobs"},{"location":"modules/matlab/#memory-profiling","text":"User can use the builtin MATLAB profiler to understand memory usage in your scripts. To enable memory profiling add the following line to your scripts: profile -memory on;","title":"Memory Profiling"},{"location":"modules/matlab/#license-information","text":"Matlab Parallel Computing Toolbox can be currently configured up to 64 cores (SMP) per simulation. We currently do not support a license for MATLAB Distributed Computing","title":"License Information"},{"location":"modules/matlab/#tutorials-and-training","text":"For more information, please visit the official Matlab training page for a wealth of video tutorials and training content.","title":"Tutorials and Training"},{"location":"modules/matlab/#known-issue-with-parpool-and-matlabpool","text":"There is a known issue when submitting multiple jobs that use either of the Matlab pool commands. Basically, if more than one task is started close to another task, they may both try and write to the same temporary file and cause problems. One solution involves changing the name of the default file Matlab writes pool information to as described in this link: Matlab Pool Solution .","title":"Known issue with parpool and matlabpool"},{"location":"modules/matlab/#dynare-support","text":"Looking to use Matlab with dynare ? Simply load the dynare module, this will automatically bring in all dependencies. You can check which versions of dynare are available with: module avail dynare","title":"Dynare Support"},{"location":"modules/matlab/#further-information","text":"See the official site: MATLAB Default help files for version \"X.Y\" (replace X and Y with desired version) may be found at: /afs/crc.nd.edu/x86_64_linux/m/matlab/X.Y/help","title":"Further Information"},{"location":"modules/python/","text":"Python Python is an interpreted, interactive, object-oriented programming language. It incorporates modules, exceptions, dynamic typing, very high level dynamic data types, and classes. Python combines remarkable power with very clear syntax. It has interfaces to many system calls and libraries, as well as to various window systems, and is extensible in C or C++. It is also usable as an extension language for applications that need a programmable interface. Finally, Python is portable: it runs on many Unix variants, on the Mac, and on PCs under MS-DOS, Windows, Windows NT, and OS/2. [!WARNING] Starting in May, 2019, the CRC Python module defaults to Python 3 . If you are using code based on Python 2 , we highly recommend moving to the 3.X branch of Python. Python 2 stopped being maintained in January of 2020 and have been completely removed from RHEL8. Basic Usage A default version of Python is available on any of our machines that run Redhat Enterprise Linux. The default version is considered to be extremely stable, but does tend to be several iterations behind the most recent version. You can check the version number with the following command: $ python3 --version Python 3.6.8 To provide the additional functionality of more recent versions, the CRC maintains additional Python modules. The current offerings can be seen with this command: $ module avail python ---------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ----------------------------------- python/3.7.3 To load the default Python module: $ module load python In addition, we often install popular packages to go along with the module versions. For example, the packages NumPy and SciPy are available through any of the above listed modules. Installing Python Packages Locally If you need a package that is not installed with the CRC version of Python, then you can easily install it locally in your personal AFS space using the following instructions. ''pip'' is a useful tool for installing Python packages, particularly those with many dependencies. Installing a python package is as easy using the pip3 command: module load python pip3 install --user package_name If the package is distributed as a compressed tar file, such as ''package.tar.gz'': Download the Python package Unpack it in your CRC space: tar -xzf package.tar.gz Change to the unpacked directory: cd package Install the package: python3 setup.py install --user This will install all of the files in your home directory under ~/.local/ When you load Python, the local package should now be accessible (via ''import''). Adding \\${HOME}/.local/bin to your path When using the --user option above, a Python package may also install helper applications in addition to source code. By default, these programs will be installed into the directory: ${HOME}/.local/bin You may always give the full path to the application, but it is often easier to add this directory to the variable $PATH , so that only the name of the program is required to run it. If you are using the BASH shell, the following line will add it: echo 'export PATH=${HOME}/.local/bin:${PATH}' >> ~/.bashrc Similarly, for TCSH: echo 'setenv PATH ${HOME}/.local/bin:${PATH}' >> ~/.cshrc If you're not sure which shell you are using, input this command: echo $0 The next time you log in or source your startup script, programs in ${HOME}/.local/bin will be available without the need for specifying the exact location. Python Virtual Environment Having a virtual environment can be useful if you want to install software, but do not want that software to be installed globally. Using virtualenv will allow you to install packages and easily delete them once you are finished. As an alternative to virtualenv , the CRC supports a conda module. To use virtualenv you must first load a python module: module load python Next, install the virtualenv package into your user space: pip3 install --user virtualenv [!NOTE] The virtualenv executable will not be automatically added to your path. Next, you will need to create a folder named whatever you like and move into it: mkdir virtualProject cd virtualProject Next, create the virtual environment naming it whatever you want: ~/.local/bin/virtualenv NameOfVirtualEnviroment The virtual environment has been created, but it still needs to be activated: source NameOfVirtualEnviroment/bin/activate You will notice that the name of your virtual environment will now appear on the left of the prompt like this: (NameOfVirtualEnviroment)userName@nameOfMachine:~/virtualProject $ This indicates that your virtual environment is currently active. You are now able to install packages into it without affecting global packages. To deactivate your virtual environment simply by type: deactivate If you ever forget which packages you had installed in which virtual environment, type: pip3 freeze into an activate virtual environment and the terminal will list which packages are installed. Try creating a virtual environment and installing a package in that environment. Then type pip3 freeze ` when the virtual environment is first active and then de-active. You will notice that the packages are different, and that is the whole point of the Python Virtual Environment: to have different packages in different virtual environments without affecting global packages. When you are finished with a virtual environment and no longer need it or the packages it has installed, simply delete the folder the virtual environment resides in: rm -rf NameOfFolder The virtual environment has now been deleted and global packages have not changed at all. Job Submission Example The following is a basic template for creating a UGE job submission script for a python job #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -q long # Specify queue #$ -pe smp 1 # Specify number of cores to use. #$ -N helloWorld # Specify job name module load python python3 HelloWorld.py Where HelloWorld.py contains: #!/usr/bin/env python3 print(\"Hello World!\\n\") Multi-core Jobs Many python packages are written to take advantage of multiple processing units (cores) to solve problems more quickly by executing code in parallel. Our batch system supports this feature through a two step process. First, you must let the batch system know how many resources you are requesting via the -pe smp flag. Second, and most important, you must also tell Python how many resources to use. By default, Python will assume that it is able to use all resources that it is aware of. In the best case, this can lead to a compute node being overtaxed and slowing down all jobs running. In the worst case, it can crash the node. We tell Python how many cores it is allowed to use through an environment variable named OMP_NUM_THREADS . Typically, we set this variable to the same value as that we set in our #$ -pe smp flag via another variable, $NSLOTS . For example, the following BASH script will run a Python program that is written to take advantage of multiple cores using at most 4 cores: #!/bin/bash #$ -q long #$ -pe smp 4 export OMP_NUM_THREADS=${NSLOTS} module load python python3 numpy-test.py The equivalent (T)CSH script would be: #!/bin/tcsh #$ -q long #$ -pe smp 4 setenv OMP_NUM_THREADS ${NSLOTS} module load python python3 numpy-test.py Further Information See the official site: Python.org","title":"Python"},{"location":"modules/python/#python","text":"Python is an interpreted, interactive, object-oriented programming language. It incorporates modules, exceptions, dynamic typing, very high level dynamic data types, and classes. Python combines remarkable power with very clear syntax. It has interfaces to many system calls and libraries, as well as to various window systems, and is extensible in C or C++. It is also usable as an extension language for applications that need a programmable interface. Finally, Python is portable: it runs on many Unix variants, on the Mac, and on PCs under MS-DOS, Windows, Windows NT, and OS/2. [!WARNING] Starting in May, 2019, the CRC Python module defaults to Python 3 . If you are using code based on Python 2 , we highly recommend moving to the 3.X branch of Python. Python 2 stopped being maintained in January of 2020 and have been completely removed from RHEL8.","title":"Python"},{"location":"modules/python/#basic-usage","text":"A default version of Python is available on any of our machines that run Redhat Enterprise Linux. The default version is considered to be extremely stable, but does tend to be several iterations behind the most recent version. You can check the version number with the following command: $ python3 --version Python 3.6.8 To provide the additional functionality of more recent versions, the CRC maintains additional Python modules. The current offerings can be seen with this command: $ module avail python ---------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ----------------------------------- python/3.7.3 To load the default Python module: $ module load python In addition, we often install popular packages to go along with the module versions. For example, the packages NumPy and SciPy are available through any of the above listed modules.","title":"Basic Usage"},{"location":"modules/python/#installing-python-packages-locally","text":"If you need a package that is not installed with the CRC version of Python, then you can easily install it locally in your personal AFS space using the following instructions. ''pip'' is a useful tool for installing Python packages, particularly those with many dependencies. Installing a python package is as easy using the pip3 command: module load python pip3 install --user package_name If the package is distributed as a compressed tar file, such as ''package.tar.gz'': Download the Python package Unpack it in your CRC space: tar -xzf package.tar.gz Change to the unpacked directory: cd package Install the package: python3 setup.py install --user This will install all of the files in your home directory under ~/.local/ When you load Python, the local package should now be accessible (via ''import'').","title":"Installing Python Packages Locally"},{"location":"modules/python/#adding-homelocalbin-to-your-path","text":"When using the --user option above, a Python package may also install helper applications in addition to source code. By default, these programs will be installed into the directory: ${HOME}/.local/bin You may always give the full path to the application, but it is often easier to add this directory to the variable $PATH , so that only the name of the program is required to run it. If you are using the BASH shell, the following line will add it: echo 'export PATH=${HOME}/.local/bin:${PATH}' >> ~/.bashrc Similarly, for TCSH: echo 'setenv PATH ${HOME}/.local/bin:${PATH}' >> ~/.cshrc If you're not sure which shell you are using, input this command: echo $0 The next time you log in or source your startup script, programs in ${HOME}/.local/bin will be available without the need for specifying the exact location.","title":"Adding \\${HOME}/.local/bin to your path"},{"location":"modules/python/#python-virtual-environment","text":"Having a virtual environment can be useful if you want to install software, but do not want that software to be installed globally. Using virtualenv will allow you to install packages and easily delete them once you are finished. As an alternative to virtualenv , the CRC supports a conda module. To use virtualenv you must first load a python module: module load python Next, install the virtualenv package into your user space: pip3 install --user virtualenv [!NOTE] The virtualenv executable will not be automatically added to your path. Next, you will need to create a folder named whatever you like and move into it: mkdir virtualProject cd virtualProject Next, create the virtual environment naming it whatever you want: ~/.local/bin/virtualenv NameOfVirtualEnviroment The virtual environment has been created, but it still needs to be activated: source NameOfVirtualEnviroment/bin/activate You will notice that the name of your virtual environment will now appear on the left of the prompt like this: (NameOfVirtualEnviroment)userName@nameOfMachine:~/virtualProject $ This indicates that your virtual environment is currently active. You are now able to install packages into it without affecting global packages. To deactivate your virtual environment simply by type: deactivate If you ever forget which packages you had installed in which virtual environment, type: pip3 freeze into an activate virtual environment and the terminal will list which packages are installed. Try creating a virtual environment and installing a package in that environment. Then type pip3 freeze ` when the virtual environment is first active and then de-active. You will notice that the packages are different, and that is the whole point of the Python Virtual Environment: to have different packages in different virtual environments without affecting global packages. When you are finished with a virtual environment and no longer need it or the packages it has installed, simply delete the folder the virtual environment resides in: rm -rf NameOfFolder The virtual environment has now been deleted and global packages have not changed at all.","title":"Python Virtual Environment"},{"location":"modules/python/#job-submission-example","text":"The following is a basic template for creating a UGE job submission script for a python job #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -q long # Specify queue #$ -pe smp 1 # Specify number of cores to use. #$ -N helloWorld # Specify job name module load python python3 HelloWorld.py Where HelloWorld.py contains: #!/usr/bin/env python3 print(\"Hello World!\\n\")","title":"Job Submission Example"},{"location":"modules/python/#multi-core-jobs","text":"Many python packages are written to take advantage of multiple processing units (cores) to solve problems more quickly by executing code in parallel. Our batch system supports this feature through a two step process. First, you must let the batch system know how many resources you are requesting via the -pe smp flag. Second, and most important, you must also tell Python how many resources to use. By default, Python will assume that it is able to use all resources that it is aware of. In the best case, this can lead to a compute node being overtaxed and slowing down all jobs running. In the worst case, it can crash the node. We tell Python how many cores it is allowed to use through an environment variable named OMP_NUM_THREADS . Typically, we set this variable to the same value as that we set in our #$ -pe smp flag via another variable, $NSLOTS . For example, the following BASH script will run a Python program that is written to take advantage of multiple cores using at most 4 cores: #!/bin/bash #$ -q long #$ -pe smp 4 export OMP_NUM_THREADS=${NSLOTS} module load python python3 numpy-test.py The equivalent (T)CSH script would be: #!/bin/tcsh #$ -q long #$ -pe smp 4 setenv OMP_NUM_THREADS ${NSLOTS} module load python python3 numpy-test.py","title":"Multi-core Jobs"},{"location":"modules/python/#further-information","text":"See the official site: Python.org","title":"Further Information"},{"location":"modules/r/","text":"R R is a language and environment for statistical computing and graphics. It is a GNU project which is similar to the S language and environment which was developed at Bell Laboratories (formerly AT&T, now Lucent Technologies) by John Chambers and colleagues. R can be considered as a different implementation of S. There are some important differences, but much code written for S runs unaltered under R. R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, ...) and graphical techniques, and is highly extensible. The S language is often the vehicle of choice for research in statistical methodology, and R provides an Open Source route to participation in that activity. Sample R Job #!/bin/bash #$ -M afs_id@nd.edu #$ -m abe module load R R CMD BATCH your_input_R_file.r your_output_R_file.out Installing Local Packages Due to the wide range of packages available for R , we are unable to install every one. Fortunately, it is easy for users to install additional libraries. To begin with, load the R module. If the default version is sufficient, this can be done with the command: module load R For convenience, although not necessary, we suggest making a central directory to hold this and any future packages: mkdir ~/myRlibs Next, there are two different ways of installing R packages: Installing packages within R Open an R shell and execute the following command: install.packages(\"package_name\", lib=\"install_location\", repos=\"mirror_location\") library('package_name', lib.loc='install_location') For our example, this would be: install.packages(\"bizdays\", lib=\"~/myRlibs\",repos='https://cran.us.r-project.org') library('bizdays', lib='~/myRlibs') To avoid having to specify the installation location every time you use this library, you can create an .Renviron file in your home directory using any text editor. Then, add the following line to it: R_LIBS=install_location For our example, this would be: R_LIBS=~/myRlibs Now, we can simply do: install.packages(\"bizdays\") library(bizdays) Installing R packages from source code You will need to obtain the source code for the package you want to install. The most common repository of these are at The Comprehensive R Archive Network (CRAN) . A simple method to get the package to the CRC is to copy the location of the file, usually through a right click sub-menu, and then use the ''wget'' command: wget https://cran.r-project.org/src/contrib/bizdays_1.0.1.tar.gz Once we have the package, we will need to decide where to install it. Now, issue the following command to install the package: R CMD INSTALL -l install_location package_name For our example, this would be: R CMD INSTALL -l ~/myRlibs bizdays_1.0.1.tar.gz The last step is to tell R the location of our new installation. In a CSH environment, this is: setenv R_LIBS install_location If you are using BASH, it would be: export R_LIBS=install_location Add this command to your .cshrc or .bashrc file, respectively, to permanently set it. Profiling R Code Profiling R code can help determine which sections in the R code need to be optimized for better performance. In order to profile the R code, one needs to use the Rprof() function. Rprof() records how many seconds have been spent on each function of the R code. The functions that get timed are the ones that get executed after the Rprof() function gets declared. Any function before the Rprof() declaration will not be timed. One needs to pass a parameter to Rprof. The parameter is the name of the file that will contain the results. If only a section of the R code needs to be profiled, one can use the Rprof() to specify when to start profiling the functions and when to stop profiling the functions. To start profiling the functions, one should place Rprof(\"file_name\") before the functions that need to be profiled get executed. In order to stop profiling the rest of the R Code, one needs to place Rprof(NULL) to stop profiling the rest of the R Code that does not need to be profiled. The following is an example on how RProf() is used in an actual R script. # load sources dyn.load(\"readbfile3_crc.so\") source(\"readbfile.r\") source(\"snpsel24_data.r\") Rprof(\"test1b.out\") #Begin profiling functions # try to read in data dat.M <- read.bfile(\"hapmap_sim_chr1_test.bed\") # try to run snpsel selmat.M <- snp_sel(dat.M,k=300,b=10,t=.1) Rprof(NULL) #Stop profiling functions # write selmat for reference write.table(selmat.M,file=\"test_selmat_v1.txt\",quote=F,sep=\" \",col.names=F,row.names=F) In the example above, the functions read.bfile() and snp_sel() as well a the functions within these functions will be profiled. The function write.table() will not be profiled by Rprof() . Parallel Computing in R R itself does not provide parallel execution. Therefore, in order to realize parallel computing in R, an appropriate parallel R package should be invoked. Test for Rmpi Here is an Rmpi test file: # Load the Rmpi pacakge: library(Rmpi) # Spawn N-1 workers ==> Don't need this on UGE so that commented out, by ISS on 04012019 # mpi.spawn.Rslaves(nslaves=mpi.universe.size()-1) # The command we want to run on all the nodes/processors we have mpi.remote.exec(paste(\"I am \", mpi.comm.rank(), \" of \", mpi.comm.size(), \" on \", Sys.info() [c(\"nodename\")])) # Tell all slaves to close down, and exit the program mpi.close.Rslaves() mpi.quit() and save this with \"Rmpi-test-on-CRC.R\". A job script file for this Rmpi parallel test on the CRC Grid Engine: #!/bin/tcsh # #$ -M Your_NetID@nd.edu #$ -m abe # #$ -pe mpi-24 48 # # Specify a queue name, for example, #$ -q debug # module load R/4.2.0 mpirun -np ${NSLOTS} Rscript Rmpi-test-on-CRC.R > Rmpi-test-on-CRC.out The R/4.2.0 version in the CRC R modules supports \"foreach\", \"parallel\", \"doParallel\", \"snow\", \"snowfall\",... parallel packages as a default. For a single node SMP parallel, you can easily download/install on your own space. For example, you can invoke the library with: >library(parallel) in your R script and then can specify a number of core you want. Typically, we set the cores variable to the same value as that we set in our #$ -pe smp flag via an environment variable, NSLOTS . For example, >options(cores = Sys.getenv(\"NSLOTS\")) >getOption('cores') Here is a typical example to compare single-core and multi-core parallel computing in R: module load R R > library(parallel) > detectCores() [1] 24 > options(cores = 24) > getOption('cores') [1] 24 > test <- lapply(1:10,function(x) rnorm(100000)) > system.time(x <- lapply(test,function(x) loess.smooth(x,x))) <<<== single-core running > system.time(x <- mclapply(test,function(x) loess.smooth(x,x))) <<<== multi-core (24-core) running Related Software For a GUI IDE for R, see rstudio . Further Information See the official website: R","title":"R"},{"location":"modules/r/#r","text":"R is a language and environment for statistical computing and graphics. It is a GNU project which is similar to the S language and environment which was developed at Bell Laboratories (formerly AT&T, now Lucent Technologies) by John Chambers and colleagues. R can be considered as a different implementation of S. There are some important differences, but much code written for S runs unaltered under R. R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, ...) and graphical techniques, and is highly extensible. The S language is often the vehicle of choice for research in statistical methodology, and R provides an Open Source route to participation in that activity.","title":"R"},{"location":"modules/r/#sample-r-job","text":"#!/bin/bash #$ -M afs_id@nd.edu #$ -m abe module load R R CMD BATCH your_input_R_file.r your_output_R_file.out","title":"Sample R Job"},{"location":"modules/r/#installing-local-packages","text":"Due to the wide range of packages available for R , we are unable to install every one. Fortunately, it is easy for users to install additional libraries. To begin with, load the R module. If the default version is sufficient, this can be done with the command: module load R For convenience, although not necessary, we suggest making a central directory to hold this and any future packages: mkdir ~/myRlibs Next, there are two different ways of installing R packages:","title":"Installing Local Packages"},{"location":"modules/r/#installing-packages-within-r","text":"Open an R shell and execute the following command: install.packages(\"package_name\", lib=\"install_location\", repos=\"mirror_location\") library('package_name', lib.loc='install_location') For our example, this would be: install.packages(\"bizdays\", lib=\"~/myRlibs\",repos='https://cran.us.r-project.org') library('bizdays', lib='~/myRlibs') To avoid having to specify the installation location every time you use this library, you can create an .Renviron file in your home directory using any text editor. Then, add the following line to it: R_LIBS=install_location For our example, this would be: R_LIBS=~/myRlibs Now, we can simply do: install.packages(\"bizdays\") library(bizdays)","title":"Installing packages within R"},{"location":"modules/r/#installing-r-packages-from-source-code","text":"You will need to obtain the source code for the package you want to install. The most common repository of these are at The Comprehensive R Archive Network (CRAN) . A simple method to get the package to the CRC is to copy the location of the file, usually through a right click sub-menu, and then use the ''wget'' command: wget https://cran.r-project.org/src/contrib/bizdays_1.0.1.tar.gz Once we have the package, we will need to decide where to install it. Now, issue the following command to install the package: R CMD INSTALL -l install_location package_name For our example, this would be: R CMD INSTALL -l ~/myRlibs bizdays_1.0.1.tar.gz The last step is to tell R the location of our new installation. In a CSH environment, this is: setenv R_LIBS install_location If you are using BASH, it would be: export R_LIBS=install_location Add this command to your .cshrc or .bashrc file, respectively, to permanently set it.","title":"Installing R packages from source code"},{"location":"modules/r/#profiling-r-code","text":"Profiling R code can help determine which sections in the R code need to be optimized for better performance. In order to profile the R code, one needs to use the Rprof() function. Rprof() records how many seconds have been spent on each function of the R code. The functions that get timed are the ones that get executed after the Rprof() function gets declared. Any function before the Rprof() declaration will not be timed. One needs to pass a parameter to Rprof. The parameter is the name of the file that will contain the results. If only a section of the R code needs to be profiled, one can use the Rprof() to specify when to start profiling the functions and when to stop profiling the functions. To start profiling the functions, one should place Rprof(\"file_name\") before the functions that need to be profiled get executed. In order to stop profiling the rest of the R Code, one needs to place Rprof(NULL) to stop profiling the rest of the R Code that does not need to be profiled. The following is an example on how RProf() is used in an actual R script. # load sources dyn.load(\"readbfile3_crc.so\") source(\"readbfile.r\") source(\"snpsel24_data.r\") Rprof(\"test1b.out\") #Begin profiling functions # try to read in data dat.M <- read.bfile(\"hapmap_sim_chr1_test.bed\") # try to run snpsel selmat.M <- snp_sel(dat.M,k=300,b=10,t=.1) Rprof(NULL) #Stop profiling functions # write selmat for reference write.table(selmat.M,file=\"test_selmat_v1.txt\",quote=F,sep=\" \",col.names=F,row.names=F) In the example above, the functions read.bfile() and snp_sel() as well a the functions within these functions will be profiled. The function write.table() will not be profiled by Rprof() .","title":"Profiling R Code"},{"location":"modules/r/#parallel-computing-in-r","text":"R itself does not provide parallel execution. Therefore, in order to realize parallel computing in R, an appropriate parallel R package should be invoked.","title":"Parallel Computing in R"},{"location":"modules/r/#test-for-rmpi","text":"Here is an Rmpi test file: # Load the Rmpi pacakge: library(Rmpi) # Spawn N-1 workers ==> Don't need this on UGE so that commented out, by ISS on 04012019 # mpi.spawn.Rslaves(nslaves=mpi.universe.size()-1) # The command we want to run on all the nodes/processors we have mpi.remote.exec(paste(\"I am \", mpi.comm.rank(), \" of \", mpi.comm.size(), \" on \", Sys.info() [c(\"nodename\")])) # Tell all slaves to close down, and exit the program mpi.close.Rslaves() mpi.quit() and save this with \"Rmpi-test-on-CRC.R\". A job script file for this Rmpi parallel test on the CRC Grid Engine: #!/bin/tcsh # #$ -M Your_NetID@nd.edu #$ -m abe # #$ -pe mpi-24 48 # # Specify a queue name, for example, #$ -q debug # module load R/4.2.0 mpirun -np ${NSLOTS} Rscript Rmpi-test-on-CRC.R > Rmpi-test-on-CRC.out The R/4.2.0 version in the CRC R modules supports \"foreach\", \"parallel\", \"doParallel\", \"snow\", \"snowfall\",... parallel packages as a default. For a single node SMP parallel, you can easily download/install on your own space. For example, you can invoke the library with: >library(parallel) in your R script and then can specify a number of core you want. Typically, we set the cores variable to the same value as that we set in our #$ -pe smp flag via an environment variable, NSLOTS . For example, >options(cores = Sys.getenv(\"NSLOTS\")) >getOption('cores') Here is a typical example to compare single-core and multi-core parallel computing in R: module load R R > library(parallel) > detectCores() [1] 24 > options(cores = 24) > getOption('cores') [1] 24 > test <- lapply(1:10,function(x) rnorm(100000)) > system.time(x <- lapply(test,function(x) loess.smooth(x,x))) <<<== single-core running > system.time(x <- mclapply(test,function(x) loess.smooth(x,x))) <<<== multi-core (24-core) running","title":"Test for Rmpi"},{"location":"modules/r/#related-software","text":"For a GUI IDE for R, see rstudio .","title":"Related Software"},{"location":"modules/r/#further-information","text":"See the official website: R","title":"Further Information"},{"location":"modules/tensorflow/","text":"Tensorflow General Description TensorFlow\u2122 is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs and GPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google\u2019s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains. Basic Usage CRC version of Tensorflow support both GPU and CPU. The following is an example of UGE job submission script requesting 1 GPU #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -q gpu # Specify queue #$ -l gpu_card=1 # Specify number of GPU cards to use. #$ -N TFjob # Specify job name module load tensorflow python3 pythonscript.py Tensorflow Python As you can see above, no python module manually loaded for a tensorflow job. The tensorflow module itself will bring it's own version of python with several necessary packages preconfigured to use the CRC infrastructure. $ module list Currently Loaded Modulefiles: 1) CRC_default/1.1 $ python3 --version Python 3.6.8 $ module load tensorflow $ python3 --version Python 3.9.5 Installing Python Packages Locally If a python package is not installed with the CRC version of Tensorflow, you can easily install it locally in your personal AFS space using pip. module load tensorflow pip3 install --user package_name","title":"Tensorflow"},{"location":"modules/tensorflow/#tensorflow","text":"","title":"Tensorflow"},{"location":"modules/tensorflow/#general-description","text":"TensorFlow\u2122 is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs and GPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google\u2019s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains.","title":"General Description"},{"location":"modules/tensorflow/#basic-usage","text":"CRC version of Tensorflow support both GPU and CPU. The following is an example of UGE job submission script requesting 1 GPU #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -q gpu # Specify queue #$ -l gpu_card=1 # Specify number of GPU cards to use. #$ -N TFjob # Specify job name module load tensorflow python3 pythonscript.py","title":"Basic Usage"},{"location":"modules/tensorflow/#tensorflow-python","text":"As you can see above, no python module manually loaded for a tensorflow job. The tensorflow module itself will bring it's own version of python with several necessary packages preconfigured to use the CRC infrastructure. $ module list Currently Loaded Modulefiles: 1) CRC_default/1.1 $ python3 --version Python 3.6.8 $ module load tensorflow $ python3 --version Python 3.9.5","title":"Tensorflow Python"},{"location":"modules/tensorflow/#installing-python-packages-locally","text":"If a python package is not installed with the CRC version of Tensorflow, you can easily install it locally in your personal AFS space using pip. module load tensorflow pip3 install --user package_name","title":"Installing Python Packages Locally"},{"location":"new_user/connecting_to_crc/","text":"Connecting to CRC Servers All activity performed on the CRC infrastructure occurs on remote servers, this requires an ssh (Secure Shell) connection to a head node at the very least. Below are instructions for creating an ssh session to a head node specific to each popular OS. For more information on the Public head nodes see the front_end_workflow page. [!NOTE] For users connecting from off campus, please review the section off-campus-connect first. Connecting from Linux Most distributions of Linux are shipped with a terminal available. Most likely, ssh will already be installed. Open a terminal, the process for doing so can very from distro to distro. Popular key-bindings are \"CTRL + Alt + T\", or \"Alt + F2\". From here you can simply use the ssh command to connect: ssh netid@crcfe01.crc.nd.edu X11 Forwarding If you plan on using a GUI (Graphical User Interface), you will need to forward an X connection to our servers. To do so, use the -Y flag to pass trusted X11 connections. ssh -Y netid@crcfe01.crc.nd.edu Connecting from a Mac As macOS is a form of Unix , there is an included terminal application. Open the Launchpad and search for \"Terminal\". Once you open the \"Terminal\" program you will have a shell in front of you. From here, you can use the ssh command. ssh netid@crcfe02.crc.nd.edu X11 forwarding for Mac If you plan on using a GUI (Graphical User Interface), you will need to first download a program called XQuartz . Go to the XQuartz download page . It will install like most other macOS applications. Once XQuartz is installed, you can use the -Y flag to ssh within a terminal to connect to a head node. ssh -Y netid@crcfe01.crc.nd.edu [!NOTE] Development of XQuartz has lagged quite behind macOS. A number of issues with it has been reported to us. It may be easier to use fastx for Mac users. Connecting from Windows For all versions of Windows, we recommend using MobaXterm. Detailed instructions on how to connect from Windows see the mobaxterm page. Connecting from off campus If you are connecting from off campus or unable to use the EDUROAM wireless network, you will first need to connect to the campus VPN. Installation instructions for Windows, Mac, and Linux are available from this OIT hosted site: https://nd.service-now.com/nd_portal?id=product_page&sys_id=9d5919c7db22a34099dcf25bbf9619e2&table=cmdb_ci_business_app/ If you are unable or prefer not to use the campus VPN, one alternative is to use the server bastion.crc.nd.edu as your login host.","title":"Connecting to CRC Servers"},{"location":"new_user/connecting_to_crc/#connecting-to-crc-servers","text":"All activity performed on the CRC infrastructure occurs on remote servers, this requires an ssh (Secure Shell) connection to a head node at the very least. Below are instructions for creating an ssh session to a head node specific to each popular OS. For more information on the Public head nodes see the front_end_workflow page. [!NOTE] For users connecting from off campus, please review the section off-campus-connect first.","title":"Connecting to CRC Servers"},{"location":"new_user/connecting_to_crc/#connecting-from-linux","text":"Most distributions of Linux are shipped with a terminal available. Most likely, ssh will already be installed. Open a terminal, the process for doing so can very from distro to distro. Popular key-bindings are \"CTRL + Alt + T\", or \"Alt + F2\". From here you can simply use the ssh command to connect: ssh netid@crcfe01.crc.nd.edu","title":"Connecting from Linux"},{"location":"new_user/connecting_to_crc/#x11-forwarding","text":"If you plan on using a GUI (Graphical User Interface), you will need to forward an X connection to our servers. To do so, use the -Y flag to pass trusted X11 connections. ssh -Y netid@crcfe01.crc.nd.edu","title":"X11 Forwarding"},{"location":"new_user/connecting_to_crc/#connecting-from-a-mac","text":"As macOS is a form of Unix , there is an included terminal application. Open the Launchpad and search for \"Terminal\". Once you open the \"Terminal\" program you will have a shell in front of you. From here, you can use the ssh command. ssh netid@crcfe02.crc.nd.edu","title":"Connecting from a Mac"},{"location":"new_user/connecting_to_crc/#x11-forwarding-for-mac","text":"If you plan on using a GUI (Graphical User Interface), you will need to first download a program called XQuartz . Go to the XQuartz download page . It will install like most other macOS applications. Once XQuartz is installed, you can use the -Y flag to ssh within a terminal to connect to a head node. ssh -Y netid@crcfe01.crc.nd.edu [!NOTE] Development of XQuartz has lagged quite behind macOS. A number of issues with it has been reported to us. It may be easier to use fastx for Mac users.","title":"X11 forwarding for Mac"},{"location":"new_user/connecting_to_crc/#connecting-from-windows","text":"For all versions of Windows, we recommend using MobaXterm. Detailed instructions on how to connect from Windows see the mobaxterm page.","title":"Connecting from Windows"},{"location":"new_user/connecting_to_crc/#connecting-from-off-campus","text":"If you are connecting from off campus or unable to use the EDUROAM wireless network, you will first need to connect to the campus VPN. Installation instructions for Windows, Mac, and Linux are available from this OIT hosted site: https://nd.service-now.com/nd_portal?id=product_page&sys_id=9d5919c7db22a34099dcf25bbf9619e2&table=cmdb_ci_business_app/ If you are unable or prefer not to use the campus VPN, one alternative is to use the server bastion.crc.nd.edu as your login host.","title":"Connecting from off campus"},{"location":"new_user/introductory_videos/","text":"Introductory Videos List of topics Accessing the CRC systems Learn how to create a CRC account. CRC front end systems Learn about general access front end machines. Connecting from a Windows Learn how to connect to a front end machine from Windows. Connecting from Mac Learn how to connect to a front end machine from a Mac. Connecting from the browser Learn how to connect to a front end machine from the browser. Utilizing front end systems Learn how to properly utilize front end systems. Modules Learn how to use modules on the CRC sytems. File systems Learn about available file systems. Transfering files Learn how to transfer files to the CRC systems. Job scripts Learn the basics of job scripts. Parallel environments Learn more about parallel environments. Queues Learn more about queues. Job submission Learn how to submit jobs to the batch system. Job monitoring Learn how to monitor submitted jobs. Checking available resources Learn how to check the available CPU and GPU resource. Job arrays Learn how to use job arrays.","title":"Introductory Videos"},{"location":"new_user/introductory_videos/#introductory-videos","text":"List of topics","title":"Introductory Videos"},{"location":"new_user/introductory_videos/#accessing-the-crc-systems","text":"Learn how to create a CRC account.","title":"Accessing the CRC systems"},{"location":"new_user/introductory_videos/#crc-front-end-systems","text":"Learn about general access front end machines.","title":"CRC front end systems"},{"location":"new_user/introductory_videos/#connecting-from-a-windows","text":"Learn how to connect to a front end machine from Windows.","title":"Connecting from a Windows"},{"location":"new_user/introductory_videos/#connecting-from-mac","text":"Learn how to connect to a front end machine from a Mac.","title":"Connecting from Mac"},{"location":"new_user/introductory_videos/#connecting-from-the-browser","text":"Learn how to connect to a front end machine from the browser.","title":"Connecting from the browser"},{"location":"new_user/introductory_videos/#utilizing-front-end-systems","text":"Learn how to properly utilize front end systems.","title":"Utilizing front end systems"},{"location":"new_user/introductory_videos/#modules","text":"Learn how to use modules on the CRC sytems.","title":"Modules"},{"location":"new_user/introductory_videos/#file-systems","text":"Learn about available file systems.","title":"File systems"},{"location":"new_user/introductory_videos/#transfering-files","text":"Learn how to transfer files to the CRC systems.","title":"Transfering files"},{"location":"new_user/introductory_videos/#job-scripts","text":"Learn the basics of job scripts.","title":"Job scripts"},{"location":"new_user/introductory_videos/#parallel-environments","text":"Learn more about parallel environments.","title":"Parallel environments"},{"location":"new_user/introductory_videos/#queues","text":"Learn more about queues.","title":"Queues"},{"location":"new_user/introductory_videos/#job-submission","text":"Learn how to submit jobs to the batch system.","title":"Job submission"},{"location":"new_user/introductory_videos/#job-monitoring","text":"Learn how to monitor submitted jobs.","title":"Job monitoring"},{"location":"new_user/introductory_videos/#checking-available-resources","text":"Learn how to check the available CPU and GPU resource.","title":"Checking available resources"},{"location":"new_user/introductory_videos/#job-arrays","text":"Learn how to use job arrays.","title":"Job arrays"},{"location":"new_user/linux_guide/","text":"Basic Linux Guide All of the CRC HPC infrastructure is running some form of Red Hat Enterprise Linux. RHEL (Red Hat Enterprise Linux) is a Linux distribution, which is a flavor of a Unix-like operating system centered around the Linux kernel. To begin using the CRC HPC infrastructure, you will need a basic understanding of how to operate and navigate a terminal in a Linux environment. This page will show you the basics, but we highly recommend learning on your own some basic Bash commands. The following is only intended to get you started, a more in depth guide can be found on the Linux Journey website. Navigating File System When first logging in, you will be placed into what is known as your Home space. This can be abbreviated with ~. Your prompt will most likely look something like this: [$USER@crcfe0X.crc.nd.edu ~]$ _ In your prompt you should see your ND NetID instead of $USER . Paths A path is simply the location in a file system of a particular file or directory (folder). There are two different basic types of paths, absolute (fully qualified) and relative. Type Def Example Relative Path in relation to current directory foo.txt Absolute Fully qualified unambiguous path /afs/crc/user/u/username/research/foo.txt To see where you are currently in the file system hierarchy, also known as your Current Working Directory or CWD , can be found with using the pwd command: [crcuser@crcfe0X.crc.nd.edu ~]$ pwd /afs/crc.nd.edu/user/c/crcuser/ Viewing Files and Directories To view which files and directories are in your Current Working Directory, simply use the ls : [crcuser@crcfe0X.crc.nd.edu ~]$ ls Private Public YESTRDAY You can also pass a relative or absolute path to the ls command to view the contents of a particular directory without being within said directory: [crcuser@crcfe0X.crc.nd.edu ~]$ ls Public myprogram.py mystuff researchstuff foobar.txt You can change which directory you're currently within by using the cd command. You can also pass in a relative or absolute path into this command and it will behave as expected: [crcuser@crcfe0X.crc.nd.edu ~]$ cd Public [crcuser@crcfe0X.crc.nd.edu ~/Public]$ _ [crcuser@crcfe0X.crc.nd.edu ~/Public]$ cd /afs/crc/user/c/crcuser/Private [crcuser@crcfe0X.crc.nd.edu ~/Private]$ pwd /afs/crc/user/c/crcuser/Private Commands In order to do anything within a terminal you will need to run commands. If you've been following along you already ran a few commands. The default shell for new CRC accounts is bash . Thus, you will be running bash commands for both UGE jobs and while logged into the front ends. If you have an older account (pre May 2018) your default login shell will most likely be tcsh . If you'd prefer to have either bash or tcsh as your login shell, feel free to drop us a line at CRCSupport@nd.edu and we'd be happy to change it over for you. If you are unsure what your login shell is, type echo $0 . To see a listing of basic commands, grab the sheet here: Linux Coding Cheat Sheet <doc/fwunixref.pdf> Flags, Arguments, Options Every command will have the name along with modifier flags, arguments, and options. These can drastically alter the result of the command or be more subtle. For example, to view hidden files you need to pass a flag to the ls command: [crcuser@crcfe0X.crc.nd.edu ~/research]$ ls -a . .. .foo.txt research.txt foobar/ There are many, many flags to most commands. Normally, the --help flag is a standard for viewing a short help message about other options, but not always. [crcuser@crcfe0X.crc.nd.edu ~]$ ls --help Usage: ls [OPTION]... [FILE]... List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., [ message clipped ] An argument to a command is simply something passed in via the command line to be harvested and used in someway by the command being ran. For example, the ls command can receive an argument of a path to list the contents of. Below, we are passing the argument of ~/research/python_scripts to the command, which will then take that path and display the listing of contents. A command may do many different things with an argument, as there is no standard for what an argument is meant to do. [crcuser@crcfe0X.crc.nd.edu ~]$ ls ~/research/python_scripts foo.py helper.py foobar.txt Normally there is a manual page for a command, although this may not always be the case. A manual page will give you the technical details about running and utilizing a certain command in terms of options, bugs, flags, and more. The command to view a manual page is man COMMAND_HERE . This will normally bring up a pager such as less to view the page, where you can scroll up and down using the arrow keys, search for strings and more, or scroll with \"J + K\" keys. To exit the man page, you can press the \"Q\" key.: LS(1) User Commands LS(1) NAME ls - list directory contents SYNOPSIS ls [OPTION]... [FILE]... DESCRIPTION List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., '--block-size=M' prints sizes in units of 1,048,576 bytes; see SIZE format below FS Manipulation Organizing files and directories can free up time normally spent searching for files. If you'd like to create a directory to hold data etc for a certain portion of research, you can do so with mkdir . Let's say you'd like to rename a directory or file, you can use the mv command to move that file / directory to a different name.: [crcuser@crcfe0X.crc.nd.edu ~]$ mkdir research [crcuser@crcfe0X.crc.nd.edu ~]$ ls research Public Private YESTRDAY [crcuser@crcfe0X.crc.nd.edu ~]$ mv research malaria_research [crcuser@crcfe0X.crc.nd.edu ~]$ ls malaria_research Public Private YESTRDAY Copying files is another important task which can easily be accomplished. First you'll need to consider if you are copying a single file or a directory. To copy a single file, simply use cp src dest where src is the original file you'd like to copy and dest is the destination (this can include a path either relative or absolute). If you're copying a directory, you'll need to pass the -r flag to indicate you'd like to recursively copy files from said directory.: [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cp foo.txt bar.txt [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt bar.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cp -r research test_research [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt bar.txt run.py* research/ test_research/ Opening Files Opening files within the terminal is normally the most efficient way to quickly see the results of some runs or check on output etc. There are several ways to see the contents of a file, with different methods being ideal in different situations. To simply dump the contents of a file to the screen, you can use cat . Be careful doing so, as even if the file is a binary (compiled executable) or raw data file it will still dump gibberish to your screen. If the file is long and you'd like to easily scroll back and forth, you can open the file with a pager like less or more . Note that these will seemingly take over your terminal and you'll need to exit them to get back to the cmd prompt. Normally this is as easy as pressing the \"Q\" key.: [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cat foo.txt this is text from the file foo.txt this is more txt. I am text. Editing Files Editing files from a terminal can be done in many ways. You can simply edit the file and transfer the edited file to the CRC servers, or edit in place through the terminal. There are several terminal text editors with varying degree of learning curves. Below they are organized from easiest to learn to hardest, normally the more difficult to learn indicates a more powerful editor in terms of features and abilities. nano emacs vim ed -- Old editor, exists but we do not recommend. Typically with each above, you can create a file for example vim newfilename.txt, or you can edit an existing file with the same command. Learning the ins and outs of a particular editor can take some time, but is almost always worth the effort to save time transferring files when a small change is needed. Most editors have the ability to customize the operation, look, and feel through configuration scripts and can add different plugins for additional modifications. It is not unheard of for some programmers to use one of the above editors as their preferred text editor for everyday use.","title":"Basic Linux Guide"},{"location":"new_user/linux_guide/#basic-linux-guide","text":"All of the CRC HPC infrastructure is running some form of Red Hat Enterprise Linux. RHEL (Red Hat Enterprise Linux) is a Linux distribution, which is a flavor of a Unix-like operating system centered around the Linux kernel. To begin using the CRC HPC infrastructure, you will need a basic understanding of how to operate and navigate a terminal in a Linux environment. This page will show you the basics, but we highly recommend learning on your own some basic Bash commands. The following is only intended to get you started, a more in depth guide can be found on the Linux Journey website.","title":"Basic Linux Guide"},{"location":"new_user/linux_guide/#navigating-file-system","text":"When first logging in, you will be placed into what is known as your Home space. This can be abbreviated with ~. Your prompt will most likely look something like this: [$USER@crcfe0X.crc.nd.edu ~]$ _ In your prompt you should see your ND NetID instead of $USER .","title":"Navigating File System"},{"location":"new_user/linux_guide/#paths","text":"A path is simply the location in a file system of a particular file or directory (folder). There are two different basic types of paths, absolute (fully qualified) and relative. Type Def Example Relative Path in relation to current directory foo.txt Absolute Fully qualified unambiguous path /afs/crc/user/u/username/research/foo.txt To see where you are currently in the file system hierarchy, also known as your Current Working Directory or CWD , can be found with using the pwd command: [crcuser@crcfe0X.crc.nd.edu ~]$ pwd /afs/crc.nd.edu/user/c/crcuser/","title":"Paths"},{"location":"new_user/linux_guide/#viewing-files-and-directories","text":"To view which files and directories are in your Current Working Directory, simply use the ls : [crcuser@crcfe0X.crc.nd.edu ~]$ ls Private Public YESTRDAY You can also pass a relative or absolute path to the ls command to view the contents of a particular directory without being within said directory: [crcuser@crcfe0X.crc.nd.edu ~]$ ls Public myprogram.py mystuff researchstuff foobar.txt You can change which directory you're currently within by using the cd command. You can also pass in a relative or absolute path into this command and it will behave as expected: [crcuser@crcfe0X.crc.nd.edu ~]$ cd Public [crcuser@crcfe0X.crc.nd.edu ~/Public]$ _ [crcuser@crcfe0X.crc.nd.edu ~/Public]$ cd /afs/crc/user/c/crcuser/Private [crcuser@crcfe0X.crc.nd.edu ~/Private]$ pwd /afs/crc/user/c/crcuser/Private","title":"Viewing Files and Directories"},{"location":"new_user/linux_guide/#commands","text":"In order to do anything within a terminal you will need to run commands. If you've been following along you already ran a few commands. The default shell for new CRC accounts is bash . Thus, you will be running bash commands for both UGE jobs and while logged into the front ends. If you have an older account (pre May 2018) your default login shell will most likely be tcsh . If you'd prefer to have either bash or tcsh as your login shell, feel free to drop us a line at CRCSupport@nd.edu and we'd be happy to change it over for you. If you are unsure what your login shell is, type echo $0 . To see a listing of basic commands, grab the sheet here: Linux Coding Cheat Sheet <doc/fwunixref.pdf>","title":"Commands"},{"location":"new_user/linux_guide/#flags-arguments-options","text":"Every command will have the name along with modifier flags, arguments, and options. These can drastically alter the result of the command or be more subtle. For example, to view hidden files you need to pass a flag to the ls command: [crcuser@crcfe0X.crc.nd.edu ~/research]$ ls -a . .. .foo.txt research.txt foobar/ There are many, many flags to most commands. Normally, the --help flag is a standard for viewing a short help message about other options, but not always. [crcuser@crcfe0X.crc.nd.edu ~]$ ls --help Usage: ls [OPTION]... [FILE]... List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., [ message clipped ] An argument to a command is simply something passed in via the command line to be harvested and used in someway by the command being ran. For example, the ls command can receive an argument of a path to list the contents of. Below, we are passing the argument of ~/research/python_scripts to the command, which will then take that path and display the listing of contents. A command may do many different things with an argument, as there is no standard for what an argument is meant to do. [crcuser@crcfe0X.crc.nd.edu ~]$ ls ~/research/python_scripts foo.py helper.py foobar.txt Normally there is a manual page for a command, although this may not always be the case. A manual page will give you the technical details about running and utilizing a certain command in terms of options, bugs, flags, and more. The command to view a manual page is man COMMAND_HERE . This will normally bring up a pager such as less to view the page, where you can scroll up and down using the arrow keys, search for strings and more, or scroll with \"J + K\" keys. To exit the man page, you can press the \"Q\" key.: LS(1) User Commands LS(1) NAME ls - list directory contents SYNOPSIS ls [OPTION]... [FILE]... DESCRIPTION List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., '--block-size=M' prints sizes in units of 1,048,576 bytes; see SIZE format below","title":"Flags, Arguments, Options"},{"location":"new_user/linux_guide/#fs-manipulation","text":"Organizing files and directories can free up time normally spent searching for files. If you'd like to create a directory to hold data etc for a certain portion of research, you can do so with mkdir . Let's say you'd like to rename a directory or file, you can use the mv command to move that file / directory to a different name.: [crcuser@crcfe0X.crc.nd.edu ~]$ mkdir research [crcuser@crcfe0X.crc.nd.edu ~]$ ls research Public Private YESTRDAY [crcuser@crcfe0X.crc.nd.edu ~]$ mv research malaria_research [crcuser@crcfe0X.crc.nd.edu ~]$ ls malaria_research Public Private YESTRDAY Copying files is another important task which can easily be accomplished. First you'll need to consider if you are copying a single file or a directory. To copy a single file, simply use cp src dest where src is the original file you'd like to copy and dest is the destination (this can include a path either relative or absolute). If you're copying a directory, you'll need to pass the -r flag to indicate you'd like to recursively copy files from said directory.: [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cp foo.txt bar.txt [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt bar.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cp -r research test_research [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt bar.txt run.py* research/ test_research/","title":"FS Manipulation"},{"location":"new_user/linux_guide/#opening-files","text":"Opening files within the terminal is normally the most efficient way to quickly see the results of some runs or check on output etc. There are several ways to see the contents of a file, with different methods being ideal in different situations. To simply dump the contents of a file to the screen, you can use cat . Be careful doing so, as even if the file is a binary (compiled executable) or raw data file it will still dump gibberish to your screen. If the file is long and you'd like to easily scroll back and forth, you can open the file with a pager like less or more . Note that these will seemingly take over your terminal and you'll need to exit them to get back to the cmd prompt. Normally this is as easy as pressing the \"Q\" key.: [crcuser@crcfe0X.crc.nd.edu ~]$ ls -F foo.txt run.py* research/ [crcuser@crcfe0X.crc.nd.edu ~]$ cat foo.txt this is text from the file foo.txt this is more txt. I am text.","title":"Opening Files"},{"location":"new_user/linux_guide/#editing-files","text":"Editing files from a terminal can be done in many ways. You can simply edit the file and transfer the edited file to the CRC servers, or edit in place through the terminal. There are several terminal text editors with varying degree of learning curves. Below they are organized from easiest to learn to hardest, normally the more difficult to learn indicates a more powerful editor in terms of features and abilities. nano emacs vim ed -- Old editor, exists but we do not recommend. Typically with each above, you can create a file for example vim newfilename.txt, or you can edit an existing file with the same command. Learning the ins and outs of a particular editor can take some time, but is almost always worth the effort to save time transferring files when a small change is needed. Most editors have the ability to customize the operation, look, and feel through configuration scripts and can add different plugins for additional modifications. It is not unheard of for some programmers to use one of the above editors as their preferred text editor for everyday use.","title":"Editing Files"},{"location":"new_user/modules/","text":"Modules Taken from the Modulefile manual page, \"A typical modulefile is a simple bit of code that sets or adds entries to the PATH, MANPATH, or other environment variables.\" A Module is simply a way to easily organize and handle different pieces of software and different versions of the same software. This allows multiple versions of a popular package like Python to be available on the same system. Looking to create your own modules? See User Modules for instructions. Module Command While using CRC systems, software which is not included within a standard install of Red Hat Enterprise Linux must be loaded through a module. Matlab for example, cannot be ran on a front end or compute node within the CRC without first loading the matlab module. matlab matlab: command not found To use matlab, you must use the \"module\" command first. Running the module command alone will give a list of available options. module Modules Release 4.2.4 (2019-04-26) Usage: module [options] [command] [args ...] Loading / Unloading commands: add | load modulefile [...] Load modulefile(s) rm | unload modulefile [...] Remove modulefile(s) purge Unload all loaded modulefiles reload | refresh Unload then load all loaded modulefiles switch | swap [mod1] mod2 Unload mod1 and load mod2 < continues > Searching Modules To see all available modules, type module avail To see if a specific module is available, type module avail XYZ where XYZ is the name of the software you are searching for. Module Categories There are different categories in which the Modules are organized: system_modules deprecated_software restricted_software general_software development_tools_and_libraries. [!IMPORTANT] Modules within the restricted_software category cannot be used without first receiving permission to access those pieces of software. The deprecated category contains modules which are out of date or no longer being supported after the next biannual outage. The date of the next biannual outage can be found on the main page . These modules can still be used, however it is recommended to move your application to a newer version of the deprecated module. Using Modules After using \"module avail\", there will be a list of programs from which you can use. Let's say we need to use matlab, the \"load\" option to the module command can be used to bring matlab into our environment. Simply type: module load matlab Now you have the default matlab loaded and ready to use by just typing matlab If you need a specific version of a program and see it listed then you'd enter module load program_name/x.x where x.x is the version number. You can see which modules currently have loaded with module list You can also remove modules from your environment that you don't need anymore with module unload program_name Note that upon logging in, by default , you will not have any modules loaded with the exception of the CRC_default module. Getting information about a module To see a short description of the software within a module, use the whatis sub-command module whatis matlab Some modules may also have a short informational help screen. View it with: module help matlab User Created Modules There are some cases where a module is desired for software which is installed into local user space. Local modules can coexist with CRC modules and being user space installed software, these modules will not become deprecated and removed over time by CRC administrators. Creating a local or private module can be straightforward once a piece of software is installed into user space. [!NOTE] For the rest of these instructions, it is assumed the software a module is intended for is already installed. For more information on the module command itself, see Module Command . Creating a Private Module Private module files are stored within a directory whose path is prepended or appended to the module commands path. First create a directory where all private module files will be stored: $ mkdir ~/privatemodules Next, for each software package a module file is desired, create a directory. For an example, we will create a private module for graphviz. Note that for every software package intended for a module, a directory should be created like this. $ mkdir ~/privatemodules/graphviz Now, a module file can be created within the directory above. The module file should be named as the version of the software it is meant to load. Thus, continuing the graphviz example, a module file will be created titled 2.40.1: $ <your favorite text editor here> ~/privatemodules/graphviz/2.40.1 Nearly anyone of the module files administered by the CRC can be used as a template to create a private module. Below is an example for a private graphviz module file. Graphviz has been compiled locally within user AFS space on CRC systems, for software which is a precompiled binary, see precompiled_binary below: #%Module # -------------------------------------------------------------------------- # proc ModulesHelp { } { puts stderr \"Graphviz version 2.40.1\" puts stderr \"\\nGraphviz is open source graph visualization software. It has several main graph layout\" puts stderr \"programs. It also has web and interactive graphical interfaces, and auxiliary tools, libraries,\" puts stderr \"and language bindings. Graphviz has many useful features for concrete diagrams, such as options for\" puts stderr \"colors, fonts, tabular node layouts, line styles, hyperlinks, and custom shapes.\" } if { [ module-info mode load ] } { puts stderr [ concat \"Loaded shampton's version of module \" [module-info name] ] } set graphviz_path \"/afs/crc.nd.edu/user/letter/netid/intended_software\" # Setting paths prepend-path PATH $graphviz_path/bin prepend-path LD_LIBRARY_PATH $graphviz_path/lib prepend-path MANPATH $graphviz_path/share/man # Cleaning up environment unset graphviz_path module-whatis \"\\nGraphviz is open source graph visualization software.\" It is important to use absolute paths while creating module files. As seen above, a module file simply manipulates paths. What if my Software is a precompiled Binary? A module file for a precompiled binary software package is even easier to create than a module file for software compiled locally. Below is an example of a module file for the Rust programming language compiler and package manager, which typically come as precompiled binaries. #%Module # -------------------------------------------------------------------------- # proc ModulesHelp { } { puts stderr \"The rust modulefile defines the default system paths\" puts stderr \"and environment variables needed to use Rust and\" puts stderr \"Cargo, Rust's package manager.\" puts stderr \"Type \\\"module load rust\\\" to load the default version of Rust.\" } if { [ module-info mode load ] } { puts stderr [ concat \"Loaded <your name>'s version of module \" [module-info name] ] } prepend-path PATH /afs/crc.nd.edu/user/letter/netid/path/to/.cargo/bin module-whatis \"Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety. More information can be found at:\\n\\t\\thttps://doc.rust-lang.org/book/second-edition/index.html\" Using Private Modules In order for the module command to find the newly created private modules, the module path must be changed. This can be done with $ module use -a ~/privatemodules The above command will only affect the current login shell. In order to always have access to private modules, add the above command to your shell configuration script. For BASH users (new user default as of May 2018), add the above command to the bottom of your ~/.bashrc file For cshell / tcsh users, add the above command to the bottom of your ~/.cshrc file. Be sure to log out and log back in for the change to occur. Now, you can use the module commands (load, unload, avail, etc) on the private modules. Different Versions of Software Just like the CRC, private modules can be created for different versions of the same software. Simply create a new module file named after the version of software it is targeting and be sure the paths within the module file are correct. Thus you may get: \\$ module avail --------- /afs/crc.nd.edu/user/user/privatemodules ---------- graphviz/2.40.1 rust/1.19.0(default) rust/1.25.0 sage/8.0 To create a default version of a module, create a .version file within the directory of the module which follows suit to below: #%Module set ModulesVersion \"1.19.0\" Considerations When using module commands, the operation will occur to the first occurrence of the module the command finds. Thus, it may be a good idea to name a module something different from the CRC system modules.","title":"Modules"},{"location":"new_user/modules/#modules","text":"Taken from the Modulefile manual page, \"A typical modulefile is a simple bit of code that sets or adds entries to the PATH, MANPATH, or other environment variables.\" A Module is simply a way to easily organize and handle different pieces of software and different versions of the same software. This allows multiple versions of a popular package like Python to be available on the same system. Looking to create your own modules? See User Modules for instructions.","title":"Modules"},{"location":"new_user/modules/#module-command","text":"While using CRC systems, software which is not included within a standard install of Red Hat Enterprise Linux must be loaded through a module. Matlab for example, cannot be ran on a front end or compute node within the CRC without first loading the matlab module. matlab matlab: command not found To use matlab, you must use the \"module\" command first. Running the module command alone will give a list of available options. module Modules Release 4.2.4 (2019-04-26) Usage: module [options] [command] [args ...] Loading / Unloading commands: add | load modulefile [...] Load modulefile(s) rm | unload modulefile [...] Remove modulefile(s) purge Unload all loaded modulefiles reload | refresh Unload then load all loaded modulefiles switch | swap [mod1] mod2 Unload mod1 and load mod2 < continues >","title":"Module Command"},{"location":"new_user/modules/#searching-modules","text":"To see all available modules, type module avail To see if a specific module is available, type module avail XYZ where XYZ is the name of the software you are searching for.","title":"Searching Modules"},{"location":"new_user/modules/#module-categories","text":"There are different categories in which the Modules are organized: system_modules deprecated_software restricted_software general_software development_tools_and_libraries. [!IMPORTANT] Modules within the restricted_software category cannot be used without first receiving permission to access those pieces of software. The deprecated category contains modules which are out of date or no longer being supported after the next biannual outage. The date of the next biannual outage can be found on the main page . These modules can still be used, however it is recommended to move your application to a newer version of the deprecated module.","title":"Module Categories"},{"location":"new_user/modules/#using-modules","text":"After using \"module avail\", there will be a list of programs from which you can use. Let's say we need to use matlab, the \"load\" option to the module command can be used to bring matlab into our environment. Simply type: module load matlab Now you have the default matlab loaded and ready to use by just typing matlab If you need a specific version of a program and see it listed then you'd enter module load program_name/x.x where x.x is the version number. You can see which modules currently have loaded with module list You can also remove modules from your environment that you don't need anymore with module unload program_name Note that upon logging in, by default , you will not have any modules loaded with the exception of the CRC_default module.","title":"Using Modules"},{"location":"new_user/modules/#getting-information-about-a-module","text":"To see a short description of the software within a module, use the whatis sub-command module whatis matlab Some modules may also have a short informational help screen. View it with: module help matlab","title":"Getting information about a module"},{"location":"new_user/modules/#user-created-modules","text":"There are some cases where a module is desired for software which is installed into local user space. Local modules can coexist with CRC modules and being user space installed software, these modules will not become deprecated and removed over time by CRC administrators. Creating a local or private module can be straightforward once a piece of software is installed into user space. [!NOTE] For the rest of these instructions, it is assumed the software a module is intended for is already installed. For more information on the module command itself, see Module Command .","title":"User Created Modules"},{"location":"new_user/modules/#creating-a-private-module","text":"Private module files are stored within a directory whose path is prepended or appended to the module commands path. First create a directory where all private module files will be stored: $ mkdir ~/privatemodules Next, for each software package a module file is desired, create a directory. For an example, we will create a private module for graphviz. Note that for every software package intended for a module, a directory should be created like this. $ mkdir ~/privatemodules/graphviz Now, a module file can be created within the directory above. The module file should be named as the version of the software it is meant to load. Thus, continuing the graphviz example, a module file will be created titled 2.40.1: $ <your favorite text editor here> ~/privatemodules/graphviz/2.40.1 Nearly anyone of the module files administered by the CRC can be used as a template to create a private module. Below is an example for a private graphviz module file. Graphviz has been compiled locally within user AFS space on CRC systems, for software which is a precompiled binary, see precompiled_binary below: #%Module # -------------------------------------------------------------------------- # proc ModulesHelp { } { puts stderr \"Graphviz version 2.40.1\" puts stderr \"\\nGraphviz is open source graph visualization software. It has several main graph layout\" puts stderr \"programs. It also has web and interactive graphical interfaces, and auxiliary tools, libraries,\" puts stderr \"and language bindings. Graphviz has many useful features for concrete diagrams, such as options for\" puts stderr \"colors, fonts, tabular node layouts, line styles, hyperlinks, and custom shapes.\" } if { [ module-info mode load ] } { puts stderr [ concat \"Loaded shampton's version of module \" [module-info name] ] } set graphviz_path \"/afs/crc.nd.edu/user/letter/netid/intended_software\" # Setting paths prepend-path PATH $graphviz_path/bin prepend-path LD_LIBRARY_PATH $graphviz_path/lib prepend-path MANPATH $graphviz_path/share/man # Cleaning up environment unset graphviz_path module-whatis \"\\nGraphviz is open source graph visualization software.\" It is important to use absolute paths while creating module files. As seen above, a module file simply manipulates paths.","title":"Creating a Private Module"},{"location":"new_user/modules/#what-if-my-software-is-a-precompiled-binary","text":"A module file for a precompiled binary software package is even easier to create than a module file for software compiled locally. Below is an example of a module file for the Rust programming language compiler and package manager, which typically come as precompiled binaries. #%Module # -------------------------------------------------------------------------- # proc ModulesHelp { } { puts stderr \"The rust modulefile defines the default system paths\" puts stderr \"and environment variables needed to use Rust and\" puts stderr \"Cargo, Rust's package manager.\" puts stderr \"Type \\\"module load rust\\\" to load the default version of Rust.\" } if { [ module-info mode load ] } { puts stderr [ concat \"Loaded <your name>'s version of module \" [module-info name] ] } prepend-path PATH /afs/crc.nd.edu/user/letter/netid/path/to/.cargo/bin module-whatis \"Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety. More information can be found at:\\n\\t\\thttps://doc.rust-lang.org/book/second-edition/index.html\"","title":"What if my Software is a precompiled Binary?"},{"location":"new_user/modules/#using-private-modules","text":"In order for the module command to find the newly created private modules, the module path must be changed. This can be done with $ module use -a ~/privatemodules The above command will only affect the current login shell. In order to always have access to private modules, add the above command to your shell configuration script. For BASH users (new user default as of May 2018), add the above command to the bottom of your ~/.bashrc file For cshell / tcsh users, add the above command to the bottom of your ~/.cshrc file. Be sure to log out and log back in for the change to occur. Now, you can use the module commands (load, unload, avail, etc) on the private modules.","title":"Using Private Modules"},{"location":"new_user/modules/#different-versions-of-software","text":"Just like the CRC, private modules can be created for different versions of the same software. Simply create a new module file named after the version of software it is targeting and be sure the paths within the module file are correct. Thus you may get: \\$ module avail --------- /afs/crc.nd.edu/user/user/privatemodules ---------- graphviz/2.40.1 rust/1.19.0(default) rust/1.25.0 sage/8.0 To create a default version of a module, create a .version file within the directory of the module which follows suit to below: #%Module set ModulesVersion \"1.19.0\"","title":"Different Versions of Software"},{"location":"new_user/modules/#considerations","text":"When using module commands, the operation will occur to the first occurrence of the module the command finds. Thus, it may be a good idea to name a module something different from the CRC system modules.","title":"Considerations"},{"location":"new_user/obtain_account/","text":"Obtaining a CRC Account In order to use the CRC systems you must first obtain a CRC account. To apply for an account with the CRC, complete the steps below: You must be signed into your Notre Dame affliated email account , for example crcuser@nd.edu . If you are not already signed in, open a new tab within your browser and sign into your ND account. Once logged in, you can fill out all entries within the new user form and a CRC account will be created for you. You will be notified via email. [!NOTE] Email is the official line of communication for your CRC account. Be sure you are checking your ND affiliated email account often for any news, updates, or direct communication from CRC staff related to your jobs and account usage.","title":"Obtaining a CRC account"},{"location":"new_user/obtain_account/#obtaining-a-crc-account","text":"In order to use the CRC systems you must first obtain a CRC account. To apply for an account with the CRC, complete the steps below: You must be signed into your Notre Dame affliated email account , for example crcuser@nd.edu . If you are not already signed in, open a new tab within your browser and sign into your ND account. Once logged in, you can fill out all entries within the new user form and a CRC account will be created for you. You will be notified via email. [!NOTE] Email is the official line of communication for your CRC account. Be sure you are checking your ND affiliated email account often for any news, updates, or direct communication from CRC staff related to your jobs and account usage.","title":"Obtaining a CRC Account"},{"location":"new_user/quick_start/","text":"Quick Start Guide Detailed below are common methodologies and good practices for access and using the CRC's resources. Cluster Computing Format The organization of a super-computer or cluster is quite different from traditional desktop computing. Instead of all commands executing on the machine in front of you, everything is executed on a remote server, at times with no user interaction. A typical connection will look like: Cluster +---+---+---+---+---+---+ +---->+-------+ | | | | | | | | | Front | | | | | | | | | | End | | | | | | | | | +---+---+ | | | | | | | Internet | | +---+---+-------+---+---+ Connection | | ^ | | | | +---------------------------+ ____|______ \\+--+------+ \\|Personal | \\|Computer | \\+---------+ To access the CRC infrastructure, you will connect to a Front end or Head node where you can prepare, submit, check on, and delete your batch jobs. Most jobs executed on CRC servers are batch jobs, which are non-interactive well-defined jobs which are queued and executed on a compute host when resources are available. Front End Systems [!NOTE] For users connecting from off campus, please review the section off-campus-connect first. In order to submit and run jobs on CRC servers, the first step is to connect to a front end machine. This machine will facilitate connections to the job manager which will handle your job from submission to execution. The CRC provides the following front-end machines for compilation and job submission. Each machine is configured with identical software stacks. crcfe01.crc.nd.edu (2 12 core Intel(R) Haswell processors with 256 GB RAM) crcfe02.crc.nd.edu (2 12 core Intel(R) Haswell processors with 256 GB RAM) [!WARNING] Front-Ends are NOT for large long running (>1hr) jobs. For such jobs please using the queuing system and compute nodes. Any long running on a public front end machine may be killed. To see how to connect to a front end from your favorite OS, see connecting_to_crc . Proper Front End Usage The front end machines are the interface to the the rest of the computing resources of the CRC. There are both faculty owned and public front ends, the majority of information found here will pertain to public front ends. The public front ends are shared by all of campus and external collaborators to perform a wide variety of tasks related to research. Logging in There are 2 general access front ends available. crcfe01.crc.nd.edu crcfe02.crc.nd.edu The primary interface to these machines is through SSH. To connect to either of these machines, you'd start either a terminal (Mac and Linux) or an ssh client on Windows. For Windows we recommend MobaXterm . You'd then either follow the instructions on the ssh client or enter the following command in a terminal, replacing \"X\" with the desired machine (1 or 2) and replacing \"netid\" with your Notre Dame NetID: ssh netid@crcfe0X.crc.nd.edu If you are having troubles logging in and have a new account, be sure to read the welcome email which was sent on the activation of your CRC account: First login to okta.nd.edu . If you continue to have trouble logging in: Check all spelling Be sure your ssh client and OS are updated/patched. If all else fails, notify us via email at CRCSupport@nd.edu and please provide the following details: ND netid Which machine you're trying to connect to Your computer's Operating System (Windows, Mac, Linux, etc) The ssh client you're using (Putty, MobaXterm, terminal, etc). [!NOTE] If you intend on using HTCondor for job submissions, the front end machine to connect to is condorfe.crc.nd.edu If you need to compile code with infiniband support, connect to epycfe.crc.nd.edu . Utilizing Front Ends Once connected to a front end, you may begin preparing jobs for submission to either UGE or HTCondor (on condorfe.crc.nd.edu ). There are a few important notes about operating within the front end environment: There will be other users connected to this machine, any disruptive behaviour will be addressed. Any task / process running longer than 1 (ONE) hour may be removed / killed by an administrator. Submit long running jobs to the batch system. Do not launch large mpi or smp processes on a front end. More information on the queues and UGE can be found on the crc_uge_env page. When logged in, you will be within your user AFS space. Initially, there will be a few directories there. DO NOT remove your Public directory, this contains important login scripts. The default shell is BASH . If you have an older account, your login shell may be tcsh . If you'd like to request bash as your default, email CRCSupport@nd.edu . Software which is not included in an install of RHEL, can be accessed through the modules . Small processing which is not disruptive/resource intensive can be done on the front ends. This is normally pre-processing or post-processing after completion of UGE jobs. All CRC systems are a Linux variant. For tip on Linux commands, see Linux Coding Cheat Sheet <doc/fwunixref.pdf> For submitting jobs to UGE, please see submitting_batch_jobs . More sample scripts/submissions can normally be found on a module/software's page. Search for the module in question in the search bar on the top left of the page. Available Software The software environment on CRC servers is managed utilizing modules . A module is a an easy way to manage the necessary environmental paths and changes to utilize different pieces of software. You can easily modify your programming and/or application environment by simply loading and removing the required modules. The most common module commands are: module avail module list module load module_name More information on the CRC Modules can be found on the modules page. File Systems The CRC provides two complimentary file systems for storing programs and data. AFS Distributed file system Initial 100GB allocation Longer-term storage; backup taken daily User file system, your home directory lives here You can check your current AFS usage with the following command: quota Panasas High-performance parallel file system To obtain an allocation on /scratch365, send us a request at CRCSupport@nd.edu . Used for runtime working storage; no backup, purged yearly. You can check your current /scratch365 usage with the following command: pan_df \u2013H /scratch365/netid Further info: storage File Transfers To transfer files from your local desktop MacOS filesystem to your CRC filesystem space we recommend installing and using the following file transfer (GUI) client: cyberduck For Windows users, we recommend using mobaxterm as both an SSH client and a file transfer client. If you would like to transfer data between the CRC servers and Google Drive, we recommend the rclone tool. Job Scripts A typical batch job is a simple script which contains the commands necessary to execute the job which needs to be accomplished whether this is an R, Matlab, or Python script or a compiled executable. Jobs are submitted to the compute nodes via the Univa Grid Engine (UGE) batch submission system. Basic UGE batch scripts should conform to the following template: #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -pe smp 24 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name module load xyz # Required modules mpirun -np $NSLOTS ./app # Application to execute Further info: submitting_batch_jobs Parallel Environments To use more than one core in a job, you must specify a parallel environment. A parallel environment is a way to specify whether to use multiple cores on one machine or to use multiple nodes (more than 1 server). The two parallel environments are below. [TABLE] [!NOTE] * If no parallel environment is requested (i.e. you do not specify a - pe parameter), then the default execution environment is a single-core serial job. * Every machine has one thread per core! Further info: crc_uge_env Queues CRC provides two general-purpose queues for the submission of jobs (using the -q parameter): Below you'll find a summarization of the available queues. [TABLE] [!NOTE] In the above table, the long queue and gpu queue can include any faculty / lab owned machines you have access to. The runtime limit and example machines will most likely be different from the table above. Speak to your lab-mates, PI, or email us at CRCSupport@nd.edu if you'd like to know specifics of those machines. If you wish to target a specific architecture for your jobs, then you can specify a host group instead of a general-purpose queue. Host Groups If you wish to target machines in a finer granularity than queues, there are host groups. For example, the general access machines are the \"@crc_d32cepyc\" host group. If your research lab or faculty advisor has purchased a machine(s), there is most likely a host group you can target. Monitoring the status and availability of resources at a glance can be done with the free_nodes.sh script. free_nodes.sh -G # For general access free_nodes.sh -D # For Debug nodes free_nodes.sh @crc_d32cepyc # You can target host groups For further resource monitoring, consult the help information: free_nodes.sh --help Job Submission and Monitoring Job scripts can be submitted to the SGE batch submission system using the qsub command: qsub job.script Once your job script is submitted, you will receive a numerical job id from the batch submission system, which you can use to monitor the progress of the job. Job scripts that are determined by UGE to have made valid resource requests will enter the queuing system with a queue-waiting qw status (once the requested resources become available, the job will enter the running (r) status). Job scripts that are determined not to be valid will enter the queuing system with an error queue-waiting (Eqw) status. To see the status of your job submissions, use the qstat command with your username (netid) and observe the status column: qstat \u2013u username For a complete overview of your job submission, invoke the qstat command with the job id: qstat \u2013j job_id To see all pending and running jobs, simply type qstat without any options qstat The main reasons for invalid job scripts (i.e. having Eqw status) typically are: Illegal specification of parallel environments and/or core size requests Illegal queue specification Copying job scripts from a Windows OS environment to the Linux OS environment on the front-end machines (invisible Windows control code-blocks are not parsed correctly by UGE). This can be fixed by running the script through the dos2unix command Why is my job waiting in the Queue? The first reason a job could be waiting in a queue is simply because there are no resources available yet for your job to begin running. Note that for the most part (especially if you are using the general access machines), you are sharing resources with every other CRC user. The first item to check if if there are available resources at the moment for your job, you can use the free_nodes.sh script to check, for example: free_nodes.sh -G Note that even if there resource shown as available, the scheduler could be freeing up space for a larger job with higher priority than yours. There is also a maximum number of concurrent jobs to avoid overloading the systems with one person's jobs, this number fluctuates during the year depending on system utilization. If you need to push a large amount of jobs consisting of less than 4 cores each, perhaps condor is a good fit for you. Parallel Jobs If you requested a parallel environment with your job, be sure that requested environment adheres to the target resources. For example, be sure the machines you're targeting through smp can support the number of cores requested, a request of smp 75 will never be served on the general access or @crc_d32cepyc host group. If you're requesting an mpi-X Y environment, be sure the Y value is a multiple of X , and be sure X is a valid number for the targeted machines. For example, mpi-64 128 is the correct requested environment of 2 machines out of the general access queue. Job Deletion To delete a running or queued (e.g. submissions with Eqw status) job, use the following command: qdel \u2013j job_id Job Resource Monitoring To better understand the resource usage (e.g. memory, CPU and I/O utilization) of your running jobs, you can monitor the runtime behavior of your job\u2019s tasks as they execute on the compute nodes. To determine the nodes on which your tasks are running, enter the following qstat command along with your username. Record the machine names (e.g. d12chas400.crc.nd.edu) associated with each task (both MASTER and SLAVE): qstat -u username -g t There are two methods for analyzing the behavior of tasks (once you have a machine name): Xymon GUI Tool (detailed breakdown per task on a given machine) Xymon is a GUI tool to analyze the behavior of processes on a given CRC machine. It can be accessed on CRC Xymon . Note that you will need to be on the ND network to see this site. Use Xymon to navigate to the specific machine and then view the runtime resource usage of tasks on the machine. qhost command (aggregate summary across all tasks on a given machine) You can summarize the resource utilization of all tasks on a given machine using the following qhost command: qhost -h machine_name Job Arrays [!NOTE] If you find that you need to frequently submit 50 or more different jobs, we request that you implement those tasks within a job array. Grid engine is able to handle arrays much more efficiently than tens or hundreds of individual scripts from a single user. Fewer individual tasks reduces load on the job scheduler and improves overall performance. If you have a large number of job scripts to run that are largely identical in terms of executable and processing tasks, (e.g. a parameter sweep where only the input changes per run) then you may want to use a job array to submit your job. You specify how many copies of the script that you need to run with the -t parameter. For example, specifying: #$ -t 1-3 will run 3 identical job scripts. Job arrays use an internal environment variable, $SGE_TASK_ID , to dinstinguish between the different jobs and this can also be used as input to your job.: #!/bin/bash #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name #$ -t 1-3 # Specify number of tasks in array module load python # Note that different tasks will use different input files. python analyze.py < data.$SGE_TASK_ID If your tasks do not map directly to consecutive integer numbers, you may use a shell array within the script to do the mapping for you. In this example, we specify three different input strings that are then passed as an argument to the Python script: #!/bin/bash #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name #$ -t 1-3 # Specify number of tasks in array module load python fruits=( \"orange\" \"apple\" \"pair\" ) # Note that different tasks will use different input parameters. python pie_recipe.py ${fruits[$SGE_TASK_ID-1]} [!WARNING] To avoid extraneous emails, please do not use email notification options (-M and -m) when submitting an array job. More detailed information about job arrays is available from the manual page: man qsub or from this website: qsub manual","title":"Quick Start Guide"},{"location":"new_user/quick_start/#quick-start-guide","text":"Detailed below are common methodologies and good practices for access and using the CRC's resources.","title":"Quick Start Guide"},{"location":"new_user/quick_start/#cluster-computing-format","text":"The organization of a super-computer or cluster is quite different from traditional desktop computing. Instead of all commands executing on the machine in front of you, everything is executed on a remote server, at times with no user interaction. A typical connection will look like: Cluster +---+---+---+---+---+---+ +---->+-------+ | | | | | | | | | Front | | | | | | | | | | End | | | | | | | | | +---+---+ | | | | | | | Internet | | +---+---+-------+---+---+ Connection | | ^ | | | | +---------------------------+ ____|______ \\+--+------+ \\|Personal | \\|Computer | \\+---------+ To access the CRC infrastructure, you will connect to a Front end or Head node where you can prepare, submit, check on, and delete your batch jobs. Most jobs executed on CRC servers are batch jobs, which are non-interactive well-defined jobs which are queued and executed on a compute host when resources are available.","title":"Cluster Computing Format"},{"location":"new_user/quick_start/#front-end-systems","text":"[!NOTE] For users connecting from off campus, please review the section off-campus-connect first. In order to submit and run jobs on CRC servers, the first step is to connect to a front end machine. This machine will facilitate connections to the job manager which will handle your job from submission to execution. The CRC provides the following front-end machines for compilation and job submission. Each machine is configured with identical software stacks. crcfe01.crc.nd.edu (2 12 core Intel(R) Haswell processors with 256 GB RAM) crcfe02.crc.nd.edu (2 12 core Intel(R) Haswell processors with 256 GB RAM) [!WARNING] Front-Ends are NOT for large long running (>1hr) jobs. For such jobs please using the queuing system and compute nodes. Any long running on a public front end machine may be killed. To see how to connect to a front end from your favorite OS, see connecting_to_crc .","title":"Front End Systems"},{"location":"new_user/quick_start/#proper-front-end-usage","text":"The front end machines are the interface to the the rest of the computing resources of the CRC. There are both faculty owned and public front ends, the majority of information found here will pertain to public front ends. The public front ends are shared by all of campus and external collaborators to perform a wide variety of tasks related to research.","title":"Proper Front End Usage"},{"location":"new_user/quick_start/#logging-in","text":"There are 2 general access front ends available. crcfe01.crc.nd.edu crcfe02.crc.nd.edu The primary interface to these machines is through SSH. To connect to either of these machines, you'd start either a terminal (Mac and Linux) or an ssh client on Windows. For Windows we recommend MobaXterm . You'd then either follow the instructions on the ssh client or enter the following command in a terminal, replacing \"X\" with the desired machine (1 or 2) and replacing \"netid\" with your Notre Dame NetID: ssh netid@crcfe0X.crc.nd.edu If you are having troubles logging in and have a new account, be sure to read the welcome email which was sent on the activation of your CRC account: First login to okta.nd.edu . If you continue to have trouble logging in: Check all spelling Be sure your ssh client and OS are updated/patched. If all else fails, notify us via email at CRCSupport@nd.edu and please provide the following details: ND netid Which machine you're trying to connect to Your computer's Operating System (Windows, Mac, Linux, etc) The ssh client you're using (Putty, MobaXterm, terminal, etc). [!NOTE] If you intend on using HTCondor for job submissions, the front end machine to connect to is condorfe.crc.nd.edu If you need to compile code with infiniband support, connect to epycfe.crc.nd.edu .","title":"Logging in"},{"location":"new_user/quick_start/#utilizing-front-ends","text":"Once connected to a front end, you may begin preparing jobs for submission to either UGE or HTCondor (on condorfe.crc.nd.edu ). There are a few important notes about operating within the front end environment: There will be other users connected to this machine, any disruptive behaviour will be addressed. Any task / process running longer than 1 (ONE) hour may be removed / killed by an administrator. Submit long running jobs to the batch system. Do not launch large mpi or smp processes on a front end. More information on the queues and UGE can be found on the crc_uge_env page. When logged in, you will be within your user AFS space. Initially, there will be a few directories there. DO NOT remove your Public directory, this contains important login scripts. The default shell is BASH . If you have an older account, your login shell may be tcsh . If you'd like to request bash as your default, email CRCSupport@nd.edu . Software which is not included in an install of RHEL, can be accessed through the modules . Small processing which is not disruptive/resource intensive can be done on the front ends. This is normally pre-processing or post-processing after completion of UGE jobs. All CRC systems are a Linux variant. For tip on Linux commands, see Linux Coding Cheat Sheet <doc/fwunixref.pdf> For submitting jobs to UGE, please see submitting_batch_jobs . More sample scripts/submissions can normally be found on a module/software's page. Search for the module in question in the search bar on the top left of the page.","title":"Utilizing Front Ends"},{"location":"new_user/quick_start/#available-software","text":"The software environment on CRC servers is managed utilizing modules . A module is a an easy way to manage the necessary environmental paths and changes to utilize different pieces of software. You can easily modify your programming and/or application environment by simply loading and removing the required modules. The most common module commands are: module avail module list module load module_name More information on the CRC Modules can be found on the modules page.","title":"Available Software"},{"location":"new_user/quick_start/#file-systems","text":"The CRC provides two complimentary file systems for storing programs and data.","title":"File Systems"},{"location":"new_user/quick_start/#afs","text":"Distributed file system Initial 100GB allocation Longer-term storage; backup taken daily User file system, your home directory lives here You can check your current AFS usage with the following command: quota","title":"AFS"},{"location":"new_user/quick_start/#panasas","text":"High-performance parallel file system To obtain an allocation on /scratch365, send us a request at CRCSupport@nd.edu . Used for runtime working storage; no backup, purged yearly. You can check your current /scratch365 usage with the following command: pan_df \u2013H /scratch365/netid Further info: storage","title":"Panasas"},{"location":"new_user/quick_start/#file-transfers","text":"To transfer files from your local desktop MacOS filesystem to your CRC filesystem space we recommend installing and using the following file transfer (GUI) client: cyberduck For Windows users, we recommend using mobaxterm as both an SSH client and a file transfer client. If you would like to transfer data between the CRC servers and Google Drive, we recommend the rclone tool.","title":"File Transfers"},{"location":"new_user/quick_start/#job-scripts","text":"A typical batch job is a simple script which contains the commands necessary to execute the job which needs to be accomplished whether this is an R, Matlab, or Python script or a compiled executable. Jobs are submitted to the compute nodes via the Univa Grid Engine (UGE) batch submission system. Basic UGE batch scripts should conform to the following template: #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -pe smp 24 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name module load xyz # Required modules mpirun -np $NSLOTS ./app # Application to execute Further info: submitting_batch_jobs","title":"Job Scripts"},{"location":"new_user/quick_start/#parallel-environments","text":"To use more than one core in a job, you must specify a parallel environment. A parallel environment is a way to specify whether to use multiple cores on one machine or to use multiple nodes (more than 1 server). The two parallel environments are below. [TABLE] [!NOTE] * If no parallel environment is requested (i.e. you do not specify a - pe parameter), then the default execution environment is a single-core serial job. * Every machine has one thread per core! Further info: crc_uge_env","title":"Parallel Environments"},{"location":"new_user/quick_start/#queues","text":"CRC provides two general-purpose queues for the submission of jobs (using the -q parameter): Below you'll find a summarization of the available queues. [TABLE] [!NOTE] In the above table, the long queue and gpu queue can include any faculty / lab owned machines you have access to. The runtime limit and example machines will most likely be different from the table above. Speak to your lab-mates, PI, or email us at CRCSupport@nd.edu if you'd like to know specifics of those machines. If you wish to target a specific architecture for your jobs, then you can specify a host group instead of a general-purpose queue.","title":"Queues"},{"location":"new_user/quick_start/#host-groups","text":"If you wish to target machines in a finer granularity than queues, there are host groups. For example, the general access machines are the \"@crc_d32cepyc\" host group. If your research lab or faculty advisor has purchased a machine(s), there is most likely a host group you can target. Monitoring the status and availability of resources at a glance can be done with the free_nodes.sh script. free_nodes.sh -G # For general access free_nodes.sh -D # For Debug nodes free_nodes.sh @crc_d32cepyc # You can target host groups For further resource monitoring, consult the help information: free_nodes.sh --help","title":"Host Groups"},{"location":"new_user/quick_start/#job-submission-and-monitoring","text":"Job scripts can be submitted to the SGE batch submission system using the qsub command: qsub job.script Once your job script is submitted, you will receive a numerical job id from the batch submission system, which you can use to monitor the progress of the job. Job scripts that are determined by UGE to have made valid resource requests will enter the queuing system with a queue-waiting qw status (once the requested resources become available, the job will enter the running (r) status). Job scripts that are determined not to be valid will enter the queuing system with an error queue-waiting (Eqw) status. To see the status of your job submissions, use the qstat command with your username (netid) and observe the status column: qstat \u2013u username For a complete overview of your job submission, invoke the qstat command with the job id: qstat \u2013j job_id To see all pending and running jobs, simply type qstat without any options qstat The main reasons for invalid job scripts (i.e. having Eqw status) typically are: Illegal specification of parallel environments and/or core size requests Illegal queue specification Copying job scripts from a Windows OS environment to the Linux OS environment on the front-end machines (invisible Windows control code-blocks are not parsed correctly by UGE). This can be fixed by running the script through the dos2unix command","title":"Job Submission and Monitoring"},{"location":"new_user/quick_start/#why-is-my-job-waiting-in-the-queue","text":"The first reason a job could be waiting in a queue is simply because there are no resources available yet for your job to begin running. Note that for the most part (especially if you are using the general access machines), you are sharing resources with every other CRC user. The first item to check if if there are available resources at the moment for your job, you can use the free_nodes.sh script to check, for example: free_nodes.sh -G Note that even if there resource shown as available, the scheduler could be freeing up space for a larger job with higher priority than yours. There is also a maximum number of concurrent jobs to avoid overloading the systems with one person's jobs, this number fluctuates during the year depending on system utilization. If you need to push a large amount of jobs consisting of less than 4 cores each, perhaps condor is a good fit for you.","title":"Why is my job waiting in the Queue?"},{"location":"new_user/quick_start/#parallel-jobs","text":"If you requested a parallel environment with your job, be sure that requested environment adheres to the target resources. For example, be sure the machines you're targeting through smp can support the number of cores requested, a request of smp 75 will never be served on the general access or @crc_d32cepyc host group. If you're requesting an mpi-X Y environment, be sure the Y value is a multiple of X , and be sure X is a valid number for the targeted machines. For example, mpi-64 128 is the correct requested environment of 2 machines out of the general access queue.","title":"Parallel Jobs"},{"location":"new_user/quick_start/#job-deletion","text":"To delete a running or queued (e.g. submissions with Eqw status) job, use the following command: qdel \u2013j job_id","title":"Job Deletion"},{"location":"new_user/quick_start/#job-resource-monitoring","text":"To better understand the resource usage (e.g. memory, CPU and I/O utilization) of your running jobs, you can monitor the runtime behavior of your job\u2019s tasks as they execute on the compute nodes. To determine the nodes on which your tasks are running, enter the following qstat command along with your username. Record the machine names (e.g. d12chas400.crc.nd.edu) associated with each task (both MASTER and SLAVE): qstat -u username -g t There are two methods for analyzing the behavior of tasks (once you have a machine name): Xymon GUI Tool (detailed breakdown per task on a given machine) Xymon is a GUI tool to analyze the behavior of processes on a given CRC machine. It can be accessed on CRC Xymon . Note that you will need to be on the ND network to see this site. Use Xymon to navigate to the specific machine and then view the runtime resource usage of tasks on the machine. qhost command (aggregate summary across all tasks on a given machine) You can summarize the resource utilization of all tasks on a given machine using the following qhost command: qhost -h machine_name","title":"Job Resource Monitoring"},{"location":"new_user/quick_start/#job-arrays","text":"[!NOTE] If you find that you need to frequently submit 50 or more different jobs, we request that you implement those tasks within a job array. Grid engine is able to handle arrays much more efficiently than tens or hundreds of individual scripts from a single user. Fewer individual tasks reduces load on the job scheduler and improves overall performance. If you have a large number of job scripts to run that are largely identical in terms of executable and processing tasks, (e.g. a parameter sweep where only the input changes per run) then you may want to use a job array to submit your job. You specify how many copies of the script that you need to run with the -t parameter. For example, specifying: #$ -t 1-3 will run 3 identical job scripts. Job arrays use an internal environment variable, $SGE_TASK_ID , to dinstinguish between the different jobs and this can also be used as input to your job.: #!/bin/bash #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name #$ -t 1-3 # Specify number of tasks in array module load python # Note that different tasks will use different input files. python analyze.py < data.$SGE_TASK_ID If your tasks do not map directly to consecutive integer numbers, you may use a shell array within the script to do the mapping for you. In this example, we specify three different input strings that are then passed as an argument to the Python script: #!/bin/bash #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q long # Specify queue #$ -N job_name # Specify job name #$ -t 1-3 # Specify number of tasks in array module load python fruits=( \"orange\" \"apple\" \"pair\" ) # Note that different tasks will use different input parameters. python pie_recipe.py ${fruits[$SGE_TASK_ID-1]} [!WARNING] To avoid extraneous emails, please do not use email notification options (-M and -m) when submitting an array job. More detailed information about job arrays is available from the manual page: man qsub or from this website: qsub manual","title":"Job Arrays"},{"location":"new_user/training/","text":"Training Events Udemy , an on-demand and self-paced learning platform, offers a wide variety of individual online courses and can be a great option if you're interested in learning different tools used in research computing, such as Linux , Python , R , C++ , Github , etc. Periodically the CRC offers remote XSEDE workshops and internally sponsored workshops. Look for emails from the CRC for these events. You may also want to checkout XSEDE's Youtube channel which contains recordings of previous workshops. The CRC will email the user base with information about upcoming workshops and other training events. The library also holds software and data carpentry workshops from time to time, see their schedule page for more information and to register. New User Training We provide New User Training Videos and CRC Quick Start Guide . Additionally, in-person office hours are available every Wednesday and Thursday from 2-3PM in 812 Flanner Hall. Register and Contacts To register for in-person office hours, click on the Office Hours page. If you have any questions or issues please contact CRCSupport@nd.edu or stop by the Support office on the 8th floor of Flanner Hall.","title":"Training Events"},{"location":"new_user/training/#training-events","text":"Udemy , an on-demand and self-paced learning platform, offers a wide variety of individual online courses and can be a great option if you're interested in learning different tools used in research computing, such as Linux , Python , R , C++ , Github , etc. Periodically the CRC offers remote XSEDE workshops and internally sponsored workshops. Look for emails from the CRC for these events. You may also want to checkout XSEDE's Youtube channel which contains recordings of previous workshops. The CRC will email the user base with information about upcoming workshops and other training events. The library also holds software and data carpentry workshops from time to time, see their schedule page for more information and to register.","title":"Training Events"},{"location":"new_user/training/#new-user-training","text":"We provide New User Training Videos and CRC Quick Start Guide . Additionally, in-person office hours are available every Wednesday and Thursday from 2-3PM in 812 Flanner Hall.","title":"New User Training"},{"location":"new_user/training/#register-and-contacts","text":"To register for in-person office hours, click on the Office Hours page. If you have any questions or issues please contact CRCSupport@nd.edu or stop by the Support office on the 8th floor of Flanner Hall.","title":"Register and Contacts"},{"location":"resources/caml/","text":"CAML This page contains information regarding the NSF funded Cyberinfrastructure to Accelerate Machine Learning (CAML) computing resource. CAML provides GPU resources for accelerating machine learning to the research community both locally at the University of Notre Dame and nationally through the Open Science Grid (OSG). CAML physically hosts GPU resources suitable for accelerating the training of models from standard Deep Learning libraries. Configured for both interactive and batch access, CAML supports both small-scale explorations to large-scale discovery science. Access requirements In order for local users to access this resource, a CRC account and access to the Panasas (scratch) storage. Please, follow the links below for more information on how to obtain these: Obtaining a CRC account: https://docs.crc.nd.edu/new_user/obtain_account.html Panasas storage: https://docs.crc.nd.edu/infrastructure/storage.html?highlight=scratch365#panasas-scratch-storage Access through OSG can be done by signing up to OSG Connect: https://www.osgconnect.net Note only 20% of resources are allocated via this method at this point. Resource description The CAML GPU cluster is composed of: camlnd.crc.nd.edu (frontend / submit host) - 17 Dual 12-cores Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz, 192 GB of Memory, 400 GB Disk 4 GPUs NVIDIA Quadro RTX 6000 - 2 Dual 12-cores Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz, 192 GB of Memory, 400 GB Disk 4 GPUs NVIDIA Tesla V100-PCIE-32GB Using the resource on campus The university provides two different methods to access this resource: through a Jupyterhub service and via HTCondor. The former allows users to start interactive Jupyterhub notebook sessions on CAML GPU resources. The latter (HTCondor) is a batch system that provides a job queueing mechanism, allowing the scheduling of multiple jobs to this resource in parallel. Jupyterhub service Use this method if you need to access a single GPU resource interactively, through notebook sessions from your browser. Pre-requisites From a remote location (e.g. off campus, etc.), one must first log into the VPN. More information is available in the section off-campus-connect . Instructions After you get an account in camlnd.crc.nd.edu, you can click on the URL below in order to user Jupyterhub with CAML resources. This will start jupyter notebooks inside the GPU nodes for a specific amount of time. At present, access to your AFS Home area is allowed in read-only mode, use /scratch365/\\$USER to write files. https://camlnd.crc.nd.edu:9800/ Use your campus credentials to log in. Then, set the following parameters (note more demanding parameters may take longer to be scheduled, so please try to estimate the resources and time needed for your work as best as possible): GPUs: Number of GPUs for your application, up to 4. Default: 1 CPUs: Number of CPUs. Default: 1 Memory: Requested Memory (GB) Runtime: Maximum wall clock time (in minutes) allowed for your notebook to run. Max: 24 hours, Default:2 hours. Container: This will be the software environment needed for your application. Please, ask the CRC for help if you need an environment not listed here. Finally, you can either run python notebooks or work directly in the terminal. You can try the pytorch notebook example with the pytorch container. Note your starting directory will be located on /scratch365/\\$USER. Please, refer to the jupyter-notebook documentation for more information. HTCondor Submission In order to use CAML resources, we require defining singularity images on PATHs. E.g.: Via cvmfs. For example, the following Notre Dame image (available via CVMFS) supports TensorFlow, Keras and PyTorch: /cvmfs/singularity.opensciencegrid.org/notredamedulac/el7-tensorflow-pytorch:latest and it is built from: https://github.com/NDCMS/el7-tensorflow-gpu This section will show submission examples for different workflows, pointing to the specific Singularity images to handle the software environment dependencies. HTCondor submission file HTCondor needs a submission file, describing the resources needed, input files, log paths, container image location and executable to run. E.g.: executable = yourexecutable.sh # Note if you use a subdirectory like logs, you need to create it beforehand # E.g.: mkdir logs Log = logs/$(Cluster).log Output = logs/$(Cluster)-$(Process).out Error = logs/$(Cluster)-$(Process).err # Input files # You can transfer files like this: should_transfer_files = Yes transfer_input_files = /some/path/input_file # But if you are using /scratch365 and all your input files are present there, all worker nodes will have read/write access to it, so you can just use the scratch365 paths instead without transferring the input files and set the following instead: should_transfer_files = IF_NEEDED # Singularity image, for amber for example, it would be: #+SingularityImage = \"cvmfs/singularity.opensciencegrid.org/notredamedulac/amber:latest\" # Number of GPUs, Cpus and Memory to use request_gpus = 1 request_memory = 1 Gb request_cpus = 1 # Number of jobs to submit Queue 1 Please, refer to the HTCondor documentation for more details on how to create a submission file. Setting up the tutorial examples Once you log in into camlnd.crc.nd.edu, type: cd /scratch365/$USER git clone https://github.com/ND-CRC/ndgputests cd ndgputests Then, follow one of the examples below. Tensorflow example $ condor_submit submit_tensorflow.jdl Output example: - Executing python TensorFlow matrix multiplication example 2020-03-25 13:18:29.845113: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compil ed to use: AVX2 AVX512F FMA 2020-03-25 13:18:30.004982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.62 pciBusID: 0000:2f:00.0 totalMemory: 22.17GiB freeMemory: 22.00GiB 2020-03-25 13:18:30.005161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2020-03-25 13:18:30.570670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-03-25 13:18:30.570757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2020-03-25 13:18:30.570794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2020-03-25 13:18:30.570954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU :0 with 21320 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:2f:00.0, compute capability: 7.5) result of matrix multiplication =============================== [[ 1.0000000e+00 0.0000000e+00] [-4.7683716e-07 1.0000002e+00]] =============================== Pytorch example $ condor_submit submit_pytorch.jdl Output example: - Executing python torch matrix multiplication example --- Debug information --- - torch version: 1.4.0 - GPU information: -- CUDA Available: True -- Number of devices: 1 -- CUDA Device Name: Quadro RTX 6000 -- Current CUDA device: 0 ------ result of matrix multiplication =============================== tensor([[ 1.0000e+00, 0.0000e+00], [-4.7684e-07, 1.0000e+00]], device='cuda:0') Amber example $ condor_submit submit_amber.jdl Output example: - Entering scratch365 submit directory - Executing pmemd.cuda - Amber job is completed. - Exit code: 0 # From mdout |------------------- GPU DEVICE INFO -------------------- | | CUDA_VISIBLE_DEVICES: 0 | CUDA Capable Devices Detected: 1 | CUDA Device ID in use: 0 | CUDA Device Name: Quadro RTX 6000 | CUDA Device Global Mem Size: 22698 MB | CUDA Device Num Multiprocessors: 72 | CUDA Device Core Freq: 1.62 GHz | |-------------------------------------------------------- JAX example: $ condor_submit submit_jax.jdl Output example: - Executing python JAX matrix multiplication example -----GPU devices information----- [GpuDevice(id=0)] GPU host id: 0 --------------------------------- Generate a random matrix [[ 1.3890220e+00 -3.2292119e-01 1.5543443e-01 ... 1.6672333e-01 1.0217550e+00 9.6981764e-02] [ 1.0637628e+00 -1.8089763e+00 -7.7909984e-02 ... 1.1778636e+00 -4.3357372e-01 -2.7877533e-01] [-4.4029754e-01 -3.2537547e-01 2.7817255e-01 ... 6.8317270e-01 -6.1108190e-01 -6.3071573e-01] ... [ 2.9218230e-01 -4.0055802e-01 -1.4978158e+00 ... 3.0673659e+00 -1.1350130e+00 4.0964666e-01] [ 2.7635786e-01 1.5621810e-01 2.2997444e-03 ... 6.8930797e-02 -4.0692501e-02 4.1683877e-01] [ 1.0231308e+00 -2.7423611e-01 -8.0369931e-01 ... 1.9415886e+00 1.0946993e+00 2.1876085e+00]] Multiply by its transpose: result of matrix multiplication ================================= [[2938.1716 17.38843 36.508224 ... 32.315964 51.31904 -34.432022] [ 17.38843 3031.179 41.194584 ... 47.24877 58.077858 -13.371615] [ 36.508224 41.194584 3000.4697 ... 8.109009 -42.50184 26.49511 ] ... [ 32.315964 47.24877 8.109009 ... 2916.339 34.381073 39.404526] [ 51.31904 58.077858 -42.50184 ... 34.381073 3032.2844 63.69183 ] [ -34.432022 -13.371615 26.49511 ... 39.404526 63.69183 3033.4866 ]] ] ] ] ] ]] ] ] ] ] ]] DeepSphere example $ condor_submit submit_deepsphere.jdl Part of output example: emory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:2f:00.0, compute capability: 7.5) 2020-05-18 14:09:22.115326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.62 pciBusID: 0000:2f:00.0 step 75 / 112 (epoch 8.00 / 12): learning_rate = 1.00e-01, training loss = 3.12e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.38e+00 CPU time: 10s, wall time: 11s step 90 / 112 (epoch 9.60 / 12): learning_rate = 1.00e-01, training loss = 5.68e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.41e+00 CPU time: 11s, wall time: 12s step 105 / 112 (epoch 11.20 / 12): learning_rate = 1.00e-01, training loss = 2.04e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.44e+00 CPU time: 12s, wall time: 13s step 112 / 112 (epoch 11.95 / 12): learning_rate = 1.00e-01, training loss = 1.00e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.44e+00 CPU time: 13s, wall time: 14s validation accuracy: best = 100.00, mean = 100.00","title":"CAML"},{"location":"resources/caml/#caml","text":"This page contains information regarding the NSF funded Cyberinfrastructure to Accelerate Machine Learning (CAML) computing resource. CAML provides GPU resources for accelerating machine learning to the research community both locally at the University of Notre Dame and nationally through the Open Science Grid (OSG). CAML physically hosts GPU resources suitable for accelerating the training of models from standard Deep Learning libraries. Configured for both interactive and batch access, CAML supports both small-scale explorations to large-scale discovery science.","title":"CAML"},{"location":"resources/caml/#access-requirements","text":"In order for local users to access this resource, a CRC account and access to the Panasas (scratch) storage. Please, follow the links below for more information on how to obtain these: Obtaining a CRC account: https://docs.crc.nd.edu/new_user/obtain_account.html Panasas storage: https://docs.crc.nd.edu/infrastructure/storage.html?highlight=scratch365#panasas-scratch-storage Access through OSG can be done by signing up to OSG Connect: https://www.osgconnect.net Note only 20% of resources are allocated via this method at this point.","title":"Access requirements"},{"location":"resources/caml/#resource-description","text":"The CAML GPU cluster is composed of: camlnd.crc.nd.edu (frontend / submit host) - 17 Dual 12-cores Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz, 192 GB of Memory, 400 GB Disk 4 GPUs NVIDIA Quadro RTX 6000 - 2 Dual 12-cores Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz, 192 GB of Memory, 400 GB Disk 4 GPUs NVIDIA Tesla V100-PCIE-32GB","title":"Resource description"},{"location":"resources/caml/#using-the-resource-on-campus","text":"The university provides two different methods to access this resource: through a Jupyterhub service and via HTCondor. The former allows users to start interactive Jupyterhub notebook sessions on CAML GPU resources. The latter (HTCondor) is a batch system that provides a job queueing mechanism, allowing the scheduling of multiple jobs to this resource in parallel.","title":"Using the resource on campus"},{"location":"resources/caml/#jupyterhub-service","text":"Use this method if you need to access a single GPU resource interactively, through notebook sessions from your browser.","title":"Jupyterhub service"},{"location":"resources/caml/#pre-requisites","text":"From a remote location (e.g. off campus, etc.), one must first log into the VPN. More information is available in the section off-campus-connect .","title":"Pre-requisites"},{"location":"resources/caml/#instructions","text":"After you get an account in camlnd.crc.nd.edu, you can click on the URL below in order to user Jupyterhub with CAML resources. This will start jupyter notebooks inside the GPU nodes for a specific amount of time. At present, access to your AFS Home area is allowed in read-only mode, use /scratch365/\\$USER to write files. https://camlnd.crc.nd.edu:9800/ Use your campus credentials to log in. Then, set the following parameters (note more demanding parameters may take longer to be scheduled, so please try to estimate the resources and time needed for your work as best as possible): GPUs: Number of GPUs for your application, up to 4. Default: 1 CPUs: Number of CPUs. Default: 1 Memory: Requested Memory (GB) Runtime: Maximum wall clock time (in minutes) allowed for your notebook to run. Max: 24 hours, Default:2 hours. Container: This will be the software environment needed for your application. Please, ask the CRC for help if you need an environment not listed here. Finally, you can either run python notebooks or work directly in the terminal. You can try the pytorch notebook example with the pytorch container. Note your starting directory will be located on /scratch365/\\$USER. Please, refer to the jupyter-notebook documentation for more information.","title":"Instructions"},{"location":"resources/caml/#htcondor-submission","text":"In order to use CAML resources, we require defining singularity images on PATHs. E.g.: Via cvmfs. For example, the following Notre Dame image (available via CVMFS) supports TensorFlow, Keras and PyTorch: /cvmfs/singularity.opensciencegrid.org/notredamedulac/el7-tensorflow-pytorch:latest and it is built from: https://github.com/NDCMS/el7-tensorflow-gpu This section will show submission examples for different workflows, pointing to the specific Singularity images to handle the software environment dependencies.","title":"HTCondor Submission"},{"location":"resources/caml/#htcondor-submission-file","text":"HTCondor needs a submission file, describing the resources needed, input files, log paths, container image location and executable to run. E.g.: executable = yourexecutable.sh # Note if you use a subdirectory like logs, you need to create it beforehand # E.g.: mkdir logs Log = logs/$(Cluster).log Output = logs/$(Cluster)-$(Process).out Error = logs/$(Cluster)-$(Process).err # Input files # You can transfer files like this: should_transfer_files = Yes transfer_input_files = /some/path/input_file # But if you are using /scratch365 and all your input files are present there, all worker nodes will have read/write access to it, so you can just use the scratch365 paths instead without transferring the input files and set the following instead: should_transfer_files = IF_NEEDED # Singularity image, for amber for example, it would be: #+SingularityImage = \"cvmfs/singularity.opensciencegrid.org/notredamedulac/amber:latest\" # Number of GPUs, Cpus and Memory to use request_gpus = 1 request_memory = 1 Gb request_cpus = 1 # Number of jobs to submit Queue 1 Please, refer to the HTCondor documentation for more details on how to create a submission file.","title":"HTCondor submission file"},{"location":"resources/caml/#setting-up-the-tutorial-examples","text":"Once you log in into camlnd.crc.nd.edu, type: cd /scratch365/$USER git clone https://github.com/ND-CRC/ndgputests cd ndgputests Then, follow one of the examples below.","title":"Setting up the tutorial examples"},{"location":"resources/caml/#tensorflow-example","text":"$ condor_submit submit_tensorflow.jdl Output example: - Executing python TensorFlow matrix multiplication example 2020-03-25 13:18:29.845113: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compil ed to use: AVX2 AVX512F FMA 2020-03-25 13:18:30.004982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.62 pciBusID: 0000:2f:00.0 totalMemory: 22.17GiB freeMemory: 22.00GiB 2020-03-25 13:18:30.005161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2020-03-25 13:18:30.570670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-03-25 13:18:30.570757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2020-03-25 13:18:30.570794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2020-03-25 13:18:30.570954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU :0 with 21320 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:2f:00.0, compute capability: 7.5) result of matrix multiplication =============================== [[ 1.0000000e+00 0.0000000e+00] [-4.7683716e-07 1.0000002e+00]] ===============================","title":"Tensorflow example"},{"location":"resources/caml/#pytorch-example","text":"$ condor_submit submit_pytorch.jdl Output example: - Executing python torch matrix multiplication example --- Debug information --- - torch version: 1.4.0 - GPU information: -- CUDA Available: True -- Number of devices: 1 -- CUDA Device Name: Quadro RTX 6000 -- Current CUDA device: 0 ------ result of matrix multiplication =============================== tensor([[ 1.0000e+00, 0.0000e+00], [-4.7684e-07, 1.0000e+00]], device='cuda:0')","title":"Pytorch example"},{"location":"resources/caml/#amber-example","text":"$ condor_submit submit_amber.jdl Output example: - Entering scratch365 submit directory - Executing pmemd.cuda - Amber job is completed. - Exit code: 0 # From mdout |------------------- GPU DEVICE INFO -------------------- | | CUDA_VISIBLE_DEVICES: 0 | CUDA Capable Devices Detected: 1 | CUDA Device ID in use: 0 | CUDA Device Name: Quadro RTX 6000 | CUDA Device Global Mem Size: 22698 MB | CUDA Device Num Multiprocessors: 72 | CUDA Device Core Freq: 1.62 GHz | |--------------------------------------------------------","title":"Amber example"},{"location":"resources/caml/#jax-example","text":"$ condor_submit submit_jax.jdl Output example: - Executing python JAX matrix multiplication example -----GPU devices information----- [GpuDevice(id=0)] GPU host id: 0 --------------------------------- Generate a random matrix [[ 1.3890220e+00 -3.2292119e-01 1.5543443e-01 ... 1.6672333e-01 1.0217550e+00 9.6981764e-02] [ 1.0637628e+00 -1.8089763e+00 -7.7909984e-02 ... 1.1778636e+00 -4.3357372e-01 -2.7877533e-01] [-4.4029754e-01 -3.2537547e-01 2.7817255e-01 ... 6.8317270e-01 -6.1108190e-01 -6.3071573e-01] ... [ 2.9218230e-01 -4.0055802e-01 -1.4978158e+00 ... 3.0673659e+00 -1.1350130e+00 4.0964666e-01] [ 2.7635786e-01 1.5621810e-01 2.2997444e-03 ... 6.8930797e-02 -4.0692501e-02 4.1683877e-01] [ 1.0231308e+00 -2.7423611e-01 -8.0369931e-01 ... 1.9415886e+00 1.0946993e+00 2.1876085e+00]] Multiply by its transpose: result of matrix multiplication ================================= [[2938.1716 17.38843 36.508224 ... 32.315964 51.31904 -34.432022] [ 17.38843 3031.179 41.194584 ... 47.24877 58.077858 -13.371615] [ 36.508224 41.194584 3000.4697 ... 8.109009 -42.50184 26.49511 ] ... [ 32.315964 47.24877 8.109009 ... 2916.339 34.381073 39.404526] [ 51.31904 58.077858 -42.50184 ... 34.381073 3032.2844 63.69183 ] [ -34.432022 -13.371615 26.49511 ... 39.404526 63.69183 3033.4866 ]] ] ] ] ] ]] ] ] ] ] ]]","title":"JAX example:"},{"location":"resources/caml/#deepsphere-example","text":"$ condor_submit submit_deepsphere.jdl Part of output example: emory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:2f:00.0, compute capability: 7.5) 2020-05-18 14:09:22.115326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: name: Quadro RTX 6000 major: 7 minor: 5 memoryClockRate(GHz): 1.62 pciBusID: 0000:2f:00.0 step 75 / 112 (epoch 8.00 / 12): learning_rate = 1.00e-01, training loss = 3.12e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.38e+00 CPU time: 10s, wall time: 11s step 90 / 112 (epoch 9.60 / 12): learning_rate = 1.00e-01, training loss = 5.68e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.41e+00 CPU time: 11s, wall time: 12s step 105 / 112 (epoch 11.20 / 12): learning_rate = 1.00e-01, training loss = 2.04e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.44e+00 CPU time: 12s, wall time: 13s step 112 / 112 (epoch 11.95 / 12): learning_rate = 1.00e-01, training loss = 1.00e-03 validation accuracy: 100.00 (50 / 50), f1 (weighted): 100.00, loss: 1.44e+00 CPU time: 13s, wall time: 14s validation accuracy: best = 100.00, mean = 100.00","title":"DeepSphere example"},{"location":"resources/computing/","text":"Computing Resources","title":"Computing Resources"},{"location":"resources/computing/#computing-resources","text":"","title":"Computing Resources"},{"location":"resources/condor/","text":"HTCondor The University of Notre Dame has a Condor pool which harnesses the idle computational cycles from workstations and servers all over campus to run batch jobs. Condor provides access to over 20,000 cores. The Condor pool is maintained by the Notre Dame Cooperative Computing Lab (CCL) and CRC; most of the information in this article is taken directly from the CCL website . Visual Status of the ND Condor Pool ND Condor Utilization Matrix Online Short Course Short Course In Data Centric Computing About Condor Condor is a distributed batch computing system used at many institutions around the world. Condor allows many users to share their computing resources, thus giving everyone access to more computing power than any one person could afford to buy. In particular, Condor is good at harnessing idle cycles from under-used servers. Users that submit jobs to Condor can specify their own requirements on what machines to use. You can require the use of one particular machine, or any from a particular cluster, or any with a certain amount of memory or processor type. Of course, if you are borrowing machines owned by other people, then you must accept the possibility that some jobs may be kicked off and must run elsewhere. For more information about Condor, please visit the Condor project page at: https://research.cs.wisc.edu/htcondor/ . Getting Started With Condor at Notre Dame Log into condorfe.crc.nd.edu to submit jobs. To submit a batch job to Condor, you must create a submission file and then run the condor_submit command. Try creating this sample submit file in /tmp/YOURNAME/test.submit . universe = vanilla executable = /bin/echo arguments = hello condor output = test.output should_transfer_files = yes when_to_transfer_output = on_exit log = test.logfile queue Now, to submit the job to Condor, execute: cd /tmp/YOURNAME condor_submit test.submit Submitting job(s)... 1 job(s) submitted to cluster 2. Once the job is submitted, you can use condor_q to look at the status of the jobs in your queue. If you run condor_q quickly enough, you will see your job idle: -- Submitter: hedwig.cse.nd.edu : <129.74.154.241:33593> : hedwig.cse.nd.edu ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 2.0 dthain 8/26 17:21 0+00:00:00 I 0 0.0 echo hello world If you job remains in state I 'idle' for a significant amount of time you should check to see why it has not started. There is most likely a problem matching your request with an available resource which will be shown with the following command. condor_q yourjobnumberhere -better-analyze The command below shows the relative priority of everyone who has recently run jobs. Those with lower priority numbers have their waiting jobs start before others. condor_userprio If you decide to cancel a job, use condor_rm and the job id: condor_rm 2.0 Job 2.0 marked for removal. [!NOTE] Despite what the Condor manual says, you will NOT receive email when a job is complete. This feature has been disabled at Notre Dame due to our email security configuration. Important note about AFS In the example above, the submit file and all of the job's details were stored in /tmp/YOURNAME on your local disk. Condor simply moved the necessary files back and forth in order to run your jobs. If instead you store your data files in AFS (i.e. your home directory), Condor cannot access them because it will not have your AFS token or Kerberos ticket. If you want Condor to be able to read any data out of AFS, you must change the ACLs on the necessary directories to allow the security group nd_campus to read the data. Note that this will allow anyone with a valid account to read the data within the directory. Here's how: fs setacl ~/my/data/directory nd_campus read If you want Condor to be able to write to AFS, you must change the ACLs to the following: fs setacl ~/my/data/directory nd_campus rlidw Because AFS permissions are hierarchical, in both of these examples nd_campus must have at least lookup 'l' permission in the destination directory's parent directories. For example, fs setacl ~/my nd_campus l fs setacl ~/my/data nd_campus l If there are several directories, the find command may be used to set ACLs recursively: find ~/my -type d -exec fs setacl {} nd_campus read \\; Submitting Large Numbers of Jobs Because you will certainly want to run many jobs at once via Condor, you can easily modify your submit file to run a program with tens or hundreds of variations. Change the queue command to queue several jobs at once, and the $(PROCESS) macro to modify the parameters with the job number. universe = vanilla executable = /bin/echo arguments = hello $(PROCESS) output = test.output.$(PROCESS) error = test.error.$(PROCESS) should_transfer_files = yes when_to_transfer_output = on_exit log = test.logfile queue 10 Now, when you run condor_submit, you should see something like this: condor_submit test.submit Submitting job(s).......... 10 job(s) submitted to cluster 9. Note in this case that \"cluster\" means \"a bunch of jobs\", where each job is named 9.0, 9.1, 9.2, and so forth. In this next example, condor_q shows that cluster 9 is halfway complete, with job 9.5 currently running. condor_q -- Submitter: hedwig.cse.nd.edu : <129.74.154.241:33593> : hedwig.cse.nd.edu ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 9.5 dthain 8/26 17:46 0+00:00:01 R 0 0.0 echo hello 5 9.6 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 6 9.7 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 7 9.8 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 8 9.9 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 9 To Submit Multicore SMP jobs to the ND Condor Pool The condor pool is configured to enable dynamic slots. Therefore, if you want to submit multi-threaded or multicore SMP Condor jobs (e.g. using OpenMP), you can add below lines in your Condor job script: ... environment = OMP_NUM_THREADS=4;LD_LIBRARY_PATH=${LD_LIBRARY_PATH} request_cpus = 4 ... For example, if you compile below hellow_world.c: #include <omp.h> #include <stdio.h> #include <stdlib.h> int main (int argc, char *argv[]) { int nthreads, tid; /* Fork a team of threads giving them their own copies of variables */ #pragma omp parallel private(nthreads, tid) { /* Obtain thread number */ tid = omp_get_thread_num(); printf(\"Hello World from thread = %d\\n\", tid); /* Only master thread does this */ if (tid == 0) { nthreads = omp_get_num_threads(); printf(\"Number of threads = %d\\n\", nthreads); } } /* All threads join master thread and disband */ } with icc -openmp hello_world.c -o hello_world.x and then submit your Condor job script with executable = hello_world.x and above options, then you will get an output, for example, like: Hello World from thread = 0 Hello World from thread = 1 Hello World from thread = 3 Hello World from thread = 2 Number of threads = 4 Example of Submitting 10 Matlab jobs Following is a Condor submission script template for running Matlab with 4 cores: universe = vanilla getenv = true executable = Path_to_your_executable_file/executable.sh output = test.output error = test.error request_cpus = 4 should_transfer_files = yes when_to_transfer_output = on_exit log = logfile queue 10 with 'executable.sh': #!/bin/bash if [ -r /opt/crc/Modules/current/init/bash ]; then source /opt/crc/Modules/current/init/bash fi module load matlab # If needed, specify the location of additional .m files. Note that Condor must be able to read this directory. export MATLABPATH=/path/to/your/matlab/files # Substitute your ID below to ensure Matlab can write configuration files to a unique directory: export MATLAB_PREFDIR=/tmp/AFS_ID export TMPDIR=/tmp/AFS_ID # Determine the full path to a matlab version export MLAB=`which matlab` ${MLAB} -nodisplay -nosplash -nojvm -r \"myFunction('$1');exit\" Example of Submitting an Amber job to a GPU node Following is a Condor submission script template for running Amber with 1 GPU: universe = vanilla getenv = true executable = Path_to_your_executable_file/executable.sh output = test.output error = test.error request_gpus = 1 should_transfer_files = yes when_to_transfer_output = on_exit log = logfile queue 1 with 'executable.sh': #!/bin/bash if [ -r /opt/crc/Modules/current/init/bash ]; then source /opt/crc/Modules/current/init/bash fi cd Path_to_your_executable_file module load amber pmemd.cuda -O -i mdin -o mdout -p prmtop -c inpcrd Condor Status You can view the total number of CPUs currently in the Condor pool here or you can view a list of all the machines in the pool here . In addition, you can view information about users with jobs currently in the queue here , and you can view a list of all the machines currently running jobs here . For a full visual status of the Condor pool, please see the Condor Visual Status Page, located here (requires Java). More information about the status of the Condor pool, including historical data, can be found at the CCL web page, located here . More Information For a more in-depth tutorial, please take a look at the full tutorial .","title":"HTCondor"},{"location":"resources/condor/#htcondor","text":"The University of Notre Dame has a Condor pool which harnesses the idle computational cycles from workstations and servers all over campus to run batch jobs. Condor provides access to over 20,000 cores. The Condor pool is maintained by the Notre Dame Cooperative Computing Lab (CCL) and CRC; most of the information in this article is taken directly from the CCL website .","title":"HTCondor"},{"location":"resources/condor/#visual-status-of-the-nd-condor-pool","text":"ND Condor Utilization Matrix","title":"Visual Status of the ND Condor Pool"},{"location":"resources/condor/#online-short-course","text":"Short Course In Data Centric Computing","title":"Online Short Course"},{"location":"resources/condor/#about-condor","text":"Condor is a distributed batch computing system used at many institutions around the world. Condor allows many users to share their computing resources, thus giving everyone access to more computing power than any one person could afford to buy. In particular, Condor is good at harnessing idle cycles from under-used servers. Users that submit jobs to Condor can specify their own requirements on what machines to use. You can require the use of one particular machine, or any from a particular cluster, or any with a certain amount of memory or processor type. Of course, if you are borrowing machines owned by other people, then you must accept the possibility that some jobs may be kicked off and must run elsewhere. For more information about Condor, please visit the Condor project page at: https://research.cs.wisc.edu/htcondor/ .","title":"About Condor"},{"location":"resources/condor/#getting-started-with-condor-at-notre-dame","text":"Log into condorfe.crc.nd.edu to submit jobs. To submit a batch job to Condor, you must create a submission file and then run the condor_submit command. Try creating this sample submit file in /tmp/YOURNAME/test.submit . universe = vanilla executable = /bin/echo arguments = hello condor output = test.output should_transfer_files = yes when_to_transfer_output = on_exit log = test.logfile queue Now, to submit the job to Condor, execute: cd /tmp/YOURNAME condor_submit test.submit Submitting job(s)... 1 job(s) submitted to cluster 2. Once the job is submitted, you can use condor_q to look at the status of the jobs in your queue. If you run condor_q quickly enough, you will see your job idle: -- Submitter: hedwig.cse.nd.edu : <129.74.154.241:33593> : hedwig.cse.nd.edu ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 2.0 dthain 8/26 17:21 0+00:00:00 I 0 0.0 echo hello world If you job remains in state I 'idle' for a significant amount of time you should check to see why it has not started. There is most likely a problem matching your request with an available resource which will be shown with the following command. condor_q yourjobnumberhere -better-analyze The command below shows the relative priority of everyone who has recently run jobs. Those with lower priority numbers have their waiting jobs start before others. condor_userprio If you decide to cancel a job, use condor_rm and the job id: condor_rm 2.0 Job 2.0 marked for removal. [!NOTE] Despite what the Condor manual says, you will NOT receive email when a job is complete. This feature has been disabled at Notre Dame due to our email security configuration.","title":"Getting Started With Condor at Notre Dame"},{"location":"resources/condor/#important-note-about-afs","text":"In the example above, the submit file and all of the job's details were stored in /tmp/YOURNAME on your local disk. Condor simply moved the necessary files back and forth in order to run your jobs. If instead you store your data files in AFS (i.e. your home directory), Condor cannot access them because it will not have your AFS token or Kerberos ticket. If you want Condor to be able to read any data out of AFS, you must change the ACLs on the necessary directories to allow the security group nd_campus to read the data. Note that this will allow anyone with a valid account to read the data within the directory. Here's how: fs setacl ~/my/data/directory nd_campus read If you want Condor to be able to write to AFS, you must change the ACLs to the following: fs setacl ~/my/data/directory nd_campus rlidw Because AFS permissions are hierarchical, in both of these examples nd_campus must have at least lookup 'l' permission in the destination directory's parent directories. For example, fs setacl ~/my nd_campus l fs setacl ~/my/data nd_campus l If there are several directories, the find command may be used to set ACLs recursively: find ~/my -type d -exec fs setacl {} nd_campus read \\;","title":"Important note about AFS"},{"location":"resources/condor/#submitting-large-numbers-of-jobs","text":"Because you will certainly want to run many jobs at once via Condor, you can easily modify your submit file to run a program with tens or hundreds of variations. Change the queue command to queue several jobs at once, and the $(PROCESS) macro to modify the parameters with the job number. universe = vanilla executable = /bin/echo arguments = hello $(PROCESS) output = test.output.$(PROCESS) error = test.error.$(PROCESS) should_transfer_files = yes when_to_transfer_output = on_exit log = test.logfile queue 10 Now, when you run condor_submit, you should see something like this: condor_submit test.submit Submitting job(s).......... 10 job(s) submitted to cluster 9. Note in this case that \"cluster\" means \"a bunch of jobs\", where each job is named 9.0, 9.1, 9.2, and so forth. In this next example, condor_q shows that cluster 9 is halfway complete, with job 9.5 currently running. condor_q -- Submitter: hedwig.cse.nd.edu : <129.74.154.241:33593> : hedwig.cse.nd.edu ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 9.5 dthain 8/26 17:46 0+00:00:01 R 0 0.0 echo hello 5 9.6 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 6 9.7 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 7 9.8 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 8 9.9 dthain 8/26 17:46 0+00:00:00 I 0 0.0 echo hello 9","title":"Submitting Large Numbers of Jobs"},{"location":"resources/condor/#to-submit-multicore-smp-jobs-to-the-nd-condor-pool","text":"The condor pool is configured to enable dynamic slots. Therefore, if you want to submit multi-threaded or multicore SMP Condor jobs (e.g. using OpenMP), you can add below lines in your Condor job script: ... environment = OMP_NUM_THREADS=4;LD_LIBRARY_PATH=${LD_LIBRARY_PATH} request_cpus = 4 ... For example, if you compile below hellow_world.c: #include <omp.h> #include <stdio.h> #include <stdlib.h> int main (int argc, char *argv[]) { int nthreads, tid; /* Fork a team of threads giving them their own copies of variables */ #pragma omp parallel private(nthreads, tid) { /* Obtain thread number */ tid = omp_get_thread_num(); printf(\"Hello World from thread = %d\\n\", tid); /* Only master thread does this */ if (tid == 0) { nthreads = omp_get_num_threads(); printf(\"Number of threads = %d\\n\", nthreads); } } /* All threads join master thread and disband */ } with icc -openmp hello_world.c -o hello_world.x and then submit your Condor job script with executable = hello_world.x and above options, then you will get an output, for example, like: Hello World from thread = 0 Hello World from thread = 1 Hello World from thread = 3 Hello World from thread = 2 Number of threads = 4","title":"To Submit Multicore SMP jobs to the ND Condor Pool"},{"location":"resources/condor/#example-of-submitting-10-matlab-jobs","text":"Following is a Condor submission script template for running Matlab with 4 cores: universe = vanilla getenv = true executable = Path_to_your_executable_file/executable.sh output = test.output error = test.error request_cpus = 4 should_transfer_files = yes when_to_transfer_output = on_exit log = logfile queue 10 with 'executable.sh': #!/bin/bash if [ -r /opt/crc/Modules/current/init/bash ]; then source /opt/crc/Modules/current/init/bash fi module load matlab # If needed, specify the location of additional .m files. Note that Condor must be able to read this directory. export MATLABPATH=/path/to/your/matlab/files # Substitute your ID below to ensure Matlab can write configuration files to a unique directory: export MATLAB_PREFDIR=/tmp/AFS_ID export TMPDIR=/tmp/AFS_ID # Determine the full path to a matlab version export MLAB=`which matlab` ${MLAB} -nodisplay -nosplash -nojvm -r \"myFunction('$1');exit\"","title":"Example of Submitting 10 Matlab jobs"},{"location":"resources/condor/#example-of-submitting-an-amber-job-to-a-gpu-node","text":"Following is a Condor submission script template for running Amber with 1 GPU: universe = vanilla getenv = true executable = Path_to_your_executable_file/executable.sh output = test.output error = test.error request_gpus = 1 should_transfer_files = yes when_to_transfer_output = on_exit log = logfile queue 1 with 'executable.sh': #!/bin/bash if [ -r /opt/crc/Modules/current/init/bash ]; then source /opt/crc/Modules/current/init/bash fi cd Path_to_your_executable_file module load amber pmemd.cuda -O -i mdin -o mdout -p prmtop -c inpcrd","title":"Example of Submitting an Amber job to a GPU node"},{"location":"resources/condor/#condor-status","text":"You can view the total number of CPUs currently in the Condor pool here or you can view a list of all the machines in the pool here . In addition, you can view information about users with jobs currently in the queue here , and you can view a list of all the machines currently running jobs here . For a full visual status of the Condor pool, please see the Condor Visual Status Page, located here (requires Java). More information about the status of the Condor pool, including historical data, can be found at the CCL web page, located here .","title":"Condor Status"},{"location":"resources/condor/#more-information","text":"For a more in-depth tutorial, please take a look at the full tutorial .","title":"More Information"},{"location":"resources/data/","text":"Data Resources","title":"Data Resources"},{"location":"resources/data/#data-resources","text":"","title":"Data Resources"},{"location":"resources/globus/","text":"Globus What Is Globus? Globus allows researchers everywhere to have access to a fast, powerful file transfer service that\u2019s easy to use. Simply submit a transfer request and walk away \u2014 no need to babysit your job or worry about coming back to a failed request. Globus manages file transfers for you: monitoring performance, retrying failures, auto-tuning, recovering from faults automatically when possible, and reporting status. Globus also allows you to quickly and efficiently share data with collaborators around the globe even if they are not a part of ND. Setting Up Globus at the CRC For instructions on setting up Globus at the CRC, view our setting_up_globus page. Transferring Files to/from CRC [!NOTE] The instructions below are for transferring files between your personal computer and the CRC systems. If you want to transfer files from the CRC systems to someone without a ND/CRC account (i.e. at another university), please see the Sharing Files <sharing-files> section below. After Globus Connect Personal has been installed on your system, you will be able to transfer files through the Globus web interface. Login to Globus if you have not already. Once logged in, you should be on the Transfer Files interface. If you are not, you can click \"File Manager\" towards the top left. Example below: Prepare Endpoints/Collections Click on the Collection field where it says \"Start here...\" This will bring up a menu from which you can choose recent collections, bookmarks, and collections you have created. To transfer files from your own computer, select the \"Your Collections\" tab. Here you will see the collection(s) you have created. Select the collection you created while setting up Globus Connect Personal. *Make sure the Globus Connect Personal program is currently running on your system, otherwise there will be an error. * Navigate to the other Collection field. Here you will enter the name of the CRC's Collection: ND Center for Research Computing Collection . If it is your first time connecting to the Collection (or it's been a while), you may be required to authenticate with your ND credentials. If so, click Continue and you will be sent to a page to select your institution. Search for University of Notre Dame and then click Continue and you will log in through Okta. Then select Allow on the next page. Once successfully connected to the CRC Collection, it will default to showing the contents of your /scratch365/\\<user>/ directory (you must have /scratch365 space to use Globus at the CRC). This is where transferred files will be stored on the CRC collection. Select and Transfer File(s) Both Endpoint windows display the files that are in the current path specified in the Path field. In order to transfer a file, navigate to the directory where you want to transfer your file to, then on the other Endpoint navigate to the directory of the file you want to transfer. Select the file by clicking on it, and click on the corresponding Start at the bottom of the Endpoint to transfer the file to the indicated Endpoint. If you want to check on the status of any transfers, click the \"Activity\" tab on the left Menu. You will be given a notification if your transfer was submitted successfully. You will then receive an e-mail once the transfer is complete, which will indicate whether the transfer was successful or not. [!WARNING] At this time, Globus has no intention of supporting AFS authentication. So, in order to transfer files using Globus at the CRC, you are REQUIRED to have /scratch365 space allocated to you at the CRC. To request a /scratch365 space, please e-mail CRCSupport@nd.edu . If you need the files in your AFS directory, you can move them to your AFS space after the files have been transferred to your /scratch365 directory.** Sharing Files With GlobusPlus, users can now share large datasets (or large files) with anyone at any institution or who has a free Globus account (even if they don't have a ND/CRC account). In order to share files with Globus users at other universities and institutions, you need to set up a new shared endpoint. If you haven't already, make sure you set up your own Globus Account as described above. Please note that this also requires having /scratch365 space. If you do not have /scratch365 space yet, please e-mail CRCSupport@nd.edu with your request. Quick Guide Authenticate with Globus and select the CRC endpoint in the Collections Field. Click \"Start Here...\" Type ND Center for Research Computing Collection and select the CRC in the drop-down menu. Authenticate with Okta if necessary. Navigate to the directory you'd like to share within your /scratch365 space. Highlight it with the mouse. Click \"Share\" towards the right of the collection viewer. Enter a display name, this is what the collaborator will see as the title of the collection. If desired, enter a description. This is not required. Click Next to setup Permissions. Setup permissions to those who'd you like to share to. Towards the top right, click \"Add Permissions - Share With\" You can customize the sharing path if you'd like, or leave it as \"/\". Enter the email address of who you'd like to share with. Click ADD directly to the right of the email field. Fill out the rest of the fields if desired. Click Add Permission on the bottom once finished. If the box titled \"Send Email\" is checked, the collaborator will receive an email from Globus with a link to get to the shared directory. From here, the collaborator can either download the data using the Connect Personal, or to another endpoint (another university etc). Globus has a more detailed guide here .","title":"Globus"},{"location":"resources/globus/#globus","text":"","title":"Globus"},{"location":"resources/globus/#what-is-globus","text":"Globus allows researchers everywhere to have access to a fast, powerful file transfer service that\u2019s easy to use. Simply submit a transfer request and walk away \u2014 no need to babysit your job or worry about coming back to a failed request. Globus manages file transfers for you: monitoring performance, retrying failures, auto-tuning, recovering from faults automatically when possible, and reporting status. Globus also allows you to quickly and efficiently share data with collaborators around the globe even if they are not a part of ND.","title":"What Is Globus?"},{"location":"resources/globus/#setting-up-globus-at-the-crc","text":"For instructions on setting up Globus at the CRC, view our setting_up_globus page.","title":"Setting Up Globus at the CRC"},{"location":"resources/globus/#transferring-files-tofrom-crc","text":"[!NOTE] The instructions below are for transferring files between your personal computer and the CRC systems. If you want to transfer files from the CRC systems to someone without a ND/CRC account (i.e. at another university), please see the Sharing Files <sharing-files> section below. After Globus Connect Personal has been installed on your system, you will be able to transfer files through the Globus web interface. Login to Globus if you have not already. Once logged in, you should be on the Transfer Files interface. If you are not, you can click \"File Manager\" towards the top left. Example below:","title":"Transferring Files to/from CRC"},{"location":"resources/globus/#prepare-endpointscollections","text":"Click on the Collection field where it says \"Start here...\" This will bring up a menu from which you can choose recent collections, bookmarks, and collections you have created. To transfer files from your own computer, select the \"Your Collections\" tab. Here you will see the collection(s) you have created. Select the collection you created while setting up Globus Connect Personal. *Make sure the Globus Connect Personal program is currently running on your system, otherwise there will be an error. * Navigate to the other Collection field. Here you will enter the name of the CRC's Collection: ND Center for Research Computing Collection . If it is your first time connecting to the Collection (or it's been a while), you may be required to authenticate with your ND credentials. If so, click Continue and you will be sent to a page to select your institution. Search for University of Notre Dame and then click Continue and you will log in through Okta. Then select Allow on the next page. Once successfully connected to the CRC Collection, it will default to showing the contents of your /scratch365/\\<user>/ directory (you must have /scratch365 space to use Globus at the CRC). This is where transferred files will be stored on the CRC collection.","title":"Prepare Endpoints/Collections"},{"location":"resources/globus/#select-and-transfer-files","text":"Both Endpoint windows display the files that are in the current path specified in the Path field. In order to transfer a file, navigate to the directory where you want to transfer your file to, then on the other Endpoint navigate to the directory of the file you want to transfer. Select the file by clicking on it, and click on the corresponding Start at the bottom of the Endpoint to transfer the file to the indicated Endpoint. If you want to check on the status of any transfers, click the \"Activity\" tab on the left Menu. You will be given a notification if your transfer was submitted successfully. You will then receive an e-mail once the transfer is complete, which will indicate whether the transfer was successful or not. [!WARNING] At this time, Globus has no intention of supporting AFS authentication. So, in order to transfer files using Globus at the CRC, you are REQUIRED to have /scratch365 space allocated to you at the CRC. To request a /scratch365 space, please e-mail CRCSupport@nd.edu . If you need the files in your AFS directory, you can move them to your AFS space after the files have been transferred to your /scratch365 directory.**","title":"Select and Transfer File(s)"},{"location":"resources/globus/#sharing-files","text":"With GlobusPlus, users can now share large datasets (or large files) with anyone at any institution or who has a free Globus account (even if they don't have a ND/CRC account). In order to share files with Globus users at other universities and institutions, you need to set up a new shared endpoint. If you haven't already, make sure you set up your own Globus Account as described above. Please note that this also requires having /scratch365 space. If you do not have /scratch365 space yet, please e-mail CRCSupport@nd.edu with your request.","title":"Sharing Files"},{"location":"resources/globus/#quick-guide","text":"Authenticate with Globus and select the CRC endpoint in the Collections Field. Click \"Start Here...\" Type ND Center for Research Computing Collection and select the CRC in the drop-down menu. Authenticate with Okta if necessary. Navigate to the directory you'd like to share within your /scratch365 space. Highlight it with the mouse. Click \"Share\" towards the right of the collection viewer. Enter a display name, this is what the collaborator will see as the title of the collection. If desired, enter a description. This is not required. Click Next to setup Permissions. Setup permissions to those who'd you like to share to. Towards the top right, click \"Add Permissions - Share With\" You can customize the sharing path if you'd like, or leave it as \"/\". Enter the email address of who you'd like to share with. Click ADD directly to the right of the email field. Fill out the rest of the fields if desired. Click Add Permission on the bottom once finished. If the box titled \"Send Email\" is checked, the collaborator will receive an email from Globus with a link to get to the shared directory. From here, the collaborator can either download the data using the Connect Personal, or to another endpoint (another university etc). Globus has a more detailed guide here .","title":"Quick Guide"},{"location":"resources/gpu/","text":"GPU Job Submission Example In order to submit a job to a GPU server, you need to use the gpu queue and specify the number of GPU cards you wish to use. The following is a job script example for running GROMACS accelerated with GPU: #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q gpu # Run on the GPU cluster #$ -l gpu_card=1 # Run on 1 GPU card #$ -N job_name # Specify job name module load gromacs # Required modules export OMP_NUM_THREADS=$NSLOTS gmx mdrun -ntomp $OMP_NUM_THREADS -nb gpu -pin on -v -s input.tpr # Run with 16 MPI tasks and 1 GPU devices [!NOTE] * If the -pe parallel environment is not defined in the job script, the default value is smp 1 . Please always make sure to request enough cores for your GPU jobs. * Please note that the runtime limit for GPU systems is 7 days. * Each job must have at least 1 GPU and 1 core to run. Installing Software on a GPU machine In some cases, it is necessary to use a GPU server to install the software you wish to use for your GPU jobs. [!NOTE] * Please note that the CRC does not provide any front end machines with GPUs. For the installation an interactive session is necessary on a GPU node. The following is an example for starting an interactive session on a GPU system with 1 GPU card and 1 core: qrsh -q gpu -l gpu_card=1 -pe smp 1 Once the connection is established, the required software may be installed. [!NOTE] * If your research lab or faculty advisor has purchased a machine(s), there is most likely a host group you can target. For the installation you can target GPUs in a specific host group by using the gpu@@hostgroupname queue. * Before installing and using a software for GPU jobs, please make sure that the software can take advantage of GPUs. CUDA And cuDNN Modules' Avalability Usually, for the installation the CUDA (Compute Unified Device Architecture) library is necessary and in some cases the cuDNN (CUDA for Deep Neural Network) library too. Many versions of these libraries are available on the CRC system: $ module avail cuda ----------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ------------------------------------ cuda/10.0 cuda/10.2 cuda/11.0 cuda/11.2 cuda/11.6 $ module avail cudnn ----------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ------------------------------------ cudnn/7.4 cudnn/8.0.4 cudnn/v7.0 [!NOTE] * If you wish to use a CUDA/cuDNN version which is not installed on the CRC system, you may install other versions with conda . Available Hardware For General Access You can find a list of the CRC owned GPU systems on available_hardware . [!NOTE] * These machines have typically 24 cores and 4 GPUs per node. * Each GPU has an ID within the machine, this ID can be 0, 1, 2 or 3. Resource and Job Monitoring You can monitor the status and availability of GPU resources with the free_gpus.sh script. free_gpus.sh @crc_gpu # For general access free_gpus.sh @crc_1080ti # You can target host groups The Xymon monitoring system can be used to analyze the behavior of processes on a given GPU machine. You can check your job's GPU usage. In order to do that, knowing the GPU ID is necessary. You can check the ID with the following command: qstat -j jobID You can find it under the resource map . Here is an example, the GPU ID is the number in brackets: resource map 1: gpu_card=qa-1080ti-004.crc.nd.edu=(1) Other Resources For GPU Jobs If you wish to run large number of GPU jobs, you may want to consider submitting your jobs via Condor. You can find detailed documentation and examples on condor . If you wish to use GPUs for Machine Learning, you may want to consider using CAML ND. You can find detailed documentation and examples on caml .","title":"GPU"},{"location":"resources/gpu/#gpu","text":"","title":"GPU"},{"location":"resources/gpu/#job-submission-example","text":"In order to submit a job to a GPU server, you need to use the gpu queue and specify the number of GPU cards you wish to use. The following is a job script example for running GROMACS accelerated with GPU: #!/bin/bash #$ -M netid@nd.edu # Email address for job notification #$ -m abe # Send mail when job begins, ends and aborts #$ -pe smp 1 # Specify parallel environment and legal core size #$ -q gpu # Run on the GPU cluster #$ -l gpu_card=1 # Run on 1 GPU card #$ -N job_name # Specify job name module load gromacs # Required modules export OMP_NUM_THREADS=$NSLOTS gmx mdrun -ntomp $OMP_NUM_THREADS -nb gpu -pin on -v -s input.tpr # Run with 16 MPI tasks and 1 GPU devices [!NOTE] * If the -pe parallel environment is not defined in the job script, the default value is smp 1 . Please always make sure to request enough cores for your GPU jobs. * Please note that the runtime limit for GPU systems is 7 days. * Each job must have at least 1 GPU and 1 core to run.","title":"Job Submission Example"},{"location":"resources/gpu/#installing-software-on-a-gpu-machine","text":"In some cases, it is necessary to use a GPU server to install the software you wish to use for your GPU jobs. [!NOTE] * Please note that the CRC does not provide any front end machines with GPUs. For the installation an interactive session is necessary on a GPU node. The following is an example for starting an interactive session on a GPU system with 1 GPU card and 1 core: qrsh -q gpu -l gpu_card=1 -pe smp 1 Once the connection is established, the required software may be installed. [!NOTE] * If your research lab or faculty advisor has purchased a machine(s), there is most likely a host group you can target. For the installation you can target GPUs in a specific host group by using the gpu@@hostgroupname queue. * Before installing and using a software for GPU jobs, please make sure that the software can take advantage of GPUs.","title":"Installing Software on a GPU machine"},{"location":"resources/gpu/#cuda-and-cudnn-modules-avalability","text":"Usually, for the installation the CUDA (Compute Unified Device Architecture) library is necessary and in some cases the cuDNN (CUDA for Deep Neural Network) library too. Many versions of these libraries are available on the CRC system: $ module avail cuda ----------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ------------------------------------ cuda/10.0 cuda/10.2 cuda/11.0 cuda/11.2 cuda/11.6 $ module avail cudnn ----------------------------------- /afs/crc.nd.edu/x86_64_linux/Modules/modules/development_tools_and_libraries ------------------------------------ cudnn/7.4 cudnn/8.0.4 cudnn/v7.0 [!NOTE] * If you wish to use a CUDA/cuDNN version which is not installed on the CRC system, you may install other versions with conda .","title":"CUDA And cuDNN Modules' Avalability"},{"location":"resources/gpu/#available-hardware-for-general-access","text":"You can find a list of the CRC owned GPU systems on available_hardware . [!NOTE] * These machines have typically 24 cores and 4 GPUs per node. * Each GPU has an ID within the machine, this ID can be 0, 1, 2 or 3.","title":"Available Hardware For General Access"},{"location":"resources/gpu/#resource-and-job-monitoring","text":"You can monitor the status and availability of GPU resources with the free_gpus.sh script. free_gpus.sh @crc_gpu # For general access free_gpus.sh @crc_1080ti # You can target host groups The Xymon monitoring system can be used to analyze the behavior of processes on a given GPU machine. You can check your job's GPU usage. In order to do that, knowing the GPU ID is necessary. You can check the ID with the following command: qstat -j jobID You can find it under the resource map . Here is an example, the GPU ID is the number in brackets: resource map 1: gpu_card=qa-1080ti-004.crc.nd.edu=(1)","title":"Resource and Job Monitoring"},{"location":"resources/gpu/#other-resources-for-gpu-jobs","text":"If you wish to run large number of GPU jobs, you may want to consider submitting your jobs via Condor. You can find detailed documentation and examples on condor . If you wish to use GPUs for Machine Learning, you may want to consider using CAML ND. You can find detailed documentation and examples on caml .","title":"Other Resources For GPU Jobs"},{"location":"resources/ndcms/","text":"NDCMS The page contains information pertaining to the Notre Dame High Energy Physics Research Group . Below you will find navigation links to all content within this page. Page Navigation [!NOTE] All of this documentation is specific to our NDCMS T3 cluster. It is written and maintained by the users of that cluster, which includes you. Please help us keep this up-to-date. The most important way in which you can do this is to send e-mail to NDT3@listserv.nd.edu if you try any of the documentation here and find it's out of date. Not on the mailing list? Contact klannon@nd.edu to get added. Logging In and Setting up your Software Environment From inside the ND network (being physically on campus or via VPN) or at CERN, one can log directly into the interactive head node: ssh -Y *username*@earth.crc.nd.edu Alternatively, if that doesn't work, try: /usr/bin/ssh -Y -l username@earth.crc.nd.edu From a remote location (e.g. off campus, etc.), one must first log into the VPN. More information is available in the section off-campus-connect . crcfe01.crc.nd.edu crcfe02.crc.nd.edu Tip: Don't forget the -Y option for both ssh commands if you want any X windows to show up on your screen (i.e. opening TBrowsers, histograms, etc.) For more comfort, you can create the file \".ssh/config\" on your local computer and insert an entry like Host earth, crcfe01, crcfe02 HostName %h.crc.nd.edu User *your_username* ForwardX11 yes ForwardX11Trusted yes ControlMaster auto ControlPath ~/.ssh/control-%r@%h:%p The last two lines are optional. They set up ssh to allow a second session to \"tunnel\" through the first one. As long as you have one ssh session open, further connections to earth do not require you to enter your password again. This should only be done for Notre Dame, as normally Kerberos authentication and ssh keys work better. With this setup, you may type just \"ssh earth\" to log into earth, and likewise for crcfe01 and crcfe02. Setting up environment [!NOTE] Only the earth.crc.nd.edu machine has the software required to use CMSSW, CRAB, etc. First login or when experiencing trouble with Condor: The first time you log into earth, set the AFS permissions of a directory to use for Condor as follows: Your home directory needs to be readable by anyone on campus because Condor doesn't run the jobs under your username. In your home directory, do the following: cd ~ fs sa . nd_campus rl fs sa . system:authuser rl If you have any subdirectories which you plan to use for Condor, you'll need to add read permissions for them as well. If you have a large number of subdirectories to modify see [[#If You Forgot to Set Your AFS Permissions at First Login|here]]. For the directory where CRAB is going to write outputs, you need to give write permission to any user on campus. Be careful doing this. You don't want to do this for directories where someone else could make a mistake and delete important files (like your home directory). Assuming your condor directory is called \"my condor_directory\", then you should do the following: cd my_condor_directory/ fs sa . nd_campus rlidwk fs sa . system:administrators rlidwka fs sa . system:authuser rlidwk You'll have to configure Condor so that any output files are stored in the specific directory to which you've granted write permissions. This will avoid possible problems in which condor does not have the correct permissions to launch jobs from your AFS space. [!WARNING] If you didn't do this the first time you logged in or created your Condor directory, this is fixable. See here <if-you-forgot> Add your proxy DN and Notre Dame username (your username on earth.crc.nd.edu) 1) Please add your proxy DN and ND username in the google doc below: https://docs.google.com/document/d/1piHU3tvAdPEXis-evx1mzOD8YwyQ59SbgeLUZR4U1cE/edit 2) Let us know that you've added your DN to the shared google doc file, please email ijohnso1@nd.edu and CC khurtado@nd.edu [!NOTE] If you would like to switch to a more modern shell, such as bash, you need to contact the CRC to have your shell changed in their database.** If You Forgot to Set Your AFS Permissions at First Login You can go back and set your AFS permissions recursively after the fact using the \"find\" command carefully: Starting in your home directory or one of your subdirectories, you can do the following to set read permissions for all subdirectories below. find . -type d -exec fs sa {} nd_campus rl \\; find . -type d -exec fs sa {} system:authuser rl \\; For the Condor directory and any of its subdirectories, you can use the following to set permissions correctly: cd my_condor_directory find . -type d -exec fs sa {} nd_campus rlidwk \\; find . -type d -exec fs sa {} system:administrators rlidwka \\; find . -type d -exec fs sa {} system:authuser rlidwk \\; PhEDEx Back to Top of the Page <ndcms> . The CMS experiment is managing hundreds petabytes of data recorded by the detector and simulated physics events. Data are transferred to distributed CMS sites for storage, processing and analysis. PhEDEx (Physics Experiment Data Export) maintains the knowledge of data replicas locations and manages data transfers between the sites. Requesting a PhEDEx Transfer to the Notre Dame Tier 3 Site (US_T3_NotreDame) use DAS https://cmsweb.cern.ch/das/] to find the dataset you're interested in transferring In the search field, use this format to search for your favorite dataset: dataset dataset=/Tau/Run2011A-PromptReco-v4/AOD Click on \"Subscribe to PhEDEx\" Request a transfer to the US_T3_NotreDame site Under \"Destinations\" check the box next to T3_US_NotreDame At the bottom of the page, click \"Submit Request\", and click \"confirm\" on the following page. You will receive an email notification with a link to the status of your request. You will receive a confirmation email when your request is approved by the site admin. Monitoring Tier 3 components and Jobs Back to Top of the Page <ndcms> . Below are a collection of links that can be used to try to monitor the health of the Tier 3 components. If you see unexpected behavior--fewer than normal running jobs, slower job I/O, failing file transfers, etc.--please check here for indications of what might be wrong. Note: Unless otherwise noted, the links below only work for those on campus or connected with a VPN. HTCondor Monitoring To check the general status of HTCondor within the CRC, you can view the HTCondor utilization matrix , for more information on HTCondor itself view the HTCondor <condor> page. The official documentation for conodr command line utilities can be found here . HTCondor Job Monitoring To view the status of all jobs in the condor queue (or for a specific user), use the following command: condor_q username Note: if you have submitted jobs from outside ND, condor maps your username to \"uscms01\". If you have jobs in the \"Idle\" state, you can ask condor why they are not running, using the following command: condor_q -better {jobID} This command will give you a list of all the reasons a job can be rejected, and tell you how many of the 600 nodes are rejecting your job for that reason. It is possible to manually abort your jobs using the following command: condor_rm (jobID or username) However, it is recommended to cancel the jobs via CRAB, because CRAB will often get confused if its jobs suddenly disappear. To abort jobs using CRAB, use: crab -kill (job_range or \"all\") The memory restriction per node on the condor queue is set to 1 GB by default. This is measured against the virtual memory of the process, meaning once a job's image size (virtual memory) becomes larger than 1 GB it could be idled indefinitely. Many CMSSW jobs tend to accumulate much more virtual memory than physical memory (up to 2x in some cases). This causes jobs to be idled when they don't necessarily need to be. You can change the default 1 GB memory restriction through the command condor_qedit. If you choose to change this value, try to be reasonably sure that your jobs won't be using more than 1 GB of real memory as this could cause problems for the machine the job is running on (including possibly crashing it). In order to change the memory limit, do the following: 1) find the job requirements string for one of your jobs: > condor_q -l <condor_job_id> | grep Requirements 2) copy the string in quotes that comes after \"Requirements = \" in the output. The requirements string will have an element like ( ( TARGET.Memory * 1024 ) >= ImageSize ) Since we can't edit the value of 'TARGET.Memory', we'll have to change the proportionality factor...from 1024 to, say, 2048. 3) reset the Requirements string for a job or group of jobs, using the old requirements string with the new proportionality factor. > condor_qedit <user/condor_job_id> Requirements <new_req_string> Note that since the default string contains double quotation marks (\"\"), you'll need to surround your \\<new_req_string> with single qoutes (''). In addition, if you copy and paste the output from step one, you'll need to remove the space in \"> =\" to have instead \">=\". Remember that 'condor_qedit' will work on a specific job ID (xxx.y), a job cluster ID (xxx), or a username. Storage Back to Top of the Page <ndcms> . Users have access to a variety of storage locations. The key is knowing the tradeoffs of each, so you can identify what's the right resource for you to use. If you don't have a directory in any of the spaces listed, ask for help at ndt3-list@nd.edu . Home Area Each user has a home directory on /afs/crc.nd.edu/user with 100GB of personal disk space that is backed up nightly. This is where you should keep software that you're developing, papers that you're writing, your thesis draft, etc. Basically, use this for anything that you would be very sad to have to recreate if it were accidentally deleted or lost due to hardware failure. To check the quota use fs lq (short for \u201cfileservice listquota\u201d) Scratch Space Also users get 500GB of non-backed up space in /scratch365/<username> and non-backed up space for small files in /store/smallfiles . There is no quota on /store/smallfiles but the total space is 80 TB and must be shared by all users. In general, this storage is useful to use for temporary files of intermediate sizes. If you need reasonable access performance for multiple jobs to the files (e.g. you're going to run more than ~100 jobs reading or writing files in the batch system) then don't use /store/smallfiles as the performance degrades severely. In that case, either use /scratch365 or /hadoop/store/user (see below). Accessing the scratch space from grid jobs Grid jobs running at ND (e.g: via CMS Connect) need to prepend /cms to the /scratch365 and /store/smallfiles directories ( /cms/scratch365/<username> and /cms/store/smallfiles ) due to standard requirements in the CMS Global Pool for singularity-enabled sites for non-hadoop storage spaces to be visible, but they point to the same storage location. Hadoop Space Hadoop is mounted at /hadoop/store/user . The Hadoop file system (hdfs) is a different sort of files system than most. Hadoop breaks your data up into blocks of ~128 MB and scatters two copies of each block across multiple physical disks. It does this for two reasons: The replication makes the system more resilient against hardware failures and it also provides better performance when many different jobs are reading or writing to the system. Like /store/smallfiles , Hadoop doesn't have per user quotas, and there is a lot of space available (at the time of this writing, 644 TB of raw space, but remember that every TB you store takes up ~2 TB of space because of replication). Hadoop is also the file system that is accessible with CMS/grid tools like gfal and XRootD. You should use Hadoop whenever you have very large datasets, when you need to access your data using gfal or XRootD, or when you will be accessing your data with many parallel running jobs (anything more than 100). There are some caveats: * Hadoop doesn't handle very small files well. If you write large numbers of files with sizes on the order of MB, don't use Hadoop. For files in that size range, use /store/smallfiles or /scratch365 * Hadoop doesn't provide posix access directly. This means that normally you can't use commands like ''ls'' or ''cp''. We use something called FUSE to provide posix access to Hadoop, but FUSE can be broken if you try to read too much data too quickly. So, when running many batch jobs, its better to access the data directly using hdfs commands, or to use a tool, like XRootD or Lobster that does this for you. If you're running jobs on data in /hadoop and they are getting stuck or having Input/Output errors, you've probably crashed FUSE on some of the nodes. If this happens, ask for help [ mailto:ndt3-list@nd.edu ndt3-list@nd.edu ]. * ROOT cannot write directly into /hadoop/store/user . If your job is producing ROOT output, write it first to local disk (every worker node has local disk for this purpose) and then at the end of the job, copy the output to /hadoop/store/user (possibly using gfal to avoid problems with FUSE!). Again, if you have questions, ask on ndt3-list@nd.edu . Lobster Working Storage Lobster doesn't do well working out of your AFS home directory. When you run Lobster jobs, you should tell Lobster to make your working area in /tmpscratch/users/<username> . Space is limited and there are no user quotas, so monitor carefully and clean up old files. We reserve the right to clean out this space if someone is using too much and not playing nice with others! [!NOTE] To Add you proxy DN and Notre Dame username, go to: https://wiki.crc.nd.edu/w/index.php/NDCMS_SettingUpEnvironment#Add_you_proxy_DN_and_Notre_Dame_username_.28your_username_on_earth.crc.nd.edu.29 Storage space for PhEDEx All CMS data are stored using the /store convention, Therefore we only need to map: /+store/(.*) Translation rules for PFN to LFN (Physical File Name to Logical File Name): /hadoop/store ==> /store To see how much space is available in the hadoop /store area, you can type the following from earth: hadoop fs -df -h /store","title":"NDCMS"},{"location":"resources/ndcms/#ndcms","text":"The page contains information pertaining to the Notre Dame High Energy Physics Research Group . Below you will find navigation links to all content within this page. Page Navigation [!NOTE] All of this documentation is specific to our NDCMS T3 cluster. It is written and maintained by the users of that cluster, which includes you. Please help us keep this up-to-date. The most important way in which you can do this is to send e-mail to NDT3@listserv.nd.edu if you try any of the documentation here and find it's out of date. Not on the mailing list? Contact klannon@nd.edu to get added.","title":"NDCMS"},{"location":"resources/ndcms/#logging-in-and-setting-up-your-software-environment","text":"From inside the ND network (being physically on campus or via VPN) or at CERN, one can log directly into the interactive head node: ssh -Y *username*@earth.crc.nd.edu Alternatively, if that doesn't work, try: /usr/bin/ssh -Y -l username@earth.crc.nd.edu From a remote location (e.g. off campus, etc.), one must first log into the VPN. More information is available in the section off-campus-connect . crcfe01.crc.nd.edu crcfe02.crc.nd.edu Tip: Don't forget the -Y option for both ssh commands if you want any X windows to show up on your screen (i.e. opening TBrowsers, histograms, etc.) For more comfort, you can create the file \".ssh/config\" on your local computer and insert an entry like Host earth, crcfe01, crcfe02 HostName %h.crc.nd.edu User *your_username* ForwardX11 yes ForwardX11Trusted yes ControlMaster auto ControlPath ~/.ssh/control-%r@%h:%p The last two lines are optional. They set up ssh to allow a second session to \"tunnel\" through the first one. As long as you have one ssh session open, further connections to earth do not require you to enter your password again. This should only be done for Notre Dame, as normally Kerberos authentication and ssh keys work better. With this setup, you may type just \"ssh earth\" to log into earth, and likewise for crcfe01 and crcfe02.","title":"Logging In and Setting up your Software Environment"},{"location":"resources/ndcms/#setting-up-environment","text":"[!NOTE] Only the earth.crc.nd.edu machine has the software required to use CMSSW, CRAB, etc. First login or when experiencing trouble with Condor: The first time you log into earth, set the AFS permissions of a directory to use for Condor as follows: Your home directory needs to be readable by anyone on campus because Condor doesn't run the jobs under your username. In your home directory, do the following: cd ~ fs sa . nd_campus rl fs sa . system:authuser rl If you have any subdirectories which you plan to use for Condor, you'll need to add read permissions for them as well. If you have a large number of subdirectories to modify see [[#If You Forgot to Set Your AFS Permissions at First Login|here]]. For the directory where CRAB is going to write outputs, you need to give write permission to any user on campus. Be careful doing this. You don't want to do this for directories where someone else could make a mistake and delete important files (like your home directory). Assuming your condor directory is called \"my condor_directory\", then you should do the following: cd my_condor_directory/ fs sa . nd_campus rlidwk fs sa . system:administrators rlidwka fs sa . system:authuser rlidwk You'll have to configure Condor so that any output files are stored in the specific directory to which you've granted write permissions. This will avoid possible problems in which condor does not have the correct permissions to launch jobs from your AFS space. [!WARNING] If you didn't do this the first time you logged in or created your Condor directory, this is fixable. See here <if-you-forgot>","title":"Setting up environment"},{"location":"resources/ndcms/#add-your-proxy-dn-and-notre-dame-username-your-username-on-earthcrcndedu","text":"1) Please add your proxy DN and ND username in the google doc below: https://docs.google.com/document/d/1piHU3tvAdPEXis-evx1mzOD8YwyQ59SbgeLUZR4U1cE/edit 2) Let us know that you've added your DN to the shared google doc file, please email ijohnso1@nd.edu and CC khurtado@nd.edu [!NOTE] If you would like to switch to a more modern shell, such as bash, you need to contact the CRC to have your shell changed in their database.**","title":"Add your proxy DN and Notre Dame username (your username on earth.crc.nd.edu)"},{"location":"resources/ndcms/#if-you-forgot-to-set-your-afs-permissions-at-first-login","text":"You can go back and set your AFS permissions recursively after the fact using the \"find\" command carefully: Starting in your home directory or one of your subdirectories, you can do the following to set read permissions for all subdirectories below. find . -type d -exec fs sa {} nd_campus rl \\; find . -type d -exec fs sa {} system:authuser rl \\; For the Condor directory and any of its subdirectories, you can use the following to set permissions correctly: cd my_condor_directory find . -type d -exec fs sa {} nd_campus rlidwk \\; find . -type d -exec fs sa {} system:administrators rlidwka \\; find . -type d -exec fs sa {} system:authuser rlidwk \\;","title":"If You Forgot to Set Your AFS Permissions at First Login"},{"location":"resources/ndcms/#phedex","text":"Back to Top of the Page <ndcms> . The CMS experiment is managing hundreds petabytes of data recorded by the detector and simulated physics events. Data are transferred to distributed CMS sites for storage, processing and analysis. PhEDEx (Physics Experiment Data Export) maintains the knowledge of data replicas locations and manages data transfers between the sites.","title":"PhEDEx"},{"location":"resources/ndcms/#requesting-a-phedex-transfer-to-the-notre-dame-tier-3-site-us_t3_notredame","text":"use DAS https://cmsweb.cern.ch/das/] to find the dataset you're interested in transferring In the search field, use this format to search for your favorite dataset: dataset dataset=/Tau/Run2011A-PromptReco-v4/AOD Click on \"Subscribe to PhEDEx\" Request a transfer to the US_T3_NotreDame site Under \"Destinations\" check the box next to T3_US_NotreDame At the bottom of the page, click \"Submit Request\", and click \"confirm\" on the following page. You will receive an email notification with a link to the status of your request. You will receive a confirmation email when your request is approved by the site admin.","title":"Requesting a PhEDEx Transfer to the Notre Dame Tier 3 Site (US_T3_NotreDame)"},{"location":"resources/ndcms/#monitoring-tier-3-components-and-jobs","text":"Back to Top of the Page <ndcms> . Below are a collection of links that can be used to try to monitor the health of the Tier 3 components. If you see unexpected behavior--fewer than normal running jobs, slower job I/O, failing file transfers, etc.--please check here for indications of what might be wrong. Note: Unless otherwise noted, the links below only work for those on campus or connected with a VPN.","title":"Monitoring Tier 3 components and Jobs"},{"location":"resources/ndcms/#htcondor-monitoring","text":"To check the general status of HTCondor within the CRC, you can view the HTCondor utilization matrix , for more information on HTCondor itself view the HTCondor <condor> page. The official documentation for conodr command line utilities can be found here .","title":"HTCondor Monitoring"},{"location":"resources/ndcms/#htcondor-job-monitoring","text":"To view the status of all jobs in the condor queue (or for a specific user), use the following command: condor_q username Note: if you have submitted jobs from outside ND, condor maps your username to \"uscms01\". If you have jobs in the \"Idle\" state, you can ask condor why they are not running, using the following command: condor_q -better {jobID} This command will give you a list of all the reasons a job can be rejected, and tell you how many of the 600 nodes are rejecting your job for that reason. It is possible to manually abort your jobs using the following command: condor_rm (jobID or username) However, it is recommended to cancel the jobs via CRAB, because CRAB will often get confused if its jobs suddenly disappear. To abort jobs using CRAB, use: crab -kill (job_range or \"all\") The memory restriction per node on the condor queue is set to 1 GB by default. This is measured against the virtual memory of the process, meaning once a job's image size (virtual memory) becomes larger than 1 GB it could be idled indefinitely. Many CMSSW jobs tend to accumulate much more virtual memory than physical memory (up to 2x in some cases). This causes jobs to be idled when they don't necessarily need to be. You can change the default 1 GB memory restriction through the command condor_qedit. If you choose to change this value, try to be reasonably sure that your jobs won't be using more than 1 GB of real memory as this could cause problems for the machine the job is running on (including possibly crashing it). In order to change the memory limit, do the following: 1) find the job requirements string for one of your jobs: > condor_q -l <condor_job_id> | grep Requirements 2) copy the string in quotes that comes after \"Requirements = \" in the output. The requirements string will have an element like ( ( TARGET.Memory * 1024 ) >= ImageSize ) Since we can't edit the value of 'TARGET.Memory', we'll have to change the proportionality factor...from 1024 to, say, 2048. 3) reset the Requirements string for a job or group of jobs, using the old requirements string with the new proportionality factor. > condor_qedit <user/condor_job_id> Requirements <new_req_string> Note that since the default string contains double quotation marks (\"\"), you'll need to surround your \\<new_req_string> with single qoutes (''). In addition, if you copy and paste the output from step one, you'll need to remove the space in \"> =\" to have instead \">=\". Remember that 'condor_qedit' will work on a specific job ID (xxx.y), a job cluster ID (xxx), or a username.","title":"HTCondor Job Monitoring"},{"location":"resources/ndcms/#storage","text":"Back to Top of the Page <ndcms> . Users have access to a variety of storage locations. The key is knowing the tradeoffs of each, so you can identify what's the right resource for you to use. If you don't have a directory in any of the spaces listed, ask for help at ndt3-list@nd.edu .","title":"Storage"},{"location":"resources/ndcms/#home-area","text":"Each user has a home directory on /afs/crc.nd.edu/user with 100GB of personal disk space that is backed up nightly. This is where you should keep software that you're developing, papers that you're writing, your thesis draft, etc. Basically, use this for anything that you would be very sad to have to recreate if it were accidentally deleted or lost due to hardware failure. To check the quota use fs lq (short for \u201cfileservice listquota\u201d)","title":"Home Area"},{"location":"resources/ndcms/#scratch-space","text":"Also users get 500GB of non-backed up space in /scratch365/<username> and non-backed up space for small files in /store/smallfiles . There is no quota on /store/smallfiles but the total space is 80 TB and must be shared by all users. In general, this storage is useful to use for temporary files of intermediate sizes. If you need reasonable access performance for multiple jobs to the files (e.g. you're going to run more than ~100 jobs reading or writing files in the batch system) then don't use /store/smallfiles as the performance degrades severely. In that case, either use /scratch365 or /hadoop/store/user (see below).","title":"Scratch Space"},{"location":"resources/ndcms/#accessing-the-scratch-space-from-grid-jobs","text":"Grid jobs running at ND (e.g: via CMS Connect) need to prepend /cms to the /scratch365 and /store/smallfiles directories ( /cms/scratch365/<username> and /cms/store/smallfiles ) due to standard requirements in the CMS Global Pool for singularity-enabled sites for non-hadoop storage spaces to be visible, but they point to the same storage location.","title":"Accessing the scratch space from grid jobs"},{"location":"resources/ndcms/#hadoop-space","text":"Hadoop is mounted at /hadoop/store/user . The Hadoop file system (hdfs) is a different sort of files system than most. Hadoop breaks your data up into blocks of ~128 MB and scatters two copies of each block across multiple physical disks. It does this for two reasons: The replication makes the system more resilient against hardware failures and it also provides better performance when many different jobs are reading or writing to the system. Like /store/smallfiles , Hadoop doesn't have per user quotas, and there is a lot of space available (at the time of this writing, 644 TB of raw space, but remember that every TB you store takes up ~2 TB of space because of replication). Hadoop is also the file system that is accessible with CMS/grid tools like gfal and XRootD. You should use Hadoop whenever you have very large datasets, when you need to access your data using gfal or XRootD, or when you will be accessing your data with many parallel running jobs (anything more than 100). There are some caveats: * Hadoop doesn't handle very small files well. If you write large numbers of files with sizes on the order of MB, don't use Hadoop. For files in that size range, use /store/smallfiles or /scratch365 * Hadoop doesn't provide posix access directly. This means that normally you can't use commands like ''ls'' or ''cp''. We use something called FUSE to provide posix access to Hadoop, but FUSE can be broken if you try to read too much data too quickly. So, when running many batch jobs, its better to access the data directly using hdfs commands, or to use a tool, like XRootD or Lobster that does this for you. If you're running jobs on data in /hadoop and they are getting stuck or having Input/Output errors, you've probably crashed FUSE on some of the nodes. If this happens, ask for help [ mailto:ndt3-list@nd.edu ndt3-list@nd.edu ]. * ROOT cannot write directly into /hadoop/store/user . If your job is producing ROOT output, write it first to local disk (every worker node has local disk for this purpose) and then at the end of the job, copy the output to /hadoop/store/user (possibly using gfal to avoid problems with FUSE!). Again, if you have questions, ask on ndt3-list@nd.edu .","title":"Hadoop Space"},{"location":"resources/ndcms/#lobster-working-storage","text":"Lobster doesn't do well working out of your AFS home directory. When you run Lobster jobs, you should tell Lobster to make your working area in /tmpscratch/users/<username> . Space is limited and there are no user quotas, so monitor carefully and clean up old files. We reserve the right to clean out this space if someone is using too much and not playing nice with others! [!NOTE] To Add you proxy DN and Notre Dame username, go to: https://wiki.crc.nd.edu/w/index.php/NDCMS_SettingUpEnvironment#Add_you_proxy_DN_and_Notre_Dame_username_.28your_username_on_earth.crc.nd.edu.29","title":"Lobster Working Storage"},{"location":"resources/ndcms/#storage-space-for-phedex","text":"All CMS data are stored using the /store convention, Therefore we only need to map: /+store/(.*) Translation rules for PFN to LFN (Physical File Name to Logical File Name): /hadoop/store ==> /store To see how much space is available in the hadoop /store area, you can type the following from earth: hadoop fs -df -h /store","title":"Storage space for PhEDEx"},{"location":"resources/singularity/","text":"Apptainer/Singularity Apptainer/Singularity is a software application that allow users to have \u2018full control\u2019 over their operating system without the need for any \u2018super-user\u2019 privileges using the notion of containers or images, the two words are used interchangeably. A container is simply an empty room that the users can configure and customize as it suits their needs. It is intended to provide portability, such that it may be run on any flavor of Linux distribution, and its containers can be shared and shipped easily. Why Use Apptainer Oftentimes, it is the case that our users would need to use some software packages that we do not have installed in our systems. As a result, they would need to submit a request for software installation. However, with Apptainer, users will be able to configure their own environments in their containers, then ship it to one of our front-end machines and be able to run any software they have installed in it. Hence, this gives the user more convenience and flexibility. Downloading Apptainer There are multiple ways to download and install Apptainer in your local machines, and they are very well explained at Apptainer\u2019s main website . Apptainer is already installed on CRC frontends and compute nodes. There is no module, simply run apptainer --help . Getting Started Below is a brief summary of the basics for Apptainer. For a more in depth review, see the Quick Start Guide and other pages from Apptainer's documentation. Obtaining Containers Once you have successfully installed Apptainer on your local machine, then there are two ways to get started. One is to use pre-built containers that are available from different sources such as SingularityHub or Docker, and another option is create your own customized containers. Note that you must be on your own machine where you have root / sudo to build a apptainer container. You do not need root to pull a prebuilt container while on CRC resources. Create Your Own Custom Container The command build is used to create containers. To create your own defined containers, you need to first create a recipe file. A recipe file is used to define a custom container. A basic example recipe file example is: Bootstrap: docker From: ubuntu:16.04 %post apt-get -y update apt-get -y install fortune cowsay lolcat %environment export LC_ALL=C export PATH=/usr/games:$PATH %runscript fortune | cowsay | lolcat If this recipe file is saved as \"ubuntuBuild\", a apptainer container can be built with the command: $ sudo apptainer build myOwn.img ubuntuBuild Running the above command will create a container titled \"myOwn.img\" with the specifications in the build script. Utilizing a recipe file, a container can be created from a starting point such as any container on apptainer hub or any docker container. For more information on recipe files, see apptainer definition file docs. Apptainer defaults to creating images in SIF format, which is read only. To create a writable image, there are two options. An image could be created as writeable: $ sudo apptainer build --writable myImg.img myrecipeFile Or, an image could be created as a sandbox directory: $ sudo apptainer build --sandbox myImg.img myrecipeFile [!NOTE] Building containers must be done on a machine not managed by the CRC as you will need admin access. Using Pre-Built Containers To obtain and use a prebuilt container use the pull command to apptainer. The pull command can be used to obtain containers directly on CRC machines. The below example shows how to obtain a basic CentOS 7.8 container from dockerhub: $ apptainer pull CentOS_7.8.sif docker://centos:centos7.8.2003 You can pull images from the Sylabs Container Library , dockerhub , or apptainer-hub . Examples for each are below: $ apptainer pull alpine.sif library://alpine:latest $ apptainer pull CentOS_7.8.sif docker://centos:centos7.8.2003 $ apptainer pull apptainer-images.sif shub://vsoch/apptainer-images Once you pull an image once you do not have to pull it again as it will be stored wherever you tell apptainer to put it. If the container will be stored in AFS, review apptainer_afs_note . For more information see Apptainer pull documentation . Once you pull a pre-built container you can use it a base to build upon with your own custom definition file or simply use the container as is. Accessing Containers Once you have a container there are multiple ways you may access/use it: apptainer shell - used to access the container interactively, more like a mini virtual machine. This command is very useful as it will run a shell that would allow you to manipulate and navigate through the container. You may use this command as follows: $ apptainer shell myContainer.img apptainer run - used to execute the runscript of the container. This requires a runscript definition within the build file of the container. Using the command may be as follows: $ apptainer run myContainer.img apptainer exec - used to execute a particular command within the container, and it can be used as follows: $ apptainer exec myContainer.sif /usr/bin/myCommand Using Apptainer in Batch Jobs The first thing you will need to do is to transfer the container/image to your /scratch365 space. To do so, you may execute the following command on the machine that has the container: scp myContainer.img username@crcefe01.crc.nd.edu:/scratch365/username If you're using mobaxterm you can transfer the image using the panel on the left. Once the container is in your space, the apptainer container can be used in our batch systems as follows: Create a job submission file. Add the below content to the submission file. Keep in mind to change the content accordingly for your own specific needs. #!/bin/bash #$ -q debug #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job apptainer exec path/to/container/myContainer.img runme Where runme is the command being executed within the container. This assumes the container is executable. The script is now ready to be submitted with qsub. Be sure to change the netid, container path, and queue for your own needs. For further details on how to submit jobs, please visit submitting_batch_jobs . Apptainer on GPU Nodes If you plan on using a container with a GPU, you'll need the extra flag --nv assuming the use of run , shell , or exec . The --nv flag will setup the basics with CUDA are setup properly for use within a container. For example, a job with a container to run on a GPU could look as: #!/bin/bash #$ -q gpu #$ -l gpu=1 #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job export SINGULARITYENV_CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES} apptainer exec --nv tensorflow_latest-gpu.sif my_scipt.py Using Apptainer within AFS Apptainer doesn't play nicely with symlinks, within AFS there is a symlink that sometimes causes obscure transient errors with executing a apptainer container. There are a few hacks which may get around this. If you'd like to use a apptainer container within your AFS space, try adding the flags: apptainer shell -B /afs --no-home my_img.simg singulairty exec -B /afs --no-home my_img.simg mycommand The flags -B /afs --no-home trick singulairty into remounting AFS within the container. Note that your home space will still be mounted within the container as it lives within afs. The following error is a transient issue seen from time to time while using apptainer images within AFS: failed to mount squashfs filesystem: input/output error Should you begin to see this error, removing the apptainer cache can solve the issue. rm -rf ~/.apptainer/cache Using Modules within Apptainer containers Sometimes your container needs to access a CRC module, if this is the case then you need to bind the path to where modules live in the file system to the proper place with in your container. For this to work, you cannot have /opt/crc used within your containers. [!NOTE] For the most part, to use modules within a container the container will need to match the RHEL version of the CRC nodes with a compatible CentOS container. You can find the RHEL version with $ cat /etc/redhat-relase For example: Bootstrap: docker From: centos:centos7.8.2003 . To gain access to modules, add -B /opt/crc flags when calling apptainer and APPTAINERENV_PATH=${PATH} APPTAINERENV_LD_LIBRARY_PATH=${LD_LIBRARY_PATH} before calling apptainer as below. #!/bin/bash #$ -q debug #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job module load julia gcc apptainer exec -B /afs /-B /opt/crc --no-home path/to/container/myContainer.img my_command Important Notes There are a few things that our users should keep in mind when using apptainer. \"To be root inside the container, you must be root outside the container\". In other words, all operations that need a super-user access must be done on a machine where you have root access (not the CRC machines). All of the apptainer container configuration must be done on a local machine, where the user has root access. Then, they should copy the container to their /scratch365 or AFS space. This is because users will not have root access on our front-end machines. Using prebuilt containers from dockerhub , the sylabs container library , or apptainer-hub will be fine to use, see Using Pre-Built Containers <using_prebuilt_containers> . It is helpful to double check the permissions of the folders and files on the container that the user intends to manipulate when moved into the cluster. Make sure that needed files and directories have the right permission sets to allow for reading, writing, and executing for all users. This is because once the container is moved to the cluster, the user will lose all super-user privileges. It is recommended that you move the containers to /scratch365 space, or copy containers first to /tmp of a front end before moving into AFS space. See apptainer_afs_note for more info if you'd like to run out of AFS. Helpful Resources There is plenty that can be done with these containers and below are a few sources that can be helpful for any additional information: https://apptainer.org/docs/user/main/index.html https://hub.docker.com/ https://singularityhub.github.io/ https://singularityhub.github.io/singularity-catalog/ Very well put together tutorial for CSE Grad Student's tutorial meeting by Brian DuSell. Apptainer/Singularity-tutorial","title":"Apptainer/Singularity"},{"location":"resources/singularity/#apptainersingularity","text":"Apptainer/Singularity is a software application that allow users to have \u2018full control\u2019 over their operating system without the need for any \u2018super-user\u2019 privileges using the notion of containers or images, the two words are used interchangeably. A container is simply an empty room that the users can configure and customize as it suits their needs. It is intended to provide portability, such that it may be run on any flavor of Linux distribution, and its containers can be shared and shipped easily.","title":"Apptainer/Singularity"},{"location":"resources/singularity/#why-use-apptainer","text":"Oftentimes, it is the case that our users would need to use some software packages that we do not have installed in our systems. As a result, they would need to submit a request for software installation. However, with Apptainer, users will be able to configure their own environments in their containers, then ship it to one of our front-end machines and be able to run any software they have installed in it. Hence, this gives the user more convenience and flexibility.","title":"Why Use Apptainer"},{"location":"resources/singularity/#downloading-apptainer","text":"There are multiple ways to download and install Apptainer in your local machines, and they are very well explained at Apptainer\u2019s main website . Apptainer is already installed on CRC frontends and compute nodes. There is no module, simply run apptainer --help .","title":"Downloading Apptainer"},{"location":"resources/singularity/#getting-started","text":"Below is a brief summary of the basics for Apptainer. For a more in depth review, see the Quick Start Guide and other pages from Apptainer's documentation.","title":"Getting Started"},{"location":"resources/singularity/#obtaining-containers","text":"Once you have successfully installed Apptainer on your local machine, then there are two ways to get started. One is to use pre-built containers that are available from different sources such as SingularityHub or Docker, and another option is create your own customized containers. Note that you must be on your own machine where you have root / sudo to build a apptainer container. You do not need root to pull a prebuilt container while on CRC resources.","title":"Obtaining Containers"},{"location":"resources/singularity/#create-your-own-custom-container","text":"The command build is used to create containers. To create your own defined containers, you need to first create a recipe file. A recipe file is used to define a custom container. A basic example recipe file example is: Bootstrap: docker From: ubuntu:16.04 %post apt-get -y update apt-get -y install fortune cowsay lolcat %environment export LC_ALL=C export PATH=/usr/games:$PATH %runscript fortune | cowsay | lolcat If this recipe file is saved as \"ubuntuBuild\", a apptainer container can be built with the command: $ sudo apptainer build myOwn.img ubuntuBuild Running the above command will create a container titled \"myOwn.img\" with the specifications in the build script. Utilizing a recipe file, a container can be created from a starting point such as any container on apptainer hub or any docker container. For more information on recipe files, see apptainer definition file docs. Apptainer defaults to creating images in SIF format, which is read only. To create a writable image, there are two options. An image could be created as writeable: $ sudo apptainer build --writable myImg.img myrecipeFile Or, an image could be created as a sandbox directory: $ sudo apptainer build --sandbox myImg.img myrecipeFile [!NOTE] Building containers must be done on a machine not managed by the CRC as you will need admin access.","title":"Create Your Own Custom Container"},{"location":"resources/singularity/#using-pre-built-containers","text":"To obtain and use a prebuilt container use the pull command to apptainer. The pull command can be used to obtain containers directly on CRC machines. The below example shows how to obtain a basic CentOS 7.8 container from dockerhub: $ apptainer pull CentOS_7.8.sif docker://centos:centos7.8.2003 You can pull images from the Sylabs Container Library , dockerhub , or apptainer-hub . Examples for each are below: $ apptainer pull alpine.sif library://alpine:latest $ apptainer pull CentOS_7.8.sif docker://centos:centos7.8.2003 $ apptainer pull apptainer-images.sif shub://vsoch/apptainer-images Once you pull an image once you do not have to pull it again as it will be stored wherever you tell apptainer to put it. If the container will be stored in AFS, review apptainer_afs_note . For more information see Apptainer pull documentation . Once you pull a pre-built container you can use it a base to build upon with your own custom definition file or simply use the container as is.","title":"Using Pre-Built Containers"},{"location":"resources/singularity/#accessing-containers","text":"Once you have a container there are multiple ways you may access/use it: apptainer shell - used to access the container interactively, more like a mini virtual machine. This command is very useful as it will run a shell that would allow you to manipulate and navigate through the container. You may use this command as follows: $ apptainer shell myContainer.img apptainer run - used to execute the runscript of the container. This requires a runscript definition within the build file of the container. Using the command may be as follows: $ apptainer run myContainer.img apptainer exec - used to execute a particular command within the container, and it can be used as follows: $ apptainer exec myContainer.sif /usr/bin/myCommand","title":"Accessing Containers"},{"location":"resources/singularity/#using-apptainer-in-batch-jobs","text":"The first thing you will need to do is to transfer the container/image to your /scratch365 space. To do so, you may execute the following command on the machine that has the container: scp myContainer.img username@crcefe01.crc.nd.edu:/scratch365/username If you're using mobaxterm you can transfer the image using the panel on the left. Once the container is in your space, the apptainer container can be used in our batch systems as follows: Create a job submission file. Add the below content to the submission file. Keep in mind to change the content accordingly for your own specific needs. #!/bin/bash #$ -q debug #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job apptainer exec path/to/container/myContainer.img runme Where runme is the command being executed within the container. This assumes the container is executable. The script is now ready to be submitted with qsub. Be sure to change the netid, container path, and queue for your own needs. For further details on how to submit jobs, please visit submitting_batch_jobs .","title":"Using Apptainer in Batch Jobs"},{"location":"resources/singularity/#apptainer-on-gpu-nodes","text":"If you plan on using a container with a GPU, you'll need the extra flag --nv assuming the use of run , shell , or exec . The --nv flag will setup the basics with CUDA are setup properly for use within a container. For example, a job with a container to run on a GPU could look as: #!/bin/bash #$ -q gpu #$ -l gpu=1 #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job export SINGULARITYENV_CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES} apptainer exec --nv tensorflow_latest-gpu.sif my_scipt.py","title":"Apptainer on GPU Nodes"},{"location":"resources/singularity/#using-apptainer-within-afs","text":"Apptainer doesn't play nicely with symlinks, within AFS there is a symlink that sometimes causes obscure transient errors with executing a apptainer container. There are a few hacks which may get around this. If you'd like to use a apptainer container within your AFS space, try adding the flags: apptainer shell -B /afs --no-home my_img.simg singulairty exec -B /afs --no-home my_img.simg mycommand The flags -B /afs --no-home trick singulairty into remounting AFS within the container. Note that your home space will still be mounted within the container as it lives within afs. The following error is a transient issue seen from time to time while using apptainer images within AFS: failed to mount squashfs filesystem: input/output error Should you begin to see this error, removing the apptainer cache can solve the issue. rm -rf ~/.apptainer/cache","title":"Using Apptainer within AFS"},{"location":"resources/singularity/#using-modules-within-apptainer-containers","text":"Sometimes your container needs to access a CRC module, if this is the case then you need to bind the path to where modules live in the file system to the proper place with in your container. For this to work, you cannot have /opt/crc used within your containers. [!NOTE] For the most part, to use modules within a container the container will need to match the RHEL version of the CRC nodes with a compatible CentOS container. You can find the RHEL version with $ cat /etc/redhat-relase For example: Bootstrap: docker From: centos:centos7.8.2003 . To gain access to modules, add -B /opt/crc flags when calling apptainer and APPTAINERENV_PATH=${PATH} APPTAINERENV_LD_LIBRARY_PATH=${LD_LIBRARY_PATH} before calling apptainer as below. #!/bin/bash #$ -q debug #$ -M crcuser@nd.edu #$ -m abe #$ -N example-job module load julia gcc apptainer exec -B /afs /-B /opt/crc --no-home path/to/container/myContainer.img my_command","title":"Using Modules within Apptainer containers"},{"location":"resources/singularity/#important-notes","text":"There are a few things that our users should keep in mind when using apptainer. \"To be root inside the container, you must be root outside the container\". In other words, all operations that need a super-user access must be done on a machine where you have root access (not the CRC machines). All of the apptainer container configuration must be done on a local machine, where the user has root access. Then, they should copy the container to their /scratch365 or AFS space. This is because users will not have root access on our front-end machines. Using prebuilt containers from dockerhub , the sylabs container library , or apptainer-hub will be fine to use, see Using Pre-Built Containers <using_prebuilt_containers> . It is helpful to double check the permissions of the folders and files on the container that the user intends to manipulate when moved into the cluster. Make sure that needed files and directories have the right permission sets to allow for reading, writing, and executing for all users. This is because once the container is moved to the cluster, the user will lose all super-user privileges. It is recommended that you move the containers to /scratch365 space, or copy containers first to /tmp of a front end before moving into AFS space. See apptainer_afs_note for more info if you'd like to run out of AFS.","title":"Important Notes"},{"location":"resources/singularity/#helpful-resources","text":"There is plenty that can be done with these containers and below are a few sources that can be helpful for any additional information: https://apptainer.org/docs/user/main/index.html https://hub.docker.com/ https://singularityhub.github.io/ https://singularityhub.github.io/singularity-catalog/ Very well put together tutorial for CSE Grad Student's tutorial meeting by Brian DuSell. Apptainer/Singularity-tutorial","title":"Helpful Resources"}]}